{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f77395",
   "metadata": {},
   "source": [
    "This notebook will test the functions and commands in create_waveform_datasets_HH_BH_on_the_fly_in_bulk2.py for making the waveform dataset and its metadata for HH and BH stations from the version 3 of the GENIE association and relocation.\n",
    "\n",
    "by Hiroto Bito (hbito@uw.edu)\n",
    "\n",
    "References:\n",
    "-  https://github.com/niyiyu/PNW-ML/blob/main/scripts/mpi_extract_comcat_acceleration.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98014543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import obspy\n",
    "from obspy import Stream\n",
    "from obspy.clients.fdsn import Client\n",
    "from pnwstore.mseed import WaveformClient\n",
    "from obspy import Stream\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import random\n",
    "from itertools import islice\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11662011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1866001/3154754930.py:20: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  assoc_df['event_id'] = 'ev' + assoc_df['otime'].astype(str).str.replace('.', '_')\n"
     ]
    }
   ],
   "source": [
    "#--------------Initiate clients and constants----------------#\n",
    "# Define clients\n",
    "client_iris = Client(\"IRIS\")\n",
    "client_ncedc = Client(\"NCEDC\")\n",
    "client_waveform = WaveformClient()\n",
    "\n",
    "# Define constants\n",
    "sampling_rate = 100  # Hz\n",
    "pre_arrival_time = 50\n",
    "window_length = 150\n",
    "\n",
    "# Load the arrival table and define the output file names\n",
    "assoc_df = pd.read_csv('/wd1/hbito_data/data/datasets_all_regions/arrival_assoc_origin_2010_2015_reloc_cog_ver3.csv', index_col=0)\n",
    "output_waveform_file = \"/wd1/hbito_data/data/datasets_all_regions/waveforms_HH_BH_on_the_fly_bulk_backup3.h5\"\n",
    "output_metadata_file = \"/wd1/hbito_data/data/datasets_all_regions/metadata_HH_BH_on_the_fly_bulk_backup3.csv\"\n",
    "error_log_file = \"/wd1/hbito_data/data/datasets_all_regions/save_errors_on_the_fly_bulk_backup3.csv\"\n",
    "\n",
    "# Preprocess dataframe\n",
    "assoc_df[['network', 'station']] = assoc_df['sta'].str.split('.', expand=True)\n",
    "assoc_df['event_id'] = 'ev' + assoc_df['otime'].astype(str).str.replace('.', '_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472929e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     9.917718\n",
       "1    20.578118\n",
       "2    16.017718\n",
       "3    24.739718\n",
       "4    26.356118\n",
       "5    26.506118\n",
       "6    30.798118\n",
       "7    15.354640\n",
       "8    15.633040\n",
       "9    15.645040\n",
       "Name: otime2picktime, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assoc_df['otime2picktime'] = assoc_df['pick_time'] - assoc_df['otime']\n",
    "assoc_df['otime2picktime'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f76b6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest time between the otime and the pick time in this pick assingment dataset from GENIE associatoin and relocation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "222.49170899391174"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The longest time between the otime and the pick time in this pick assingment dataset from GENIE associatoin and relocation')\n",
    "assoc_df.loc[assoc_df['otime2picktime'].idxmax()]['otime2picktime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5300b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to reorder the traces in a stream\n",
    "def order_traces(stream: Stream, expected_len: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts an ObsPy stream into a (3, expected_len) numpy array, \n",
    "    consistently ordered as [Z, E, N].\n",
    "\n",
    "    Parameters:\n",
    "    - stream: ObsPy Stream containing cleaned traces (padded to expected_len)\n",
    "    - expected_len: Target length of each waveform trace\n",
    "\n",
    "    Returns:\n",
    "    - data_array: np.ndarray of shape (3, expected_len)\n",
    "    \"\"\"\n",
    "    # Fixed component order: Z → 0, E → 1, N → 2\n",
    "    comp_to_index = {\"Z\": 0, \"E\": 1, \"N\": 2, '1': 1, '2': 2}\n",
    "    data_list = [np.zeros(expected_len) for _ in range(3)]  # Default to zeros\n",
    "\n",
    "    for tr in stream:\n",
    "        chan_suffix = tr.stats.channel[-1]\n",
    "        if chan_suffix in comp_to_index:\n",
    "            idx = comp_to_index[chan_suffix]\n",
    "            data_list[idx] = tr.data  \n",
    "\n",
    "    return np.vstack(data_list)  # Shape: (3, expected_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "141d97c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Gather Station Information----------------#\n",
    "# Obtain unique network-station combinations\n",
    "unique_ns = assoc_df.sta.unique()\n",
    "\n",
    "# Define the start and end times for requesting station information\n",
    "starttime_bulk = obspy.UTCDateTime(\"2010-01-01T00:00:00\")\n",
    "endtime_bulk = obspy.UTCDateTime(\"2015-12-31T23:59:59\")\n",
    "\n",
    "# Make a list of stations for bulk request \n",
    "bulk =[]\n",
    "for u_ns in unique_ns:\n",
    "    n,s = u_ns.split('.')\n",
    "\n",
    "    for bi in ['EH?', 'BH?', 'HH?']:\n",
    "        line = (n, s, '*', bi, starttime_bulk, endtime_bulk)\n",
    "        bulk.append(line)\n",
    "\n",
    "# Make a bulk request \n",
    "inv = client_iris.get_stations_bulk(bulk, level='channel')\n",
    "time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c04f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sta</th>\n",
       "      <th>pick_time</th>\n",
       "      <th>arid</th>\n",
       "      <th>iphase</th>\n",
       "      <th>prob</th>\n",
       "      <th>orid</th>\n",
       "      <th>phase</th>\n",
       "      <th>timeres</th>\n",
       "      <th>slatitude</th>\n",
       "      <th>slongitude</th>\n",
       "      <th>...</th>\n",
       "      <th>nass</th>\n",
       "      <th>p_picks</th>\n",
       "      <th>s_picks</th>\n",
       "      <th>rms</th>\n",
       "      <th>nsphz</th>\n",
       "      <th>gap</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>network</th>\n",
       "      <th>station</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UW.PCMD</td>\n",
       "      <td>1.262305e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>0.049</td>\n",
       "      <td>46.888962</td>\n",
       "      <td>-122.301483</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.081</td>\n",
       "      <td>5.0</td>\n",
       "      <td>235.831208</td>\n",
       "      <td>genie</td>\n",
       "      <td>UW</td>\n",
       "      <td>PCMD</td>\n",
       "      <td>ev1262304917_262282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UW.RVW</td>\n",
       "      <td>1.262305e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>1.264</td>\n",
       "      <td>46.149750</td>\n",
       "      <td>-122.742996</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.081</td>\n",
       "      <td>5.0</td>\n",
       "      <td>235.831208</td>\n",
       "      <td>genie</td>\n",
       "      <td>UW</td>\n",
       "      <td>RVW</td>\n",
       "      <td>ev1262304917_262282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UW.GNW</td>\n",
       "      <td>1.262305e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>2.402</td>\n",
       "      <td>47.564130</td>\n",
       "      <td>-122.824980</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.081</td>\n",
       "      <td>5.0</td>\n",
       "      <td>235.831208</td>\n",
       "      <td>genie</td>\n",
       "      <td>UW</td>\n",
       "      <td>GNW</td>\n",
       "      <td>ev1262304917_262282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PB.B013</td>\n",
       "      <td>1.262305e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>S</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>47.813000</td>\n",
       "      <td>-122.910797</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.081</td>\n",
       "      <td>5.0</td>\n",
       "      <td>235.831208</td>\n",
       "      <td>genie</td>\n",
       "      <td>PB</td>\n",
       "      <td>B013</td>\n",
       "      <td>ev1262304917_262282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PB.B943</td>\n",
       "      <td>1.262305e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>S</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.511</td>\n",
       "      <td>47.813202</td>\n",
       "      <td>-122.911301</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.081</td>\n",
       "      <td>5.0</td>\n",
       "      <td>235.831208</td>\n",
       "      <td>genie</td>\n",
       "      <td>PB</td>\n",
       "      <td>B943</td>\n",
       "      <td>ev1262304917_262282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690483</th>\n",
       "      <td>7D.J11D</td>\n",
       "      <td>1.435102e+09</td>\n",
       "      <td>1004326</td>\n",
       "      <td>P</td>\n",
       "      <td>0.694</td>\n",
       "      <td>63886</td>\n",
       "      <td>P</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>43.541599</td>\n",
       "      <td>-126.368599</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.447</td>\n",
       "      <td>5.0</td>\n",
       "      <td>247.683119</td>\n",
       "      <td>genie</td>\n",
       "      <td>7D</td>\n",
       "      <td>J11D</td>\n",
       "      <td>ev1435101498_841147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690484</th>\n",
       "      <td>7D.J19D</td>\n",
       "      <td>1.435102e+09</td>\n",
       "      <td>1004327</td>\n",
       "      <td>P</td>\n",
       "      <td>0.694</td>\n",
       "      <td>63886</td>\n",
       "      <td>P</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>44.179001</td>\n",
       "      <td>-126.271202</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.447</td>\n",
       "      <td>5.0</td>\n",
       "      <td>247.683119</td>\n",
       "      <td>genie</td>\n",
       "      <td>7D</td>\n",
       "      <td>J19D</td>\n",
       "      <td>ev1435101498_841147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690485</th>\n",
       "      <td>7D.J10D</td>\n",
       "      <td>1.435102e+09</td>\n",
       "      <td>1004328</td>\n",
       "      <td>P</td>\n",
       "      <td>0.694</td>\n",
       "      <td>63886</td>\n",
       "      <td>P</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>43.348499</td>\n",
       "      <td>-125.545097</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.447</td>\n",
       "      <td>5.0</td>\n",
       "      <td>247.683119</td>\n",
       "      <td>genie</td>\n",
       "      <td>7D</td>\n",
       "      <td>J10D</td>\n",
       "      <td>ev1435101498_841147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690486</th>\n",
       "      <td>7D.J27D</td>\n",
       "      <td>1.435102e+09</td>\n",
       "      <td>1004329</td>\n",
       "      <td>P</td>\n",
       "      <td>0.694</td>\n",
       "      <td>63886</td>\n",
       "      <td>P</td>\n",
       "      <td>0.915</td>\n",
       "      <td>44.848900</td>\n",
       "      <td>-126.308296</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.447</td>\n",
       "      <td>5.0</td>\n",
       "      <td>247.683119</td>\n",
       "      <td>genie</td>\n",
       "      <td>7D</td>\n",
       "      <td>J27D</td>\n",
       "      <td>ev1435101498_841147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690487</th>\n",
       "      <td>7D.G35D</td>\n",
       "      <td>1.435102e+09</td>\n",
       "      <td>1004331</td>\n",
       "      <td>S</td>\n",
       "      <td>0.694</td>\n",
       "      <td>63886</td>\n",
       "      <td>S</td>\n",
       "      <td>0.358</td>\n",
       "      <td>42.555698</td>\n",
       "      <td>-126.399002</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.447</td>\n",
       "      <td>5.0</td>\n",
       "      <td>247.683119</td>\n",
       "      <td>genie</td>\n",
       "      <td>7D</td>\n",
       "      <td>G35D</td>\n",
       "      <td>ev1435101498_841147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690488 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sta     pick_time     arid iphase   prob   orid phase  timeres  \\\n",
       "0       UW.PCMD  1.262305e+09        0      P  0.680      0     P    0.049   \n",
       "1        UW.RVW  1.262305e+09        1      P  0.680      0     P    1.264   \n",
       "2        UW.GNW  1.262305e+09        3      S  0.680      0     S    2.402   \n",
       "3       PB.B013  1.262305e+09        4      S  0.680      0     S   -0.651   \n",
       "4       PB.B943  1.262305e+09        5      S  0.680      0     S   -0.511   \n",
       "...         ...           ...      ...    ...    ...    ...   ...      ...   \n",
       "690483  7D.J11D  1.435102e+09  1004326      P  0.694  63886     P   -0.336   \n",
       "690484  7D.J19D  1.435102e+09  1004327      P  0.694  63886     P   -0.419   \n",
       "690485  7D.J10D  1.435102e+09  1004328      P  0.694  63886     P   -0.505   \n",
       "690486  7D.J27D  1.435102e+09  1004329      P  0.694  63886     P    0.915   \n",
       "690487  7D.G35D  1.435102e+09  1004331      S  0.694  63886     S    0.358   \n",
       "\n",
       "        slatitude  slongitude  ...  nass  p_picks  s_picks    rms  nsphz  \\\n",
       "0       46.888962 -122.301483  ...     7        2        5  1.081    5.0   \n",
       "1       46.149750 -122.742996  ...     7        2        5  1.081    5.0   \n",
       "2       47.564130 -122.824980  ...     7        2        5  1.081    5.0   \n",
       "3       47.813000 -122.910797  ...     7        2        5  1.081    5.0   \n",
       "4       47.813202 -122.911301  ...     7        2        5  1.081    5.0   \n",
       "...           ...         ...  ...   ...      ...      ...    ...    ...   \n",
       "690483  43.541599 -126.368599  ...     9        4        5  0.447    5.0   \n",
       "690484  44.179001 -126.271202  ...     9        4        5  0.447    5.0   \n",
       "690485  43.348499 -125.545097  ...     9        4        5  0.447    5.0   \n",
       "690486  44.848900 -126.308296  ...     9        4        5  0.447    5.0   \n",
       "690487  42.555698 -126.399002  ...     9        4        5  0.447    5.0   \n",
       "\n",
       "               gap  algorithm  network  station             event_id  \n",
       "0       235.831208      genie       UW     PCMD  ev1262304917_262282  \n",
       "1       235.831208      genie       UW      RVW  ev1262304917_262282  \n",
       "2       235.831208      genie       UW      GNW  ev1262304917_262282  \n",
       "3       235.831208      genie       PB     B013  ev1262304917_262282  \n",
       "4       235.831208      genie       PB     B943  ev1262304917_262282  \n",
       "...            ...        ...      ...      ...                  ...  \n",
       "690483  247.683119      genie       7D     J11D  ev1435101498_841147  \n",
       "690484  247.683119      genie       7D     J19D  ev1435101498_841147  \n",
       "690485  247.683119      genie       7D     J10D  ev1435101498_841147  \n",
       "690486  247.683119      genie       7D     J27D  ev1435101498_841147  \n",
       "690487  247.683119      genie       7D     G35D  ev1435101498_841147  \n",
       "\n",
       "[690488 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------Gather Waveform Information----------------#\n",
    "# Obtain uniquee otime-network-station combinations\n",
    "unique_n_s_otime = assoc_df.drop_duplicates(['event_id', 'network', 'station'],keep='first').reset_index(drop=True)\n",
    "unique_n_s_otime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5d9492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to append entries for the bulk request\n",
    "def append_bulk_lists_chunks(bulk_waveforms, n, s, bi, trace_start, trace_end, day_end, next_day_start):\n",
    "    \"\"\"\n",
    "    Append waveform requests to the bulk list based on the availability of HH? and BH? channels. If the stream runs over the midnight, split the request into two.\n",
    "    \"\"\"\n",
    "    if day_end > trace_end:\n",
    "        # If the trace end is within the same day, we can use HH?\n",
    "        bulk_waveforms.append((n, s, '*', bi, trace_start, trace_end))\n",
    "    else:\n",
    "        # If the trace end goes beyond the day, we need to adjust\n",
    "        bulk_waveforms.append((n, s, '*', bi, trace_start, day_end))\n",
    "        bulk_waveforms.append((n, s, '*', bi, next_day_start, trace_end))\n",
    "    return bulk_waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d63d7c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_bulk_lists(bulk_waveforms, n, s, bi, trace_start, trace_end):\n",
    "    \"\"\"\n",
    "    Append waveform requests to the bulk list based on the availability of HH? and BH? channels.\n",
    "    \"\"\"\n",
    "    bulk_waveforms.append((n, s, '*', bi, trace_start, trace_end))\n",
    "\n",
    "    return bulk_waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e72e2c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [06:14<00:00, 34.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# compose \n",
    "batches_bulk_waveforms_chunks =[]\n",
    "batches_bulk_waveforms_chunks_ncedc =[]\n",
    "\n",
    "batches_bulk_waveforms = []\n",
    "num_batches = 10\n",
    "len_batches = len(unique_n_s_otime) // num_batches\n",
    "\n",
    "count_EH_pairs = 0\n",
    "\n",
    "# Constants\n",
    "sampling_rate = 100  # Hz\n",
    "pre_arrival_time = 50\n",
    "window_length = 150\n",
    "\n",
    "for i in tqdm(range(0, num_batches+1)):\n",
    "    bulk_waveforms_chunks = []\n",
    "    bulk_waveforms_chunks_ncedc = []\n",
    "    bulk_waveforms = []\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    for index, u_ns in islice(unique_n_s_otime.iterrows(), i*len_batches, (i + 1) * len_batches):\n",
    "        n,s = u_ns['network'], u_ns['station']\n",
    "\n",
    "        first_arrival = u_ns['otime']\n",
    "        pick_time = u_ns['pick_time']\n",
    "        trace_start = obspy.UTCDateTime(first_arrival - pre_arrival_time)\n",
    "        trace_end = trace_start + window_length\n",
    "\n",
    "        day_end = obspy.UTCDateTime(trace_start.date + timedelta(days=1))-1e-6\n",
    "        next_day_start = obspy.UTCDateTime(trace_start.date + timedelta(days=1))\n",
    "\n",
    "        # print(trace_start, trace_end)\n",
    "\n",
    "        sta = inv.select(network=n, station=s, time=pick_time)\n",
    "\n",
    "        has_Z = bool(sta.select(channel='??Z'))\n",
    "        has_HH = bool(sta.select(channel='HH?'))\n",
    "        has_BH = bool(sta.select(channel='BH?'))\n",
    "\n",
    "        if not has_Z or not (has_HH or has_BH):\n",
    "            count_EH_pairs += 1\n",
    "            # print(\"count_EH_pairs\", count_EH_pairs)\n",
    "            continue\n",
    "        \n",
    "        if has_HH:\n",
    "            if n in ['NC', 'BK']:\n",
    "                bulk_waveforms_chunks_ncedc = append_bulk_lists_chunks(bulk_waveforms_chunks_ncedc, n, s, 'HH?', trace_start, trace_end, day_end, next_day_start)\n",
    "            else:\n",
    "                bulk_waveforms_chunks = append_bulk_lists_chunks(bulk_waveforms_chunks, n, s, 'HH?', trace_start, trace_end, day_end, next_day_start)\n",
    "            \n",
    "            bulk_waveforms = append_bulk_lists(bulk_waveforms, n, s, 'HH?', trace_start, trace_end)\n",
    "\n",
    "        else:\n",
    "            if n in ['NC', 'BK']:\n",
    "                bulk_waveforms_chunks_ncedc = append_bulk_lists_chunks(bulk_waveforms_chunks_ncedc, n, s, 'BH?', trace_start, trace_end, day_end, next_day_start)\n",
    "            else:\n",
    "                bulk_waveforms_chunks = append_bulk_lists_chunks(bulk_waveforms_chunks, n, s, 'BH?', trace_start, trace_end, day_end, next_day_start)\n",
    "            \n",
    "            bulk_waveforms = append_bulk_lists(bulk_waveforms, n, s, 'BH?', trace_start, trace_end)\n",
    "\n",
    "    batches_bulk_waveforms_chunks.append(bulk_waveforms_chunks)\n",
    "    batches_bulk_waveforms_chunks_ncedc.append(bulk_waveforms_chunks_ncedc)\n",
    "    batches_bulk_waveforms.append(bulk_waveforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3458c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 processed entries.\n"
     ]
    }
   ],
   "source": [
    "#--------------Create Waveform Datasets in batches----------------#\n",
    "# Find entries that have already been processed\n",
    "processed_keys = set()\n",
    "if os.path.exists(output_metadata_file):\n",
    "    processed_df = pd.read_csv(output_metadata_file)\n",
    "    processed_keys = set(zip(processed_df['trace_start_time'], processed_df['station_network_code'], processed_df['station_code']))\n",
    "    print(f\"Loaded {len(processed_keys)} processed entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de6ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open output files\n",
    "h5f = h5py.File(output_waveform_file, \"a\")\n",
    "meta_out = open(output_metadata_file, \"a\")\n",
    "write_header = os.stat(output_metadata_file).st_size == 0 if os.path.exists(output_metadata_file) else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf70c8b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mh5f\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m      2\u001b[0m meta_out\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h5f' is not defined"
     ]
    }
   ],
   "source": [
    "h5f.close()\n",
    "meta_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7da171d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames = ['event_id', 'source_origin_time', 'source_latitude_deg', 'source_longitude_deg',\n",
    "              'source_type', 'source_depth_km', 'preferred_source_magnitude', 'preferred_source_magnitude_type',\n",
    "              'preferred_source_magnitude_uncertainty', 'source_depth_uncertainty_km', 'source_horizontal_uncertainty_km',\n",
    "              'station_network_code', 'station_channel_code', 'station_code', 'station_location_code',\n",
    "              'station_latitude_deg', 'station_longitude_deg', 'station_elevation_m', 'trace_name',\n",
    "              'trace_sampling_rate_hz', 'trace_start_time', 'trace_S_arrival_sample', 'trace_P_arrival_sample',\n",
    "              'trace_S_arrival_uncertainty_s', 'trace_P_arrival_uncertainty_s', 'trace_P_polarity',\n",
    "              'trace_S_onset', 'trace_P_onset', 'trace_snr_db', 'source_type_pnsn_label',\n",
    "              'source_local_magnitude', 'source_local_magnitude_uncertainty', 'source_duration_magnitude',\n",
    "              'source_duration_magnitude_uncertainty', 'source_hand_magnitude', 'trace_missing_channel', 'trace_has_offset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea1ab315",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_writer = csv.DictWriter(meta_out, fieldnames=fieldnames)\n",
    "\n",
    "if write_header:\n",
    "    meta_writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48879f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Finished downloading from WaveformClient\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m n, s, loc, bi, trace_start_time, trace_end_time \u001b[38;5;241m=\u001b[39m batch_chunk_ncedc[j]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[0;32m---> 34\u001b[0m     st2 \u001b[38;5;241m=\u001b[39m \u001b[43mclient_ncedc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_waveforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mstarttime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_start_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace_end_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     37\u001b[0m     st\u001b[38;5;241m.\u001b[39mextend(st2)\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/obspy/clients/fdsn/client.py:872\u001b[0m, in \u001b[0;36mClient.get_waveforms\u001b[0;34m(self, network, station, location, channel, starttime, endtime, quality, minimumlength, longestonly, filename, attach_response, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_url_from_parameters(\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataselect\u001b[39m\u001b[38;5;124m\"\u001b[39m, DEFAULT_PARAMETERS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataselect\u001b[39m\u001b[38;5;124m'\u001b[39m], kwargs)\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# Gzip not worth it for MiniSEED and most likely disabled for this\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# route in any case.\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m data_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gzip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m data_stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/obspy/clients/fdsn/client.py:1482\u001b[0m, in \u001b[0;36mClient._download\u001b[0;34m(self, url, return_string, data, use_gzip, content_type)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m content_type:\n\u001b[1;32m   1481\u001b[0m     headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m content_type\n\u001b[0;32m-> 1482\u001b[0m code, data \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_url_opener\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gzip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gzip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m raise_on_error(code, data)\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/obspy/clients/fdsn/client.py:1890\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, opener, timeout, headers, debug, return_string, data, use_gzip)\u001b[0m\n\u001b[1;32m   1888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_gzip:\n\u001b[1;32m   1889\u001b[0m         request\u001b[38;5;241m.\u001b[39madd_header(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1890\u001b[0m     url_obj \u001b[38;5;241m=\u001b[39m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;66;03m# Catch HTTP errors.\u001b[39;00m\n\u001b[1;32m   1892\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib_request\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/urllib/request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    516\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 517\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    520\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/urllib/request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    533\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    535\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/urllib/request.py:1389\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/urllib/request.py:1350\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m-> 1350\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1352\u001b[0m     h\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sampling_rate = 100  # Hz\n",
    "window_length = 150  # seconds\n",
    "expected_len = int(sampling_rate * window_length)\n",
    "\n",
    "i_iter = 0\n",
    "\n",
    "# for i in range(len(batches_bulk_waveforms)):\n",
    "for i in range(1):\n",
    "    print(\"Batch\",i)\n",
    "    batch_chunk = batches_bulk_waveforms_chunks[2]\n",
    "    batch_chunk_ncedc = batches_bulk_waveforms_chunks_ncedc[2]\n",
    "    batch = batches_bulk_waveforms[2]\n",
    "\n",
    "    save_errors = []\n",
    "\n",
    "\n",
    "    st = Stream()\n",
    "\n",
    "    for j in range(len(batch_chunk)):\n",
    "        n, s, loc, bi, trace_start_time, trace_end_time = batch_chunk[j]\n",
    "        try: \n",
    "            st1 = client_waveform.get_waveforms(network=n, station=s, location=loc, channel=bi,\n",
    "                                                starttime=trace_start_time, endtime=trace_end_time)\n",
    "            st.extend(st1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching waveforms for {n}.{s} {bi} from {trace_start_time} to {trace_end_time}: {e}\")\n",
    "            # Write error immediately\n",
    "            continue\n",
    "    print('Finished downloading from WaveformClient')\n",
    "\n",
    "    for j in range(len(batch_chunk_ncedc)):\n",
    "        n, s, loc, bi, trace_start_time, trace_end_time = batch_chunk_ncedc[j]\n",
    "        try: \n",
    "            st2 = client_ncedc.get_waveforms(network=n, station=s, location=loc, channel=bi,\n",
    "                                                 starttime=trace_start_time, endtime=trace_end_time)\n",
    "            time.sleep(0.2)\n",
    "            st.extend(st2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching waveforms for {n}.{s} {bi} from {trace_start_time} to {trace_end_time}: {e}\")\n",
    "            # Write error immediately\n",
    "            continue\n",
    "    print('Finished downloading NCEDC')    \n",
    "\n",
    "    \n",
    "\n",
    "    # print(\"Requesting waveforms.\")\n",
    "    # if len(batch_chunk) != 0:\n",
    "    #     st1 = client_waveform.get_waveforms_bulk(batch_chunk)\n",
    "    #     time.sleep(0.2) # Stop the execution to avoid making too many requests to the server\n",
    "    # if len(batch_chunk_ncedc) != 0:\n",
    "    #     st2 = client_ncedc.get_waveforms_bulk(batch_chunk_ncedc)\n",
    "    #     time.sleep(0.2) # Stop the execution to avoid making too many requests to the server\n",
    "    # if len(st1) == 0 and len(st2) == 0:\n",
    "    #     print(f\"Batch {i+1} has no waveform requests.\")\n",
    "    #     continue\n",
    "\n",
    "    time.sleep(0.2) # Stop the execution to avoid making too many requests to the server\n",
    "\n",
    "    # st = st1.extend(st2) if len(st2) != 0 else st1\n",
    "\n",
    "    for n_s_time in tqdm(batch[22095:22105]):\n",
    "        i_iter += 1\n",
    "        network, station, location, channel, trace_start_time, trace_end_time = n_s_time\n",
    "\n",
    "        rows_sta  = assoc_df.loc[(assoc_df['sta'] == f\"{network}.{station}\") & (abs(assoc_df['otime'] - float(trace_start_time + timedelta(seconds=pre_arrival_time))) < 1)]\n",
    "        \n",
    "\n",
    "        p_arrival = rows_sta[rows_sta['iphase'] == 'P']\n",
    "        s_arrival = rows_sta[rows_sta['iphase'] == 'S']\n",
    "\n",
    "        key = (str(trace_start_time), network, station)\n",
    "        if key in processed_keys:\n",
    "            print(f\"Skipping already processed entry: {key}\")\n",
    "            # time.sleep(0.2)\n",
    "            continue\n",
    "\n",
    "        # inv_n_s_time = inv.select(network=network, station=station, location=location, channel='*',\n",
    "        #                            starttime=trace_start_time, endtime=trace_end_time)\n",
    "\n",
    "        # inv_n_s_time = inv.select(network=network, station=station, location=location, channel='*')\n",
    "        # print('inv_n_s_time', inv_n_s_time)\n",
    "        st_n_s = st.select(id=f\"{network}.{station}.*.{channel}\",)\n",
    "        # print('st_n_s', st_n_s)\n",
    "\n",
    "        st_n_s_time = Stream([tr for tr in st_n_s if tr.stats.starttime > (trace_start_time-1) and tr.stats.endtime < (trace_end_time+1)]) # Tolerate the error of 1 second when selecting the traces in the stream for the specific time window\n",
    "        st_n_s_time.merge(method=0, fill_value='interpolate')\n",
    "        st_n_s_time.detrend()\n",
    "        st_n_s_time.resample(sampling_rate)\n",
    "\n",
    "        cleaned_stream = Stream()\n",
    "        # print('st_n_s_time', st_n_s_time)\n",
    "        for tr in st_n_s_time:\n",
    "            trace_data = tr.data[:expected_len]\n",
    "            if len(trace_data) < expected_len:\n",
    "                trace_data = np.pad(trace_data, (0, expected_len - len(trace_data)), mode=\"constant\") # Pads zeros at the end\n",
    "            tr.data = trace_data\n",
    "            cleaned_stream.append(tr)\n",
    "\n",
    "        # print('cleaned_stream', cleaned_stream)\n",
    "\n",
    "        _cleaned_stream = order_traces(cleaned_stream, expected_len)\n",
    "\n",
    "        try:\n",
    "            data = np.stack(_cleaned_stream, axis=0)\n",
    "    #         data = np.stack([tr.data[:window_length * sampling_rate - 2] for tr in waveform], axis=0)\n",
    "        except Exception as e:\n",
    "            # Write error immediately\n",
    "            file_exists = os.path.exists(error_log_file)\n",
    "            with open(error_log_file, \"a\", newline=\"\") as errfile:\n",
    "                writer = csv.DictWriter(errfile, fieldnames=['i_iter', 'network', 'station', 'starttime', 'endtime', 'stage', 'error'])\n",
    "                if not file_exists:\n",
    "                    writer.writeheader()\n",
    "                writer.writerow({'i_iter': i_iter, 'network': network, 'station': station, 'starttime': trace_start_time, 'endtime': trace_end_time, 'stage': 'metadata_write', 'error': str(e)})\n",
    "            continue\n",
    "\n",
    "        bucket = str(random.randint(0, 10))\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            dset_path = f\"/data/{bucket}\"\n",
    "            if dset_path not in h5f:\n",
    "                h5f.create_dataset(dset_path, data=np.expand_dims(data, axis=0), maxshape=(None, *data.shape), chunks=True, dtype='float32')\n",
    "                dataset_index = 0\n",
    "            else:\n",
    "                dset = h5f[dset_path]\n",
    "                dataset_index = dset.shape[0]\n",
    "                dset.resize((dataset_index + 1), axis=0)\n",
    "                dset[dataset_index] = data\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing to HDF5 for bucket {bucket}: {e}\")\n",
    "            # Write error immediately\n",
    "            file_exists = os.path.exists(error_log_file)\n",
    "            with open(error_log_file, \"a\", newline=\"\") as errfile:\n",
    "                writer = csv.DictWriter(errfile, fieldnames=['i_iter', 'network', 'station', 'starttime', 'endtime', 'stage', 'error'])\n",
    "                if not file_exists:\n",
    "                    writer.writeheader()\n",
    "                writer.writerow({'i_iter': i_iter, 'network': network, 'station': station, 'starttime': trace_start_time, 'endtime': trace_end_time, 'stage': 'metadata_write', 'error': str(e)})\n",
    "            continue\n",
    "\n",
    "        trace_name = f\"{bucket}${dataset_index},:{data.shape[0]},:{data.shape[1]}\"\n",
    "\n",
    "        print(network, station, location, channel, trace_start_time, trace_end_time)\n",
    "        # print(rows_sta)\n",
    "        # print(rows_sta['lat'].iloc[0])\n",
    "        # print(rows_sta['lat'].iloc[0])\n",
    "        # print(rows_sta['lon'].iloc[0])\n",
    "        # print(rows_sta['depth'].iloc[0])\n",
    "        # print(s_arrival['pick_time'].iloc[0] if not s_arrival.empty else None)\n",
    "        # print(inv_n_s_time[0][0].latitude)\n",
    "        print(cleaned_stream[0].stats.channel[:-1])\n",
    "\n",
    "\n",
    "        try:\n",
    "            row = {\n",
    "                'event_id': rows_sta['event_id'].iloc[0],\n",
    "                'source_origin_time': rows_sta['otime'].iloc[0],\n",
    "                'source_latitude_deg': rows_sta['lat'].iloc[0],\n",
    "                'source_longitude_deg': rows_sta['lon'].iloc[0],\n",
    "                'source_type': \"earthquake\",\n",
    "                'source_depth_km': rows_sta['depth'].iloc[0],\n",
    "                'preferred_source_magnitude': None,\n",
    "                'preferred_source_magnitude_type': None,\n",
    "                'preferred_source_magnitude_uncertainty': None,\n",
    "                'source_depth_uncertainty_km': None,\n",
    "                'source_horizontal_uncertainty_km': None,\n",
    "                'station_network_code': network,\n",
    "                'station_channel_code': cleaned_stream[0].stats.channel[:-1],\n",
    "                'station_code': station,\n",
    "                'station_location_code': \"\",\n",
    "                'station_latitude_deg': None,\n",
    "                'station_longitude_deg': None,\n",
    "                'station_elevation_m': None,\n",
    "                'trace_name': trace_name,\n",
    "                'trace_sampling_rate_hz': sampling_rate,\n",
    "                'trace_start_time': trace_start_time,\n",
    "                'trace_S_arrival_sample': int((s_arrival['pick_time'].iloc[0] - (rows_sta['otime'].iloc[0] - pre_arrival_time)) * sampling_rate)if not s_arrival.empty else None,\n",
    "                'trace_P_arrival_sample': int((p_arrival['pick_time'].iloc[0] - (rows_sta['otime'].iloc[0] - pre_arrival_time)) * sampling_rate) if not p_arrival.empty else None,\n",
    "                'trace_S_arrival_uncertainty_s': None,\n",
    "                'trace_P_arrival_uncertainty_s': None,\n",
    "                'trace_P_polarity': None,\n",
    "                'trace_S_onset': \"impulsive\"if not s_arrival.empty else None,\n",
    "                'trace_P_onset': \"impulsive\" if not p_arrival.empty else None,\n",
    "                'trace_snr_db': None,\n",
    "                'source_type_pnsn_label': None,\n",
    "                'source_local_magnitude': None,\n",
    "                'source_local_magnitude_uncertainty': None,\n",
    "                'source_duration_magnitude': None,\n",
    "                'source_duration_magnitude_uncertainty': None,\n",
    "                'source_hand_magnitude': None,\n",
    "                'trace_missing_channel': \"\",\n",
    "                'trace_has_offset': None\n",
    "            }\n",
    "            meta_writer.writerow(row)\n",
    "            meta_out.flush()\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing metadata for {station}/{trace_start_time}: {e}\")\n",
    "            # Write error immediately\n",
    "            file_exists = os.path.exists(error_log_file)\n",
    "            with open(error_log_file, \"a\", newline=\"\") as errfile:\n",
    "                writer = csv.DictWriter(errfile, fieldnames=['i_iter', 'network', 'station', 'starttime', 'endtime', 'stage', 'error'])\n",
    "                if not file_exists:\n",
    "                    writer.writeheader()\n",
    "                writer.writerow({'i_iter': i_iter, 'network': network, 'station': station, 'starttime': trace_start_time, 'endtime': trace_end_time, 'stage': 'metadata_write', 'error': str(e)})\n",
    "            continue\n",
    "            \n",
    "\n",
    "h5f.close()\n",
    "meta_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb4f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>source_origin_time</th>\n",
       "      <th>source_latitude_deg</th>\n",
       "      <th>source_longitude_deg</th>\n",
       "      <th>source_depth_km</th>\n",
       "      <th>station_network_code</th>\n",
       "      <th>station_channel_code</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_latitude_deg</th>\n",
       "      <th>station_longitude_deg</th>\n",
       "      <th>trace_name</th>\n",
       "      <th>trace_P_arrival_sample</th>\n",
       "      <th>trace_S_arrival_sample</th>\n",
       "      <th>trace_P_onset</th>\n",
       "      <th>trace_S_onset</th>\n",
       "      <th>trace_start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ev1289640038_820443</td>\n",
       "      <td>1.289640e+09</td>\n",
       "      <td>46.46399</td>\n",
       "      <td>-122.37395</td>\n",
       "      <td>12.994</td>\n",
       "      <td>UW</td>\n",
       "      <td>BH</td>\n",
       "      <td>PASS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7$0,:3,:15000</td>\n",
       "      <td>9206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-11-13T09:19:48.820443Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ev1289640038_820443</td>\n",
       "      <td>1.289640e+09</td>\n",
       "      <td>46.46399</td>\n",
       "      <td>-122.37395</td>\n",
       "      <td>12.994</td>\n",
       "      <td>TA</td>\n",
       "      <td>BH</td>\n",
       "      <td>E04D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3$0,:3,:15000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5587.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>2010-11-13T09:19:48.820443Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ev1289646219_581208</td>\n",
       "      <td>1.289646e+09</td>\n",
       "      <td>46.45339</td>\n",
       "      <td>-122.28806</td>\n",
       "      <td>8.582</td>\n",
       "      <td>TA</td>\n",
       "      <td>BH</td>\n",
       "      <td>E04D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6$0,:3,:15000</td>\n",
       "      <td>5390.0</td>\n",
       "      <td>5725.0</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>2010-11-13T11:02:49.581208Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ev1289661539_462542</td>\n",
       "      <td>1.289662e+09</td>\n",
       "      <td>47.58415</td>\n",
       "      <td>-122.74959</td>\n",
       "      <td>16.593</td>\n",
       "      <td>UW</td>\n",
       "      <td>BH</td>\n",
       "      <td>DOSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4$0,:3,:15000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5781.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>2010-11-13T15:18:09.462542Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ev1289670652_802892</td>\n",
       "      <td>1.289671e+09</td>\n",
       "      <td>47.71158</td>\n",
       "      <td>-122.58572</td>\n",
       "      <td>21.296</td>\n",
       "      <td>UW</td>\n",
       "      <td>BH</td>\n",
       "      <td>DOSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9$0,:3,:15000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5986.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>2010-11-13T17:50:02.802892Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ev1289670652_802892</td>\n",
       "      <td>1.289671e+09</td>\n",
       "      <td>47.71158</td>\n",
       "      <td>-122.58572</td>\n",
       "      <td>21.296</td>\n",
       "      <td>TA</td>\n",
       "      <td>BH</td>\n",
       "      <td>B05D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4$1,:3,:15000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>2010-11-13T17:50:02.802892Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ev1289678332_928612</td>\n",
       "      <td>1.289678e+09</td>\n",
       "      <td>45.99873</td>\n",
       "      <td>-122.11309</td>\n",
       "      <td>14.316</td>\n",
       "      <td>UW</td>\n",
       "      <td>BH</td>\n",
       "      <td>YACT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0$0,:3,:15000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5824.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>2010-11-13T19:58:02.928612Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ev1289680261_012108</td>\n",
       "      <td>1.289680e+09</td>\n",
       "      <td>47.72763</td>\n",
       "      <td>-120.31876</td>\n",
       "      <td>0.800</td>\n",
       "      <td>TA</td>\n",
       "      <td>BH</td>\n",
       "      <td>B05D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8$0,:3,:15000</td>\n",
       "      <td>7393.0</td>\n",
       "      <td>9103.0</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>2010-11-13T20:30:11.012108Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ev1289680261_012108</td>\n",
       "      <td>1.289680e+09</td>\n",
       "      <td>47.72763</td>\n",
       "      <td>-120.31876</td>\n",
       "      <td>0.800</td>\n",
       "      <td>TA</td>\n",
       "      <td>BH</td>\n",
       "      <td>E04D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10$0,:3,:15000</td>\n",
       "      <td>8501.0</td>\n",
       "      <td>11052.0</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>2010-11-13T20:30:11.012108Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ev1289680261_012108</td>\n",
       "      <td>1.289680e+09</td>\n",
       "      <td>47.72763</td>\n",
       "      <td>-120.31876</td>\n",
       "      <td>0.800</td>\n",
       "      <td>UW</td>\n",
       "      <td>BH</td>\n",
       "      <td>DOSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3$1,:3,:15000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>impulsive</td>\n",
       "      <td>2010-11-13T20:30:11.012108Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              event_id  source_origin_time  source_latitude_deg  \\\n",
       "0  ev1289640038_820443        1.289640e+09             46.46399   \n",
       "1  ev1289640038_820443        1.289640e+09             46.46399   \n",
       "2  ev1289646219_581208        1.289646e+09             46.45339   \n",
       "3  ev1289661539_462542        1.289662e+09             47.58415   \n",
       "4  ev1289670652_802892        1.289671e+09             47.71158   \n",
       "5  ev1289670652_802892        1.289671e+09             47.71158   \n",
       "6  ev1289678332_928612        1.289678e+09             45.99873   \n",
       "7  ev1289680261_012108        1.289680e+09             47.72763   \n",
       "8  ev1289680261_012108        1.289680e+09             47.72763   \n",
       "9  ev1289680261_012108        1.289680e+09             47.72763   \n",
       "\n",
       "   source_longitude_deg  source_depth_km station_network_code  \\\n",
       "0            -122.37395           12.994                   UW   \n",
       "1            -122.37395           12.994                   TA   \n",
       "2            -122.28806            8.582                   TA   \n",
       "3            -122.74959           16.593                   UW   \n",
       "4            -122.58572           21.296                   UW   \n",
       "5            -122.58572           21.296                   TA   \n",
       "6            -122.11309           14.316                   UW   \n",
       "7            -120.31876            0.800                   TA   \n",
       "8            -120.31876            0.800                   TA   \n",
       "9            -120.31876            0.800                   UW   \n",
       "\n",
       "  station_channel_code station_code  station_latitude_deg  \\\n",
       "0                   BH         PASS                   NaN   \n",
       "1                   BH         E04D                   NaN   \n",
       "2                   BH         E04D                   NaN   \n",
       "3                   BH         DOSE                   NaN   \n",
       "4                   BH         DOSE                   NaN   \n",
       "5                   BH         B05D                   NaN   \n",
       "6                   BH         YACT                   NaN   \n",
       "7                   BH         B05D                   NaN   \n",
       "8                   BH         E04D                   NaN   \n",
       "9                   BH         DOSE                   NaN   \n",
       "\n",
       "   station_longitude_deg      trace_name  trace_P_arrival_sample  \\\n",
       "0                    NaN   7$0,:3,:15000                  9206.0   \n",
       "1                    NaN   3$0,:3,:15000                     NaN   \n",
       "2                    NaN   6$0,:3,:15000                  5390.0   \n",
       "3                    NaN   4$0,:3,:15000                     NaN   \n",
       "4                    NaN   9$0,:3,:15000                     NaN   \n",
       "5                    NaN   4$1,:3,:15000                     NaN   \n",
       "6                    NaN   0$0,:3,:15000                     NaN   \n",
       "7                    NaN   8$0,:3,:15000                  7393.0   \n",
       "8                    NaN  10$0,:3,:15000                  8501.0   \n",
       "9                    NaN   3$1,:3,:15000                     NaN   \n",
       "\n",
       "   trace_S_arrival_sample trace_P_onset trace_S_onset  \\\n",
       "0                     NaN     impulsive           NaN   \n",
       "1                  5587.0           NaN     impulsive   \n",
       "2                  5725.0     impulsive     impulsive   \n",
       "3                  5781.0           NaN     impulsive   \n",
       "4                  5986.0           NaN     impulsive   \n",
       "5                  7020.0           NaN     impulsive   \n",
       "6                  5824.0           NaN     impulsive   \n",
       "7                  9103.0     impulsive     impulsive   \n",
       "8                 11052.0     impulsive     impulsive   \n",
       "9                 10480.0           NaN     impulsive   \n",
       "\n",
       "              trace_start_time  \n",
       "0  2010-11-13T09:19:48.820443Z  \n",
       "1  2010-11-13T09:19:48.820443Z  \n",
       "2  2010-11-13T11:02:49.581208Z  \n",
       "3  2010-11-13T15:18:09.462542Z  \n",
       "4  2010-11-13T17:50:02.802892Z  \n",
       "5  2010-11-13T17:50:02.802892Z  \n",
       "6  2010-11-13T19:58:02.928612Z  \n",
       "7  2010-11-13T20:30:11.012108Z  \n",
       "8  2010-11-13T20:30:11.012108Z  \n",
       "9  2010-11-13T20:30:11.012108Z  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(output_metadata_file)\n",
    "metadata.iloc[0:10][['event_id','source_origin_time','source_latitude_deg','source_longitude_deg','source_depth_km','station_network_code','station_channel_code','station_code','station_latitude_deg','station_longitude_deg','trace_name','trace_P_arrival_sample', 'trace_S_arrival_sample','trace_P_onset','trace_S_onset','trace_start_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d3279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d43cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7750"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches_bulk_waveforms_chunks_ncedc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22adbd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16880"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches_bulk_waveforms_chunks[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
