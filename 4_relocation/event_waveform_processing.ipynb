{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc8c6957",
   "metadata": {},
   "source": [
    "# Event Waveform Processing and Analysis\n",
    "\n",
    "This notebook processes event waveforms from the Cascadia dataset:\n",
    "1. Reads event and pick information from CSV files\n",
    "2. Downloads waveforms from IRIS FDSN\n",
    "3. Processes waveforms (resampling, filtering)\n",
    "4. Calculates amplitudes for local magnitude estimation\n",
    "5. Visualizes waveforms with picks\n",
    "\n",
    "by Marine Denolle (mdenolle@uw.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a31024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import obspy\n",
    "from obspy.clients.fdsn.client import Client\n",
    "from obspy import UTCDateTime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.signal.filter import highpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f660483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling obspy...\n",
      "OK\n",
      "Installing latest obspy...\n",
      "OK\n",
      "Done. Restart the kernel to use the new obspy.\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "\n",
    "for cmd, action in [\n",
    "    ([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"obspy\"], \"Uninstalling\"),\n",
    "    ([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"obspy\"], \"Installing latest\")\n",
    "]:\n",
    "    print(f\"{action} obspy...\")\n",
    "    r = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    print(\"OK\" if r.returncode == 0 else \"FAILED\")\n",
    "\n",
    "print(\"Done. Restart the kernel to use the new obspy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6370af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set processing parameters\n",
    "sample_rate = 100  # Hz\n",
    "highpass_freq = 4  # Hz\n",
    "window_after = 120  # seconds after origin time\n",
    "window_before = 30  # seconds before origin time\n",
    "\n",
    "# Initialize FDSN client\n",
    "client = Client(\"IRIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d7cb9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event data summary:\n",
      "Number of events: 63887\n",
      "\n",
      "First few events:\n",
      "   Latitude   Longitude   Depth (km)             Origin Time (UTC)  \\\n",
      "0  47.22533  -122.16895       56.111   2010-01-01T00:15:17.262282Z   \n",
      "1  48.19518  -121.77276        3.820   2010-01-01T00:16:49.375360Z   \n",
      "2  47.86208  -122.09903       17.799   2010-01-01T07:18:03.689209Z   \n",
      "3  47.96435  -122.91906       21.286   2010-01-01T08:51:56.371091Z   \n",
      "4  45.87262  -122.19180        9.822   2010-01-01T16:12:43.838660Z   \n",
      "\n",
      "    Uncertainity (km)   Horizontal Uncertainity (km)   Geometric Std. (km)  \\\n",
      "0              10.223                         10.216                 0.790   \n",
      "1               7.560                          3.786                 0.140   \n",
      "2               5.118                          4.807                 0.195   \n",
      "3               1.899                          1.884                 0.287   \n",
      "4               2.842                          2.838                 0.229   \n",
      "\n",
      "    Detection Value   Num. P   Num. S   RMS Residual (s)   Event ID   \n",
      "0             0.680        2        5              1.081           0  \n",
      "1             0.840       25       30              0.985           1  \n",
      "2             0.741       10       18              0.784           2  \n",
      "3             0.756       10       10              0.465           3  \n",
      "4             0.850       20       19              0.657           4  \n",
      "\n",
      "Pick data summary:\n",
      "Number of picks: 1004335\n",
      "\n",
      "First few picks:\n",
      "               Pick Time (UTC)  Station Name   Phase Type   Residual (s)  \\\n",
      "0  2010-01-01T00:15:27.180000Z       PCMD.UW            0          0.049   \n",
      "1  2010-01-01T00:15:37.840400Z        RVW.UW            0          1.264   \n",
      "2  2010-01-01T00:15:33.280000Z       PCMD.UW            1         -0.243   \n",
      "3  2010-01-01T00:15:42.002000Z        GNW.UW            1          2.402   \n",
      "4  2010-01-01T00:15:43.618400Z       B013.PB            1         -0.651   \n",
      "\n",
      "    Event ID    Pick ID   \n",
      "0           0          0  \n",
      "1           0          1  \n",
      "2           0          2  \n",
      "3           0          3  \n",
      "4           0          4  \n"
     ]
    }
   ],
   "source": [
    "# Read event and pick data\n",
    "events_df = pd.read_csv('../data/Cascadia_relocated_catalog_ver_3.csv')\n",
    "picks_df = pd.read_csv('~/Downloads/Cascadia_relocated_catalog_picks_ver_3.csv')\n",
    "\n",
    "print(\"Event data summary:\")\n",
    "print(f\"Number of events: {len(events_df)}\")\n",
    "print(\"\\nFirst few events:\")\n",
    "print(events_df.head())\n",
    "\n",
    "print(\"\\nPick data summary:\")\n",
    "print(f\"Number of picks: {len(picks_df)}\")\n",
    "print(\"\\nFirst few picks:\")\n",
    "print(picks_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deddf46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_event(event_id, events_df, picks_df):\n",
    "    \"\"\"\n",
    "    Process single event and return waveforms and metadata\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    event_id : str\n",
    "        Event identifier\n",
    "    events_df : pandas.DataFrame\n",
    "        DataFrame containing event information\n",
    "    picks_df : pandas.DataFrame\n",
    "        DataFrame containing pick information\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    st : obspy.Stream\n",
    "        Processed waveforms\n",
    "    amplitudes : dict\n",
    "        Peak amplitudes for each station\n",
    "    origin_time : UTCDateTime\n",
    "        Event origin time\n",
    "    \"\"\"\n",
    "\n",
    "    # window_before and window_after are defined globally\n",
    "    global window_before, window_after\n",
    "    # Get event information\n",
    "    event_cols = [col for col in events_df.columns if 'event' in col.lower()][0]\n",
    "    origin_cols = [col for col in events_df.columns if 'origin' in col.lower()][0]\n",
    "    station_cols = [col for col in picks_df.columns if 'station' in col.lower()][0]\n",
    "    event = events_df[events_df[event_cols] == event_id].iloc[0]\n",
    "    origin_time = UTCDateTime(event[origin_cols])\n",
    "    \n",
    "    # Get associated picks\n",
    "    event_picks = picks_df[picks_df[event_cols] == event_id]\n",
    "    # Storage for waveforms and amplitudes\n",
    "    st = obspy.Stream()\n",
    "    station_amplitudes = {}\n",
    "    \n",
    "    # Process each station's data\n",
    "    for _, pick in event_picks.iterrows():\n",
    "        try:\n",
    "            # Get network and station codes\n",
    "            station,network = pick[station_cols].split('.')\n",
    "            # remove any headers or trailing spaces\n",
    "            station = station.strip()\n",
    "            network = network.strip()\n",
    "            # sta = client.get_stations(network=network, station=station,\n",
    "                # starttime=origin_time - 7200,\n",
    "                # endtime=origin_time + 7200,level=\"response\")\n",
    "            # Download waveforms\n",
    "            st_temp = client.get_waveforms(\n",
    "                network=network,\n",
    "                station=station,\n",
    "                location=\"*\",\n",
    "                channel=\"*H*\",\n",
    "                starttime=origin_time - window_before,\n",
    "                endtime=origin_time + window_after\n",
    "            )\n",
    "            \n",
    "            # Process each trace\n",
    "            for tr in st_temp:\n",
    "                # Resample\n",
    "                tr.resample(sample_rate)\n",
    "                \n",
    "                # Apply highpass filter\n",
    "                tr.filter('highpass', freq=highpass_freq)\n",
    "                \n",
    "                # Add to stream\n",
    "                st += tr\n",
    "                \n",
    "            # Calculate amplitude (average of 3 components)\n",
    "            station_amps = []\n",
    "            for comp in ['Z', 'N', 'E']:\n",
    "                tr = st_temp.select(component=comp)\n",
    "                if len(tr) > 0:\n",
    "                    station_amps.append(np.max(np.abs(tr[0].data)))\n",
    "            \n",
    "            if station_amps:\n",
    "                station_amplitudes[network+'.'+station] = np.mean(station_amps)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pick[network+'.'+station]}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return st, station_amplitudes, origin_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0044f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = events_df[' Event ID '].values.tolist()\n",
    "st, amplitudes, origin_time = process_event(event_id[0], events_df, picks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7fe1396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pick Time (UTC)', ' Station Name', ' Phase Type', ' Residual (s)',\n",
       "       ' Event ID ', ' Pick ID '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picks_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab88bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each event, process the waveforms and store amplitudes in a new column in picks_df\n",
    "for eid in event_id:\n",
    "    st, amplitudes, origin_time = process_event(eid, events_df, picks_df)\n",
    "    # Store amplitudes in picks_df\n",
    "    for station_key, amp in amplitudes.items():\n",
    "        network, station = station_key.split('.')\n",
    "        # find the row in picks_df based on any unique identifier in Station regardless of empty spaces\n",
    "        station_col = picks_df[' Station Name'].str.strip()\n",
    "        # find the row in picks_df based on Event ID and Station\n",
    "        picks_df.loc[(picks_df[' Event ID '] == eid) & (station_col == station+\".\"+network), ' Amplitude '] = amp\n",
    "    #print updated picks_df\n",
    "    print(picks_df[picks_df[' Event ID '] == eid])\n",
    "\n",
    "# save picks_df with amplitudes to a new csv file\n",
    "picks_df.to_csv('../data/Cascadia_relocated_catalog_picks_with_amplitudes_ver_3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noisepy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
