{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b096be",
   "metadata": {},
   "source": [
    "# Test Event Waveform Processing\n",
    "\n",
    "This notebook tests the event waveform processing script with a small subset of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc7b7ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pnwstore'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mobspy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UTCDateTime\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mobspy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclients\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfdsn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpnwstore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmseed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WaveformClient\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Import functions from the script\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mevent_waveform_processing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find_column, process_event\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pnwstore'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "from pnwstore.mseed import WaveformClient\n",
    "\n",
    "# Import functions from the script\n",
    "from event_waveform_processing import find_column, process_event\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s: %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523cb69d",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the events and picks CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af2c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "events_path = '../data/Cascadia_relocated_catalog_ver_3.csv'\n",
    "picks_path = '../data/Cascadia_relocated_catalog_picks_ver_3.csv'\n",
    "\n",
    "events_df = pd.read_csv(events_path)\n",
    "picks_df = pd.read_csv(picks_path)\n",
    "\n",
    "print(f\"Events shape: {events_df.shape}\")\n",
    "print(f\"Picks shape: {picks_df.shape}\")\n",
    "print(f\"\\nEvents columns: {events_df.columns.tolist()}\")\n",
    "print(f\"\\nPicks columns: {picks_df.columns.tolist()[:10]}...\")  # First 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e52f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few events\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few picks\n",
    "picks_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b22ff6f",
   "metadata": {},
   "source": [
    "## Test Column Detection\n",
    "\n",
    "Test the `find_column` function to ensure it correctly identifies column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3030a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test column finding\n",
    "event_col = find_column(events_df, (\"event id\", \"event_id\", \"event\"))\n",
    "origin_col = find_column(events_df, (\"origin\", \"time\", \"origin time\", \"datetime\"))\n",
    "station_col = find_column(picks_df, (\"station name\", \"station\", \"sta\"))\n",
    "phase_col = find_column(picks_df, (\"phase\", \"type\", \"phase_hint\"))\n",
    "\n",
    "print(f\"Event ID column: {event_col}\")\n",
    "print(f\"Origin time column: {origin_col}\")\n",
    "print(f\"Station column: {station_col}\")\n",
    "print(f\"Phase column: {phase_col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2991bfd4",
   "metadata": {},
   "source": [
    "## Select Test Event\n",
    "\n",
    "Choose a single event to test the processing workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of available event IDs\n",
    "event_ids = events_df[event_col].dropna().unique()\n",
    "print(f\"Total number of events: {len(event_ids)}\")\n",
    "print(f\"\\nFirst 10 event IDs: {event_ids[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9501f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a test event (you can change this)\n",
    "test_event_id = event_ids[0]\n",
    "print(f\"Testing with event ID: {test_event_id}\")\n",
    "\n",
    "# Get event details\n",
    "test_event = events_df[events_df[event_col] == test_event_id].iloc[0]\n",
    "print(f\"\\nEvent details:\")\n",
    "print(test_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56182d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get picks for this event\n",
    "pick_event_col = find_column(picks_df, (\"event id\", \"event_id\", \"event\"))\n",
    "test_picks = picks_df[picks_df[pick_event_col] == test_event_id]\n",
    "print(f\"Number of picks for this event: {len(test_picks)}\")\n",
    "print(f\"\\nPicks:\")\n",
    "test_picks.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff59b3a",
   "metadata": {},
   "source": [
    "## Test WaveformClient Connection\n",
    "\n",
    "Verify that we can connect to the WaveformClient and fetch data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd562dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients\n",
    "client = Client('IRIS')\n",
    "client_waveform = WaveformClient()\n",
    "\n",
    "print(\"Clients initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15171727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test fetching waveforms for one station\n",
    "if len(test_picks) > 0:\n",
    "    # Get first pick's station info\n",
    "    test_pick = test_picks.iloc[0]\n",
    "    raw_station = str(test_pick[station_col]).strip()\n",
    "    parts = raw_station.split('.')\n",
    "    \n",
    "    if len(parts) == 2:\n",
    "        station, network = parts[0].strip(), parts[1].strip()\n",
    "        origin_time = UTCDateTime(test_event[origin_col])\n",
    "        \n",
    "        print(f\"Testing waveform download for: {network}.{station}\")\n",
    "        print(f\"Origin time: {origin_time}\")\n",
    "        \n",
    "        try:\n",
    "            st_test = client_waveform.get_waveforms(\n",
    "                network=network,\n",
    "                station=station,\n",
    "                channel=\"?H?,?N?\",\n",
    "                year=origin_time.strftime('%Y'),\n",
    "                month=origin_time.strftime('%m'),\n",
    "                day=origin_time.strftime('%d'),\n",
    "            )\n",
    "            print(f\"\\nSuccessfully downloaded {len(st_test)} traces\")\n",
    "            print(st_test)\n",
    "            \n",
    "            # Trim to event window\n",
    "            st_test.trim(starttime=origin_time - 30, endtime=origin_time + 120)\n",
    "            print(f\"\\nAfter trimming: {len(st_test)} traces\")\n",
    "            print(st_test)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading waveforms: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8eecee",
   "metadata": {},
   "source": [
    "## Test Process Event Function\n",
    "\n",
    "Run the main processing function on the test event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7947c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the test event\n",
    "_, measurements, origin = process_event(\n",
    "    test_event_id,\n",
    "    events_df,\n",
    "    picks_df,\n",
    "    client,\n",
    "    sample_rate=100,\n",
    "    highpass_freq=4.0,\n",
    "    window_before=30,\n",
    "    window_after=120,\n",
    ")\n",
    "\n",
    "print(f\"\\nOrigin time: {origin}\")\n",
    "print(f\"Number of stations with measurements: {len(measurements)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display measurements\n",
    "if measurements:\n",
    "    print(\"\\nMeasurements by station:\")\n",
    "    for station_key, station_data in measurements.items():\n",
    "        print(f\"\\n{station_key}:\")\n",
    "        for comp in ['Z', 'N', 'E']:\n",
    "            comp_data = station_data[comp]\n",
    "            if not np.isnan(comp_data['max_amp']):\n",
    "                print(f\"  {comp}: max_amp={comp_data['max_amp']:.2f} mm, \"\n",
    "                      f\"min_amp={comp_data['min_amp']:.2f} mm, \"\n",
    "                      f\"duration={comp_data['duration']:.2f} s\")\n",
    "else:\n",
    "    print(\"No measurements returned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f3083",
   "metadata": {},
   "source": [
    "## Update Picks DataFrame\n",
    "\n",
    "Test updating the picks DataFrame with the computed measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d71fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test copy of picks_df\n",
    "test_picks_df = picks_df.copy()\n",
    "\n",
    "# Find or create amplitude column\n",
    "amplitude_col = None\n",
    "for c in test_picks_df.columns:\n",
    "    if \"amplitude\" in c.strip().lower():\n",
    "        amplitude_col = c\n",
    "        break\n",
    "if amplitude_col is None:\n",
    "    amplitude_col = \" Amplitude \"\n",
    "    test_picks_df[amplitude_col] = np.nan\n",
    "\n",
    "# Create component-specific columns\n",
    "for comp in ['Z', 'N', 'E']:\n",
    "    for mtype in ['max_amp', 'min_amp', 'duration']:\n",
    "        col_name = f\" {comp}_{mtype} \"\n",
    "        if col_name not in test_picks_df.columns:\n",
    "            test_picks_df[col_name] = np.nan\n",
    "\n",
    "print(f\"Amplitude column: '{amplitude_col}'\")\n",
    "print(f\"\\nNew columns added: {[f' {c}_{m} ' for c in ['Z', 'N', 'E'] for m in ['max_amp', 'min_amp', 'duration']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update measurements for the test event\n",
    "if measurements:\n",
    "    pick_station_col = find_column(test_picks_df, (\"station name\", \"station\", \"sta\"))\n",
    "    \n",
    "    for station_key, station_data in measurements.items():\n",
    "        network, sta = station_key.split('.')\n",
    "        candidates = [f\"{sta}.{network}\", f\"{network}.{sta}\"]\n",
    "        \n",
    "        # Find matching rows\n",
    "        mask = (test_picks_df[pick_event_col] == test_event_id) & \\\n",
    "               (test_picks_df[pick_station_col].astype(str).str.strip().isin(candidates))\n",
    "        \n",
    "        # Update measurements\n",
    "        max_all_comps = float('-inf')\n",
    "        for comp in ['Z', 'N', 'E']:\n",
    "            comp_data = station_data[comp]\n",
    "            for mtype in ['max_amp', 'min_amp', 'duration']:\n",
    "                col_name = f\" {comp}_{mtype} \"\n",
    "                test_picks_df.loc[mask, col_name] = comp_data[mtype]\n",
    "            \n",
    "            if not np.isnan(comp_data['max_amp']):\n",
    "                max_all_comps = max(max_all_comps, comp_data['max_amp'])\n",
    "        \n",
    "        if max_all_comps != float('-inf'):\n",
    "            test_picks_df.loc[mask, amplitude_col] = max_all_comps\n",
    "\n",
    "print(\"Updated picks DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc71696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display updated picks for the test event\n",
    "updated_picks = test_picks_df[test_picks_df[pick_event_col] == test_event_id]\n",
    "updated_picks_with_amp = updated_picks[updated_picks[amplitude_col].notna()]\n",
    "\n",
    "if len(updated_picks_with_amp) > 0:\n",
    "    print(f\"\\nUpdated picks with amplitudes ({len(updated_picks_with_amp)} rows):\")\n",
    "    cols_to_show = [pick_station_col, amplitude_col]\n",
    "    cols_to_show.extend([f\" {c}_{m} \" for c in ['Z', 'N', 'E'] \n",
    "                         for m in ['max_amp', 'min_amp', 'duration']])\n",
    "    display(updated_picks_with_amp[cols_to_show])\n",
    "else:\n",
    "    print(\"\\nNo picks were updated with amplitudes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a074f8",
   "metadata": {},
   "source": [
    "## Test with Multiple Events (Optional)\n",
    "\n",
    "Process a few more events to ensure the workflow is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1510ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process first 3 events as a test\n",
    "n_test_events = 3\n",
    "test_event_ids = event_ids[:n_test_events]\n",
    "\n",
    "print(f\"Processing {n_test_events} events...\\n\")\n",
    "\n",
    "for i, eid in enumerate(test_event_ids, start=1):\n",
    "    print(f\"[{i}/{n_test_events}] Processing event {eid}\")\n",
    "    \n",
    "    _, measurements, origin = process_event(\n",
    "        eid,\n",
    "        events_df,\n",
    "        test_picks_df,\n",
    "        client,\n",
    "        sample_rate=100,\n",
    "        highpass_freq=4.0,\n",
    "        window_before=30,\n",
    "        window_after=120,\n",
    "    )\n",
    "    \n",
    "    if measurements:\n",
    "        print(f\"  -> Got measurements for {len(measurements)} stations\")\n",
    "    else:\n",
    "        print(f\"  -> No measurements returned\")\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f76228b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Check the overall results and data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938db48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "n_with_amp = test_picks_df[amplitude_col].notna().sum()\n",
    "n_total = len(test_picks_df)\n",
    "\n",
    "print(f\"Total picks: {n_total}\")\n",
    "print(f\"Picks with amplitude measurements: {n_with_amp} ({100*n_with_amp/n_total:.1f}%)\")\n",
    "\n",
    "if n_with_amp > 0:\n",
    "    print(f\"\\nAmplitude statistics:\")\n",
    "    print(test_picks_df[amplitude_col].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
