{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63dd070",
   "metadata": {},
   "source": [
    "## Notebook to optimize detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5ea9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnwstore.mseed import WaveformClient\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "import gc\n",
    "import seisbench.models as sbm\n",
    "from ELEP.elep.ensemble_statistics import ensemble_statistics\n",
    "from ELEP.elep.ensemble_coherence import ensemble_semblance \n",
    "from ELEP.elep.trigger_func import picks_summary_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5ed702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7cde0",
   "metadata": {},
   "source": [
    "# 1. Set up the job\n",
    "\n",
    "* Make a list of stations\n",
    "* make a list pf days\n",
    "* set up parallel job using Dask (ask Zoe&Yiyu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f623f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "twin = 6000     # length of time window\n",
    "step = 3000     # step length\n",
    "l_blnd, r_blnd = 500, 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba28f06",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "157a4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WaveformClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1415507f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3 Trace(s) in Stream:\n",
       "7D.J57A..BH1 | 2012-07-10T00:00:00.010700Z - 2012-07-10T23:59:59.990700Z | 50.0 Hz, 4320000 samples\n",
       "7D.J57A..BH2 | 2012-07-10T00:00:00.010700Z - 2012-07-10T23:59:59.990700Z | 50.0 Hz, 4320000 samples\n",
       "7D.J57A..BHZ | 2012-07-10T00:00:00.010700Z - 2012-07-10T23:59:59.990700Z | 50.0 Hz, 4320000 samples"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get waveforms and filter\n",
    "s_J57A = client.get_waveforms(network=\"7D\", station=\"J57A\", channel=\"?H?\", year=2012, month=7, day=10)\n",
    "s_J57A.filter(type='bandpass',freqmin=4,freqmax=15)\n",
    "s_J57A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa92b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start time and delta \n",
    "delta = s_J57A[0].stats.delta\n",
    "starttime = s_J57A[0].stats.starttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "756ace40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download models\n",
    "pretrain_list = [\"pnw\",\"ethz\",\"instance\",\"scedc\",\"stead\",\"geofon\"]\n",
    "pn_pnw_model = sbm.EQTransformer.from_pretrained('pnw')\n",
    "pn_ethz_model = sbm.EQTransformer.from_pretrained(\"ethz\")\n",
    "pn_instance_model = sbm.EQTransformer.from_pretrained(\"instance\")\n",
    "pn_scedc_model = sbm.EQTransformer.from_pretrained(\"scedc\")\n",
    "pn_stead_model = sbm.EQTransformer.from_pretrained(\"stead\")\n",
    "pn_geofon_model = sbm.EQTransformer.from_pretrained(\"geofon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d1b67c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s_J57A[0].stats.sampling_rate\n",
    "dt = 1/fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba639a13",
   "metadata": {},
   "source": [
    "## Reshaping data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "873d0767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window data shape: (1439, 3, 6000)\n"
     ]
    }
   ],
   "source": [
    "sdata = np.array(s_J57A)\n",
    "npts = sdata.shape[1]\n",
    "nseg = int(np.ceil((npts - twin) / step)) + 1\n",
    "windows = np.zeros(shape=(nseg, 3, twin), dtype= np.float32)\n",
    "tap = 0.5 * (1 + np.cos(np.linspace(np.pi, 2 * np.pi, 6)))\n",
    "\n",
    "\n",
    "windows_std = np.zeros(shape=(nseg, 3, twin), dtype= np.float32)\n",
    "windows_max = np.zeros(shape=(nseg, 3, twin), dtype= np.float32)\n",
    "windows = np.zeros(shape=(nseg, 3, twin), dtype= np.float32)\n",
    "windows_idx = np.zeros(nseg, dtype=np.int32)\n",
    "\n",
    "for iseg in range(nseg):\n",
    "    idx = iseg * step\n",
    "    windows[iseg, :] = sdata[:, idx:idx + twin]\n",
    "    windows[iseg, :] -= np.mean(windows[iseg, :], axis=-1, keepdims=True)\n",
    "    # original use std norm\n",
    "    windows_std[iseg, :] = windows[iseg, :] / np.std(windows[iseg, :]) + 1e-10\n",
    "    # others use max norm\n",
    "    windows_max[iseg, :] = windows[iseg, :] / (np.max(np.abs(windows[iseg, :]), axis=-1, keepdims=True))\n",
    "    windows_idx[iseg] = idx\n",
    "\n",
    "# taper\n",
    "windows_std[:, :, :6] *= tap; windows_std[:, :, -6:] *= tap[::-1]; \n",
    "windows_max[:, :, :6] *= tap; windows_max[:, :, -6:] *= tap[::-1];\n",
    "del windows\n",
    "\n",
    "print(f\"Window data shape: {windows_std.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03da6fa",
   "metadata": {},
   "source": [
    "## Predict on base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69100be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picking using [original] model: 32.422 second\n",
      "picking using [ethz] model: 18.822 second\n",
      "picking using [instance] model: 17.925 second\n",
      "picking using [scedc] model: 18.933 second\n",
      "picking using [stead] model: 18.676 second\n",
      "All prediction shape: (2, 5, 1439, 6000)\n"
     ]
    }
   ],
   "source": [
    "pretrain_list = ['original', 'ethz', 'instance', 'scedc', 'stead']\n",
    "\n",
    "# dim 0: 0 = P, 1 = S\n",
    "batch_pred = np.zeros([2, len(pretrain_list), nseg, twin], dtype = np.float32) \n",
    "\n",
    "for ipre, pretrain in enumerate(pretrain_list):\n",
    "    t0 = time.time()\n",
    "    eqt = sbm.EQTransformer.from_pretrained(pretrain)\n",
    "    eqt.to(device);\n",
    "    eqt._annotate_args['overlap'] = ('Overlap between prediction windows in samples \\\n",
    "                                    (only for window prediction models)', step)\n",
    "    eqt._annotate_args['blinding'] = ('Number of prediction samples to discard on \\\n",
    "                                     each side of each window prediction', (l_blnd, r_blnd))\n",
    "    eqt.eval();\n",
    "    if pretrain == 'original':\n",
    "        # batch prediction through torch model\n",
    "        windows_std_tt = torch.Tensor(windows_std)\n",
    "        _torch_pred = eqt(windows_std_tt.to(device))\n",
    "    else:\n",
    "        windows_max_tt = torch.Tensor(windows_max)\n",
    "        _torch_pred = eqt(windows_max_tt.to(device))\n",
    "    batch_pred[0, ipre, :] = _torch_pred[1].detach().cpu().numpy()\n",
    "    batch_pred[1, ipre, :] = _torch_pred[2].detach().cpu().numpy()\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(f\"picking using [{pretrain}] model: %.3f second\" % (t1 - t0))\n",
    "    \n",
    "# clean up memory\n",
    "del _torch_pred, windows_max_tt, windows_std_tt\n",
    "del windows_std, windows_max\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"All prediction shape: {batch_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b17a4aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking(data, npts, l_blnd, r_blnd):\n",
    "    _data = data.copy()\n",
    "    stack = np.full(npts, np.nan, dtype = np.float32)\n",
    "    _data[:, :l_blnd] = np.nan; _data[:, -r_blnd:] = np.nan\n",
    "    stack[:twin] = _data[0, :]\n",
    "    for iseg in range(nseg-1):\n",
    "        idx = step*(iseg+1)\n",
    "        stack[idx:idx + twin] = \\\n",
    "                np.nanmax([stack[idx:idx + twin], _data[iseg+1, :]], axis = 0)\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee46d01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_986382/1491012717.py:9: RuntimeWarning: All-NaN axis encountered\n",
      "  np.nanmax([stack[idx:idx + twin], _data[iseg+1, :]], axis = 0)\n"
     ]
    }
   ],
   "source": [
    "pretrain_pred = np.zeros([2, len(pretrain_list), npts], dtype = np.float32)\n",
    "for ipre, pretrain in enumerate(pretrain_list):\n",
    "    # 0 for P-wave\n",
    "    pretrain_pred[0, ipre, :] = stacking(batch_pred[0, ipre, :], npts, l_blnd, r_blnd)\n",
    "    \n",
    "    # 1 for S-wave\n",
    "    pretrain_pred[1, ipre, :] = stacking(batch_pred[1, ipre, :], npts, l_blnd, r_blnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdb8e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paras_semblance = {'dt':dt, 'semblance_order':2, 'window_flag':True, \n",
    "                   'semblance_win':0.5, 'weight_flag':'max'}\n",
    "p_thrd, s_thrd = 0.05, 0.05\n",
    "\n",
    "smb_pred = np.zeros([2, nseg, twin], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c971c360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1439/1439 [01:24<00:00, 17.01it/s]\n",
      "/tmp/ipykernel_986382/1491012717.py:9: RuntimeWarning: All-NaN axis encountered\n",
      "  np.nanmax([stack[idx:idx + twin], _data[iseg+1, :]], axis = 0)\n"
     ]
    }
   ],
   "source": [
    "# calculate the semblance\n",
    "## the semblance may takes a while bit to calculate\n",
    "for iseg in tqdm(range(nseg)):\n",
    "    # 0 for P-wave\n",
    "    smb_pred[0, iseg, :] = ensemble_semblance(batch_pred[0, :, iseg, :], paras_semblance)\n",
    "    \n",
    "    # 1 for P-wave\n",
    "    smb_pred[1, iseg, :] = ensemble_semblance(batch_pred[1, :, iseg, :], paras_semblance)\n",
    "\n",
    "## ... and stack\n",
    "# 0 for P-wave\n",
    "smb_p = stacking(smb_pred[0, :], npts, l_blnd, r_blnd)\n",
    "\n",
    "# 1 for P-wave\n",
    "smb_s = stacking(smb_pred[1, :], npts, l_blnd, r_blnd)\n",
    "\n",
    "# clean-up RAM\n",
    "del smb_pred, batch_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d111ed",
   "metadata": {},
   "source": [
    "## Create a csv file\n",
    "- Create a dictionary and the keys for the station name, network,station latitude, station longitude, depth, P, S, pick time, \n",
    "- Create a dictionary and the keys for the station name, station_network_code, station_channel_code, station_latitude_deg, station_longitude_deg, source_depth_km, P, S, pick time, \n",
    "- The keys used in the CamCat dataset in the seisbench format:  event_id,source_origin_time,source_latitude_deg,source_longitude_deg,source_type,source_depth_km,preferred_source_magnitude,preferred_source_magnitude_type,preferred_source_magnitude_uncertainty,source_depth_uncertainty_km,source_horizontal_uncertainty_km,station_network_code,station_channel_code,station_code,station_location_code,station_latitude_deg,station_longitude_deg,station_elevation_m,trace_name,trace_sampling_rate_hz,trace_start_time,trace_S_arrival_sample,trace_P_arrival_sample,trace_S_arrival_uncertainty_s,trace_P_arrival_uncertainty_s,trace_P_polarity,trace_S_onset,trace_P_onset,trace_snr_db,source_type_pnsn_label,source_local_magnitude,source_local_magnitude_uncertainty,source_duration_magnitude,source_duration_magnitude_uncertainty,source_hand_magnitude,trace_missing_channel,trace_has_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a97e626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 P picks\n",
      "3 S picks\n"
     ]
    }
   ],
   "source": [
    "p_index = picks_summary_simple(smb_p, p_thrd)\n",
    "s_index = picks_summary_simple(smb_s, s_thrd)\n",
    "print(f\"{len(p_index)} P picks\\n{len(s_index)} S picks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf2e30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd8cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f15232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754776a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4907b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49656227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d7c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo-py38-shared"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
