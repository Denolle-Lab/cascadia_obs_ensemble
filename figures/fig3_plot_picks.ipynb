{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make plots of picks from ELEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from obspy import UTCDateTime,Stream\n",
    "from obspy.clients.fdsn import Client\n",
    "from pnwstore.mseed import WaveformClient\n",
    "# from obspy.geodetics import locations2degrees, degrees2kilometers\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "# from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "import time\n",
    "\n",
    "# notebook_dir = os.getcwd()\n",
    "# parent_dir = os.path.abspath(os.path.join(notebook_dir, '../utils/'))\n",
    "# if parent_dir not in sys.path:\n",
    "#     sys.path.append(parent_dir)\n",
    "# from plot_utils import *\n",
    "\n",
    "from obspy.geodetics import locations2degrees, degrees2kilometers\n",
    "\n",
    "\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import windows\n",
    "\n",
    "if not hasattr(signal, 'hann'):\n",
    "    signal.hann = windows.hann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory for this plot\n",
    "os.makedirs('/wd1/hbito_data/data/datasets_all_regions/fig3', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define clients\n",
    "client_iris = Client(\"IRIS\")\n",
    "client_pnw = WaveformClient()\n",
    "client_ncedc = Client('NCEDC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>depth</th>\n",
       "      <th>time</th>\n",
       "      <th>orid</th>\n",
       "      <th>nass</th>\n",
       "      <th>p_picks</th>\n",
       "      <th>s_picks</th>\n",
       "      <th>rms</th>\n",
       "      <th>nsphz</th>\n",
       "      <th>gap</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>id_Morton</th>\n",
       "      <th>dist</th>\n",
       "      <th>dt</th>\n",
       "      <th>NonDimDist</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>47.22533</td>\n",
       "      <td>-122.16895</td>\n",
       "      <td>56.111</td>\n",
       "      <td>1.262305e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.081</td>\n",
       "      <td>5.0</td>\n",
       "      <td>235.831208</td>\n",
       "      <td>genie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.753784</td>\n",
       "      <td>4.933721e+07</td>\n",
       "      <td>411143.414481</td>\n",
       "      <td>2010-01-01 00:15:17.262282+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48.19518</td>\n",
       "      <td>-121.77276</td>\n",
       "      <td>3.820</td>\n",
       "      <td>1.262305e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>0.985</td>\n",
       "      <td>30.0</td>\n",
       "      <td>201.698107</td>\n",
       "      <td>genie</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333054</td>\n",
       "      <td>4.933712e+07</td>\n",
       "      <td>411142.646872</td>\n",
       "      <td>2010-01-01 00:16:49.375360+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>47.86208</td>\n",
       "      <td>-122.09903</td>\n",
       "      <td>17.799</td>\n",
       "      <td>1.262330e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0.784</td>\n",
       "      <td>18.0</td>\n",
       "      <td>181.023074</td>\n",
       "      <td>genie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957326</td>\n",
       "      <td>4.931184e+07</td>\n",
       "      <td>410932.027590</td>\n",
       "      <td>2010-01-01 07:18:03.689209+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>47.96435</td>\n",
       "      <td>-122.91906</td>\n",
       "      <td>21.286</td>\n",
       "      <td>1.262336e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.465</td>\n",
       "      <td>10.0</td>\n",
       "      <td>150.528010</td>\n",
       "      <td>genie</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684951</td>\n",
       "      <td>4.930621e+07</td>\n",
       "      <td>410885.088574</td>\n",
       "      <td>2010-01-01 08:51:56.371091+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>45.87262</td>\n",
       "      <td>-122.19180</td>\n",
       "      <td>9.822</td>\n",
       "      <td>1.262362e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>0.657</td>\n",
       "      <td>19.0</td>\n",
       "      <td>237.324295</td>\n",
       "      <td>genie</td>\n",
       "      <td>0</td>\n",
       "      <td>1.627692</td>\n",
       "      <td>4.927976e+07</td>\n",
       "      <td>410664.693011</td>\n",
       "      <td>2010-01-01 16:12:43.838660+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63882</th>\n",
       "      <td>63882</td>\n",
       "      <td>40.59439</td>\n",
       "      <td>-124.42438</td>\n",
       "      <td>19.741</td>\n",
       "      <td>1.435097e+09</td>\n",
       "      <td>63882</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>1.015</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.959960</td>\n",
       "      <td>genie</td>\n",
       "      <td>4408</td>\n",
       "      <td>0.112501</td>\n",
       "      <td>7.919735e+03</td>\n",
       "      <td>65.997794</td>\n",
       "      <td>2015-06-23 22:11:15.735288+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63883</th>\n",
       "      <td>63883</td>\n",
       "      <td>40.54636</td>\n",
       "      <td>-127.10076</td>\n",
       "      <td>26.165</td>\n",
       "      <td>1.435100e+09</td>\n",
       "      <td>63883</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.744</td>\n",
       "      <td>11.0</td>\n",
       "      <td>223.080984</td>\n",
       "      <td>genie</td>\n",
       "      <td>4408</td>\n",
       "      <td>2.139193</td>\n",
       "      <td>9.995899e+03</td>\n",
       "      <td>83.299204</td>\n",
       "      <td>2015-06-23 22:45:51.899203+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63884</th>\n",
       "      <td>63884</td>\n",
       "      <td>49.74167</td>\n",
       "      <td>-124.58578</td>\n",
       "      <td>5.274</td>\n",
       "      <td>1.435101e+09</td>\n",
       "      <td>63884</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.894</td>\n",
       "      <td>6.0</td>\n",
       "      <td>197.904075</td>\n",
       "      <td>genie</td>\n",
       "      <td>4408</td>\n",
       "      <td>9.188393</td>\n",
       "      <td>1.107364e+04</td>\n",
       "      <td>92.281049</td>\n",
       "      <td>2015-06-23 23:03:49.638010+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63885</th>\n",
       "      <td>63885</td>\n",
       "      <td>40.64363</td>\n",
       "      <td>-125.36531</td>\n",
       "      <td>1.891</td>\n",
       "      <td>1.435101e+09</td>\n",
       "      <td>63885</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.982</td>\n",
       "      <td>5.0</td>\n",
       "      <td>145.748415</td>\n",
       "      <td>genie</td>\n",
       "      <td>4408</td>\n",
       "      <td>0.824720</td>\n",
       "      <td>1.158579e+04</td>\n",
       "      <td>96.548245</td>\n",
       "      <td>2015-06-23 23:12:21.788775+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63886</th>\n",
       "      <td>63886</td>\n",
       "      <td>43.37085</td>\n",
       "      <td>-127.35251</td>\n",
       "      <td>5.915</td>\n",
       "      <td>1.435101e+09</td>\n",
       "      <td>63886</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.447</td>\n",
       "      <td>5.0</td>\n",
       "      <td>247.683119</td>\n",
       "      <td>genie</td>\n",
       "      <td>4408</td>\n",
       "      <td>3.622500</td>\n",
       "      <td>1.194284e+04</td>\n",
       "      <td>99.523782</td>\n",
       "      <td>2015-06-23 23:18:18.841147+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63887 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       lat        lon   depth          time   orid  nass  \\\n",
       "0               0  47.22533 -122.16895  56.111  1.262305e+09      0     7   \n",
       "1               1  48.19518 -121.77276   3.820  1.262305e+09      1    55   \n",
       "2               2  47.86208 -122.09903  17.799  1.262330e+09      2    28   \n",
       "3               3  47.96435 -122.91906  21.286  1.262336e+09      3    20   \n",
       "4               4  45.87262 -122.19180   9.822  1.262362e+09      4    39   \n",
       "...           ...       ...        ...     ...           ...    ...   ...   \n",
       "63882       63882  40.59439 -124.42438  19.741  1.435097e+09  63882    23   \n",
       "63883       63883  40.54636 -127.10076  26.165  1.435100e+09  63883    12   \n",
       "63884       63884  49.74167 -124.58578   5.274  1.435101e+09  63884    13   \n",
       "63885       63885  40.64363 -125.36531   1.891  1.435101e+09  63885     8   \n",
       "63886       63886  43.37085 -127.35251   5.915  1.435101e+09  63886     9   \n",
       "\n",
       "       p_picks  s_picks    rms  nsphz         gap algorithm  id_Morton  \\\n",
       "0            2        5  1.081    5.0  235.831208     genie          0   \n",
       "1           25       30  0.985   30.0  201.698107     genie          0   \n",
       "2           10       18  0.784   18.0  181.023074     genie          0   \n",
       "3           10       10  0.465   10.0  150.528010     genie          0   \n",
       "4           20       19  0.657   19.0  237.324295     genie          0   \n",
       "...        ...      ...    ...    ...         ...       ...        ...   \n",
       "63882        9       14  1.015   14.0   73.959960     genie       4408   \n",
       "63883        1       11  0.744   11.0  223.080984     genie       4408   \n",
       "63884        7        6  0.894    6.0  197.904075     genie       4408   \n",
       "63885        3        5  0.982    5.0  145.748415     genie       4408   \n",
       "63886        4        5  0.447    5.0  247.683119     genie       4408   \n",
       "\n",
       "           dist            dt     NonDimDist                         datetime  \n",
       "0      0.753784  4.933721e+07  411143.414481 2010-01-01 00:15:17.262282+00:00  \n",
       "1      1.333054  4.933712e+07  411142.646872 2010-01-01 00:16:49.375360+00:00  \n",
       "2      0.957326  4.931184e+07  410932.027590 2010-01-01 07:18:03.689209+00:00  \n",
       "3      0.684951  4.930621e+07  410885.088574 2010-01-01 08:51:56.371091+00:00  \n",
       "4      1.627692  4.927976e+07  410664.693011 2010-01-01 16:12:43.838660+00:00  \n",
       "...         ...           ...            ...                              ...  \n",
       "63882  0.112501  7.919735e+03      65.997794 2015-06-23 22:11:15.735288+00:00  \n",
       "63883  2.139193  9.995899e+03      83.299204 2015-06-23 22:45:51.899203+00:00  \n",
       "63884  9.188393  1.107364e+04      92.281049 2015-06-23 23:03:49.638010+00:00  \n",
       "63885  0.824720  1.158579e+04      96.548245 2015-06-23 23:12:21.788775+00:00  \n",
       "63886  3.622500  1.194284e+04      99.523782 2015-06-23 23:18:18.841147+00:00  \n",
       "\n",
       "[63887 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = pd.read_csv('/wd1/hbito_data/data/datasets_all_regions/origin_2010_2015_reloc_cog_morton_ver3.csv')\n",
    "_df['datetime'] = _df.apply(lambda a: datetime.fromtimestamp(a['time'], tz=timezone.utc), axis=1)\n",
    "_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load catalogs from Morton (2023) and ANSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CI YEAR</th>\n",
       "      <th>TSTRING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>SECOND</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>...</th>\n",
       "      <th>dist to nearest stn</th>\n",
       "      <th>tt RMS</th>\n",
       "      <th>ERH</th>\n",
       "      <th>ERZ</th>\n",
       "      <th>STRIKE</th>\n",
       "      <th>DIP</th>\n",
       "      <th>RAKE</th>\n",
       "      <th>PLATE DESIGNATION</th>\n",
       "      <th>TEMPLATE EVENT?</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.37</td>\n",
       "      <td>47.3217</td>\n",
       "      <td>-123.2708</td>\n",
       "      <td>...</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interface</td>\n",
       "      <td>Catalog</td>\n",
       "      <td>2011-07-26 01:02:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.72</td>\n",
       "      <td>44.2888</td>\n",
       "      <td>-124.3340</td>\n",
       "      <td>...</td>\n",
       "      <td>163.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>13.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-26 01:02:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>44.3017</td>\n",
       "      <td>-124.3180</td>\n",
       "      <td>...</td>\n",
       "      <td>131.1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>35.4</td>\n",
       "      <td>22.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-26 01:02:08+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.17</td>\n",
       "      <td>48.2635</td>\n",
       "      <td>-124.9298</td>\n",
       "      <td>...</td>\n",
       "      <td>44.4</td>\n",
       "      <td>0.77</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-26 07:31:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.63</td>\n",
       "      <td>48.3032</td>\n",
       "      <td>-124.9157</td>\n",
       "      <td>...</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>T</td>\n",
       "      <td>2011-07-26 09:50:27+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CI YEAR       TSTRING    YEAR  MONTH   DAY  HOUR  MINUTE  SECOND      LAT  \\\n",
       "0      1.0  2.011073e+13  2011.0    7.0  26.0   1.0     2.0    7.37  47.3217   \n",
       "1      1.0  2.011073e+13  2011.0    7.0  26.0   1.0     2.0    7.72  44.2888   \n",
       "2      1.0  2.011073e+13  2011.0    7.0  26.0   1.0     2.0    8.56  44.3017   \n",
       "3      1.0  2.011073e+13  2011.0    7.0  26.0   7.0    31.0    2.17  48.2635   \n",
       "4      1.0  2.011073e+13  2011.0    7.0  26.0   9.0    50.0   27.63  48.3032   \n",
       "\n",
       "        LON  ...  dist to nearest stn  tt RMS   ERH   ERZ  STRIKE  DIP  RAKE  \\\n",
       "0 -123.2708  ...                 27.4    0.19   0.8   1.2     NaN  NaN   NaN   \n",
       "1 -124.3340  ...                163.8    0.06  13.1   3.2     NaN  NaN   NaN   \n",
       "2 -124.3180  ...                131.1    0.50  35.4  22.2     NaN  NaN   NaN   \n",
       "3 -124.9298  ...                 44.4    0.77   3.5   6.4     NaN  NaN   NaN   \n",
       "4 -124.9157  ...                 46.1    0.94   4.0   6.9     NaN  NaN   NaN   \n",
       "\n",
       "   PLATE DESIGNATION  TEMPLATE EVENT?                  datetime  \n",
       "0          Interface          Catalog 2011-07-26 01:02:07+00:00  \n",
       "1        Upper Plate              NaN 2011-07-26 01:02:07+00:00  \n",
       "2        Upper Plate              NaN 2011-07-26 01:02:08+00:00  \n",
       "3        Upper Plate              NaN 2011-07-26 07:31:02+00:00  \n",
       "4        Upper Plate                T 2011-07-26 09:50:27+00:00  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Morton's catalog\n",
    "events_morton = pd.read_csv('../data/ds01.csv')\n",
    "# Convert the TSTRING to datetime\n",
    "events_morton['datetime'] = pd.to_datetime(events_morton['TSTRING'], format='%Y%m%d%H%M%S', utc=True)\n",
    "# Get the events in the Morton catalog \n",
    "# t1 = pd.Timestamp('2011-1-1 00:00:00.000000+0000', tz='UTC')\n",
    "# t2 = pd.Timestamp('2015-12-31 23:59:59.999999+0000', tz='UTC')\n",
    "\n",
    "# events_morton= events_morton.loc[(events_morton['datetime'] > t1) & (events_morton['datetime'] < t2) ]\n",
    "\n",
    "events_morton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010-01-01T00:16:49.190Z</td>\n",
       "      <td>48.203167</td>\n",
       "      <td>-121.676833</td>\n",
       "      <td>2.948</td>\n",
       "      <td>2.20</td>\n",
       "      <td>md</td>\n",
       "      <td>16.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>...</td>\n",
       "      <td>8 km SW of Darrington, Washington</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>1.004</td>\n",
       "      <td>12.60</td>\n",
       "      <td>0.070</td>\n",
       "      <td>9.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>uw</td>\n",
       "      <td>uw</td>\n",
       "      <td>2010-01-01 00:16:49.190000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-01T01:09:53.550Z</td>\n",
       "      <td>38.755167</td>\n",
       "      <td>-122.717167</td>\n",
       "      <td>1.604</td>\n",
       "      <td>0.20</td>\n",
       "      <td>md</td>\n",
       "      <td>9.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>...</td>\n",
       "      <td>7 km S of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.175</td>\n",
       "      <td>4.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2010-01-01 01:09:53.550000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2010-01-01T01:28:40.410Z</td>\n",
       "      <td>38.824167</td>\n",
       "      <td>-122.814667</td>\n",
       "      <td>1.479</td>\n",
       "      <td>0.29</td>\n",
       "      <td>md</td>\n",
       "      <td>15.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>...</td>\n",
       "      <td>7 km W of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.273</td>\n",
       "      <td>4.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2010-01-01 01:28:40.410000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-01-01T01:28:44.590Z</td>\n",
       "      <td>38.825500</td>\n",
       "      <td>-122.815333</td>\n",
       "      <td>1.859</td>\n",
       "      <td>0.65</td>\n",
       "      <td>md</td>\n",
       "      <td>7.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>...</td>\n",
       "      <td>8 km W of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>1.220</td>\n",
       "      <td>1.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2010-01-01 01:28:44.590000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2010-01-01T01:45:21.220Z</td>\n",
       "      <td>38.813332</td>\n",
       "      <td>-122.785500</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.97</td>\n",
       "      <td>md</td>\n",
       "      <td>15.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>...</td>\n",
       "      <td>5 km W of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.120</td>\n",
       "      <td>16.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2010-01-01 01:45:21.220000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151785</th>\n",
       "      <td>151785</td>\n",
       "      <td>2015-12-31T22:15:46.650Z</td>\n",
       "      <td>38.837502</td>\n",
       "      <td>-122.825333</td>\n",
       "      <td>1.450</td>\n",
       "      <td>0.18</td>\n",
       "      <td>md</td>\n",
       "      <td>6.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>...</td>\n",
       "      <td>9 km W of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.660</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.110</td>\n",
       "      <td>2.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2015-12-31 22:15:46.650000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151786</th>\n",
       "      <td>151786</td>\n",
       "      <td>2015-12-31T22:18:13.120Z</td>\n",
       "      <td>41.856400</td>\n",
       "      <td>-119.599200</td>\n",
       "      <td>8.700</td>\n",
       "      <td>1.40</td>\n",
       "      <td>ml</td>\n",
       "      <td>6.0</td>\n",
       "      <td>210.1</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>...</td>\n",
       "      <td>45 km E of Fort Bidwell, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.210</td>\n",
       "      <td>3.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>2015-12-31 22:18:13.120000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151787</th>\n",
       "      <td>151787</td>\n",
       "      <td>2015-12-31T23:19:21.650Z</td>\n",
       "      <td>38.823334</td>\n",
       "      <td>-122.765663</td>\n",
       "      <td>1.680</td>\n",
       "      <td>0.54</td>\n",
       "      <td>md</td>\n",
       "      <td>7.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>...</td>\n",
       "      <td>3 km W of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2015-12-31 23:19:21.650000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151788</th>\n",
       "      <td>151788</td>\n",
       "      <td>2015-12-31T23:22:20.730Z</td>\n",
       "      <td>38.841000</td>\n",
       "      <td>-122.878166</td>\n",
       "      <td>1.730</td>\n",
       "      <td>0.77</td>\n",
       "      <td>md</td>\n",
       "      <td>8.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>...</td>\n",
       "      <td>12 km ENE of Cloverdale, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.580</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.180</td>\n",
       "      <td>3.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2015-12-31 23:22:20.730000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151789</th>\n",
       "      <td>151789</td>\n",
       "      <td>2015-12-31T23:53:17.350Z</td>\n",
       "      <td>40.457667</td>\n",
       "      <td>-124.763000</td>\n",
       "      <td>24.960</td>\n",
       "      <td>2.32</td>\n",
       "      <td>md</td>\n",
       "      <td>16.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>0.325200</td>\n",
       "      <td>...</td>\n",
       "      <td>44 km WSW of Ferndale, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4.72</td>\n",
       "      <td>0.324</td>\n",
       "      <td>18.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2015-12-31 23:53:17.350000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151790 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                      time   latitude   longitude   depth  \\\n",
       "0                0  2010-01-01T00:16:49.190Z  48.203167 -121.676833   2.948   \n",
       "1                1  2010-01-01T01:09:53.550Z  38.755167 -122.717167   1.604   \n",
       "2                2  2010-01-01T01:28:40.410Z  38.824167 -122.814667   1.479   \n",
       "3                3  2010-01-01T01:28:44.590Z  38.825500 -122.815333   1.859   \n",
       "4                4  2010-01-01T01:45:21.220Z  38.813332 -122.785500   0.739   \n",
       "...            ...                       ...        ...         ...     ...   \n",
       "151785      151785  2015-12-31T22:15:46.650Z  38.837502 -122.825333   1.450   \n",
       "151786      151786  2015-12-31T22:18:13.120Z  41.856400 -119.599200   8.700   \n",
       "151787      151787  2015-12-31T23:19:21.650Z  38.823334 -122.765663   1.680   \n",
       "151788      151788  2015-12-31T23:22:20.730Z  38.841000 -122.878166   1.730   \n",
       "151789      151789  2015-12-31T23:53:17.350Z  40.457667 -124.763000  24.960   \n",
       "\n",
       "         mag magType   nst    gap      dmin  ...  \\\n",
       "0       2.20      md  16.0   79.0  0.167900  ...   \n",
       "1       0.20      md   9.0   67.0  0.015320  ...   \n",
       "2       0.29      md  15.0   90.0  0.003604  ...   \n",
       "3       0.65      md   7.0  106.0  0.004505  ...   \n",
       "4       0.97      md  15.0   56.0  0.009009  ...   \n",
       "...      ...     ...   ...    ...       ...  ...   \n",
       "151785  0.18      md   6.0  180.0  0.008108  ...   \n",
       "151786  1.40      ml   6.0  210.1  0.175000  ...   \n",
       "151787  0.54      md   7.0   99.0  0.008108  ...   \n",
       "151788  0.77      md   8.0   95.0  0.007207  ...   \n",
       "151789  2.32      md  16.0  301.0  0.325200  ...   \n",
       "\n",
       "                                      place        type horizontalError  \\\n",
       "0         8 km SW of Darrington, Washington  earthquake           1.004   \n",
       "1                7 km S of Cobb, California  earthquake           0.500   \n",
       "2                7 km W of Cobb, California  earthquake           0.250   \n",
       "3                8 km W of Cobb, California  earthquake           1.220   \n",
       "4                5 km W of Cobb, California  earthquake           0.200   \n",
       "...                                     ...         ...             ...   \n",
       "151785           9 km W of Cobb, California  earthquake           0.660   \n",
       "151786  45 km E of Fort Bidwell, California  earthquake             NaN   \n",
       "151787           3 km W of Cobb, California  earthquake           0.500   \n",
       "151788  12 km ENE of Cloverdale, California  earthquake           0.580   \n",
       "151789    44 km WSW of Ferndale, California  earthquake           0.990   \n",
       "\n",
       "       depthError magError magNst     status  locationSource  magSource  \\\n",
       "0           12.60    0.070    9.0   reviewed              uw         uw   \n",
       "1            1.19    0.175    4.0   reviewed              nc         nc   \n",
       "2            0.33    0.273    4.0   reviewed              nc         nc   \n",
       "3            1.78      NaN    1.0   reviewed              nc         nc   \n",
       "4            0.49    0.120   16.0  automatic              nc         nc   \n",
       "...           ...      ...    ...        ...             ...        ...   \n",
       "151785       1.08    0.110    2.0  automatic              nc         nc   \n",
       "151786       3.40    0.210    3.0   reviewed              nn         nn   \n",
       "151787       1.54    0.030    2.0  automatic              nc         nc   \n",
       "151788       1.02    0.180    3.0  automatic              nc         nc   \n",
       "151789       4.72    0.324   18.0   reviewed              nc         nc   \n",
       "\n",
       "                               datetime  \n",
       "0      2010-01-01 00:16:49.190000+00:00  \n",
       "1      2010-01-01 01:09:53.550000+00:00  \n",
       "2      2010-01-01 01:28:40.410000+00:00  \n",
       "3      2010-01-01 01:28:44.590000+00:00  \n",
       "4      2010-01-01 01:45:21.220000+00:00  \n",
       "...                                 ...  \n",
       "151785 2015-12-31 22:15:46.650000+00:00  \n",
       "151786 2015-12-31 22:18:13.120000+00:00  \n",
       "151787 2015-12-31 23:19:21.650000+00:00  \n",
       "151788 2015-12-31 23:22:20.730000+00:00  \n",
       "151789 2015-12-31 23:53:17.350000+00:00  \n",
       "\n",
       "[151790 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_anss = pd.read_csv('/wd1/hbito_data/data/datasets_anss/anss_2010-15.csv')\n",
    "events_anss['datetime'] = pd.to_datetime(events_anss['time'], format='%Y-%m-%dT%H:%M:%S.%fZ', utc=True)\n",
    "# events_anss= events_anss.loc[(events_anss['datetime'] > t1) & (events_anss['datetime'] < t2) ]\n",
    "events_anss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>depth</th>\n",
       "      <th>time</th>\n",
       "      <th>orid</th>\n",
       "      <th>nass</th>\n",
       "      <th>p_picks</th>\n",
       "      <th>s_picks</th>\n",
       "      <th>rms</th>\n",
       "      <th>nsphz</th>\n",
       "      <th>gap</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>id_Morton</th>\n",
       "      <th>dist</th>\n",
       "      <th>dt</th>\n",
       "      <th>NonDimDist</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52800</th>\n",
       "      <td>52800</td>\n",
       "      <td>46.97998</td>\n",
       "      <td>-124.75515</td>\n",
       "      <td>15.409</td>\n",
       "      <td>1.413533e+09</td>\n",
       "      <td>52800</td>\n",
       "      <td>81</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>0.96</td>\n",
       "      <td>43.0</td>\n",
       "      <td>83.470991</td>\n",
       "      <td>genie</td>\n",
       "      <td>2513</td>\n",
       "      <td>6.569731</td>\n",
       "      <td>9487.333491</td>\n",
       "      <td>79.061549</td>\n",
       "      <td>2014-10-17 07:58:38.666509+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       lat        lon   depth          time   orid  nass  \\\n",
       "52800       52800  46.97998 -124.75515  15.409  1.413533e+09  52800    81   \n",
       "\n",
       "       p_picks  s_picks   rms  nsphz        gap algorithm  id_Morton  \\\n",
       "52800       38       43  0.96   43.0  83.470991     genie       2513   \n",
       "\n",
       "           dist           dt  NonDimDist                         datetime  \n",
       "52800  6.569731  9487.333491   79.061549 2014-10-17 07:58:38.666509+00:00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good location: Offshore WA\n",
    "event_a = _df.loc[(_df['lat']>=46.97)&(_df['lat']<=46.99)&(_df['lon']<=-124.74)&(_df['lon']>=-124.76)]\n",
    "event_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CI YEAR</th>\n",
       "      <th>TSTRING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>SECOND</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>...</th>\n",
       "      <th>dist to nearest stn</th>\n",
       "      <th>tt RMS</th>\n",
       "      <th>ERH</th>\n",
       "      <th>ERZ</th>\n",
       "      <th>STRIKE</th>\n",
       "      <th>DIP</th>\n",
       "      <th>RAKE</th>\n",
       "      <th>PLATE DESIGNATION</th>\n",
       "      <th>TEMPLATE EVENT?</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CI YEAR, TSTRING, YEAR, MONTH, DAY, HOUR, MINUTE, SECOND, LAT, LON, DEPTH, Md, Num P&S with weights > 0.1, max az gap, dist to nearest stn, tt RMS, ERH, ERZ, STRIKE, DIP, RAKE, PLATE DESIGNATION, TEMPLATE EVENT?, datetime]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Localize (not convert) the naive timestamp to UTC\n",
    "time_center = pd.to_datetime(event_a['datetime'].values[0]).tz_localize('UTC')\n",
    "time_window = pd.to_timedelta(120, unit='s')\n",
    "\n",
    "# Apply mask to timezone-aware datetimes\n",
    "mask = (events_morton['datetime'] >= time_center - time_window) & \\\n",
    "       (events_morton['datetime'] <= time_center + time_window)\n",
    "\n",
    "events_morton.loc[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119619</th>\n",
       "      <td>119619</td>\n",
       "      <td>2014-10-17T07:58:38.470Z</td>\n",
       "      <td>46.965167</td>\n",
       "      <td>-124.867833</td>\n",
       "      <td>39.643</td>\n",
       "      <td>1.59</td>\n",
       "      <td>md</td>\n",
       "      <td>18.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.7488</td>\n",
       "      <td>...</td>\n",
       "      <td>54 km W of Oyehut, Washington</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.107</td>\n",
       "      <td>5.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>uw</td>\n",
       "      <td>uw</td>\n",
       "      <td>2014-10-17 07:58:38.470000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                      time   latitude   longitude   depth  \\\n",
       "119619      119619  2014-10-17T07:58:38.470Z  46.965167 -124.867833  39.643   \n",
       "\n",
       "         mag magType   nst    gap    dmin  ...                          place  \\\n",
       "119619  1.59      md  18.0  244.0  0.7488  ...  54 km W of Oyehut, Washington   \n",
       "\n",
       "              type horizontalError depthError magError magNst    status  \\\n",
       "119619  earthquake            2.02       0.96    0.107    5.0  reviewed   \n",
       "\n",
       "        locationSource  magSource                         datetime  \n",
       "119619              uw         uw 2014-10-17 07:58:38.470000+00:00  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Localize (not convert) the naive timestamp to UTC\n",
    "time_center = pd.to_datetime(event_a['datetime'].values[0]).tz_localize('UTC')\n",
    "time_window = pd.to_timedelta(120, unit='s')\n",
    "\n",
    "# Apply mask to timezone-aware datetimes\n",
    "mask = (events_anss['datetime'] >= time_center - time_window) & \\\n",
    "       (events_anss['datetime'] <= time_center + time_window)\n",
    "\n",
    "events_anss.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                               20052\n",
       "lat                                   44.38373\n",
       "lon                                 -124.46256\n",
       "depth                                   10.063\n",
       "time                         1332235717.680858\n",
       "orid                                     20052\n",
       "nass                                        80\n",
       "p_picks                                     43\n",
       "s_picks                                     37\n",
       "rms                                      1.206\n",
       "nsphz                                     37.0\n",
       "gap                                  70.022537\n",
       "algorithm                                genie\n",
       "id_Morton                                  194\n",
       "dist                                  0.048454\n",
       "dt                                    0.680858\n",
       "NonDimDist                            0.005996\n",
       "datetime      2012-03-20 09:28:37.680858+00:00\n",
       "Name: 20052, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good location: Offshore OR\n",
    "event_b = _df.loc[(_df['lat']>=44.37)&(_df['lat']<=44.39)&(_df['lon']<=-124.45)&(_df['lon']>=-124.47)].iloc[2]\n",
    "event_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CI YEAR</th>\n",
       "      <th>TSTRING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>SECOND</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>...</th>\n",
       "      <th>dist to nearest stn</th>\n",
       "      <th>tt RMS</th>\n",
       "      <th>ERH</th>\n",
       "      <th>ERZ</th>\n",
       "      <th>STRIKE</th>\n",
       "      <th>DIP</th>\n",
       "      <th>RAKE</th>\n",
       "      <th>PLATE DESIGNATION</th>\n",
       "      <th>TEMPLATE EVENT?</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.012032e+13</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>44.3517</td>\n",
       "      <td>-124.4117</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interface</td>\n",
       "      <td>T</td>\n",
       "      <td>2012-03-20 09:28:37+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CI YEAR       TSTRING    YEAR  MONTH   DAY  HOUR  MINUTE  SECOND  \\\n",
       "194      1.0  2.012032e+13  2012.0    3.0  20.0   9.0    28.0    37.0   \n",
       "\n",
       "         LAT       LON  ...  dist to nearest stn  tt RMS  ERH  ERZ  STRIKE  \\\n",
       "194  44.3517 -124.4117  ...                 21.5    0.42  0.9  2.0     NaN   \n",
       "\n",
       "     DIP  RAKE  PLATE DESIGNATION  TEMPLATE EVENT?                  datetime  \n",
       "194  NaN   NaN          Interface                T 2012-03-20 09:28:37+00:00  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Localize (not convert) the naive timestamp to UTC\n",
    "time_center = pd.to_datetime(event_b['datetime'])\n",
    "time_window = pd.to_timedelta(120, unit='s')\n",
    "\n",
    "# Apply mask to timezone-aware datetimes\n",
    "mask = (events_morton['datetime'] >= time_center - time_window) & \\\n",
    "       (events_morton['datetime'] <= time_center + time_window)\n",
    "\n",
    "events_morton.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52043</th>\n",
       "      <td>52043</td>\n",
       "      <td>2012-03-20T09:28:37.350Z</td>\n",
       "      <td>44.383333</td>\n",
       "      <td>-124.456333</td>\n",
       "      <td>32.93</td>\n",
       "      <td>3.7</td>\n",
       "      <td>ml</td>\n",
       "      <td>16.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.3795</td>\n",
       "      <td>...</td>\n",
       "      <td>29 km WNW of Yachats, Oregon</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.18</td>\n",
       "      <td>82.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>uw</td>\n",
       "      <td>uw</td>\n",
       "      <td>2012-03-20 09:28:37.350000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                      time   latitude   longitude  depth  \\\n",
       "52043       52043  2012-03-20T09:28:37.350Z  44.383333 -124.456333  32.93   \n",
       "\n",
       "       mag magType   nst    gap    dmin  ...                         place  \\\n",
       "52043  3.7      ml  16.0  228.0  0.3795  ...  29 km WNW of Yachats, Oregon   \n",
       "\n",
       "             type horizontalError depthError magError magNst    status  \\\n",
       "52043  earthquake            0.81       1.07     0.18   82.0  reviewed   \n",
       "\n",
       "       locationSource  magSource                         datetime  \n",
       "52043              uw         uw 2012-03-20 09:28:37.350000+00:00  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Localize (not convert) the naive timestamp to UTC\n",
    "time_center = pd.to_datetime(event_b['datetime'])\n",
    "time_window = pd.to_timedelta(120, unit='s')\n",
    "\n",
    "# Apply mask to timezone-aware datetimes\n",
    "mask = (events_anss['datetime'] >= time_center - time_window) & \\\n",
    "       (events_anss['datetime'] <= time_center + time_window)\n",
    "\n",
    "events_anss.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>depth</th>\n",
       "      <th>time</th>\n",
       "      <th>orid</th>\n",
       "      <th>nass</th>\n",
       "      <th>p_picks</th>\n",
       "      <th>s_picks</th>\n",
       "      <th>rms</th>\n",
       "      <th>nsphz</th>\n",
       "      <th>gap</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>id_Morton</th>\n",
       "      <th>dist</th>\n",
       "      <th>dt</th>\n",
       "      <th>NonDimDist</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55331</th>\n",
       "      <td>55331</td>\n",
       "      <td>40.85222</td>\n",
       "      <td>-123.3666</td>\n",
       "      <td>26.107</td>\n",
       "      <td>1.418415e+09</td>\n",
       "      <td>55331</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1.586</td>\n",
       "      <td>12.0</td>\n",
       "      <td>102.274632</td>\n",
       "      <td>genie</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.047893</td>\n",
       "      <td>1.349966</td>\n",
       "      <td>0.011412</td>\n",
       "      <td>2014-12-12 20:16:44.349966+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       lat       lon   depth          time   orid  nass  \\\n",
       "55331       55331  40.85222 -123.3666  26.107  1.418415e+09  55331    22   \n",
       "\n",
       "       p_picks  s_picks    rms  nsphz         gap algorithm  id_Morton  \\\n",
       "55331       10       12  1.586   12.0  102.274632     genie       2924   \n",
       "\n",
       "           dist        dt  NonDimDist                         datetime  \n",
       "55331  0.047893  1.349966    0.011412 2014-12-12 20:16:44.349966+00:00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good location: Northern California\n",
    "event_c = _df.loc[(_df['lat']>=40.84)&(_df['lat']<=40.86)&(_df['lon']<=-123.36)&(_df['lon']>=-123.38)]\n",
    "event_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CI YEAR</th>\n",
       "      <th>TSTRING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>SECOND</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>...</th>\n",
       "      <th>dist to nearest stn</th>\n",
       "      <th>tt RMS</th>\n",
       "      <th>ERH</th>\n",
       "      <th>ERZ</th>\n",
       "      <th>STRIKE</th>\n",
       "      <th>DIP</th>\n",
       "      <th>RAKE</th>\n",
       "      <th>PLATE DESIGNATION</th>\n",
       "      <th>TEMPLATE EVENT?</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.014121e+13</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>43.27</td>\n",
       "      <td>40.888</td>\n",
       "      <td>-123.3245</td>\n",
       "      <td>...</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>164.24</td>\n",
       "      <td>63.48</td>\n",
       "      <td>26.76</td>\n",
       "      <td>Interface</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-12-12 20:16:43+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CI YEAR       TSTRING    YEAR  MONTH   DAY  HOUR  MINUTE  SECOND  \\\n",
       "2924      4.0  2.014121e+13  2014.0   12.0  12.0  20.0    16.0   43.27   \n",
       "\n",
       "         LAT       LON  ...  dist to nearest stn  tt RMS  ERH  ERZ  STRIKE  \\\n",
       "2924  40.888 -123.3245  ...                 26.8     0.1  0.6  1.4  164.24   \n",
       "\n",
       "        DIP   RAKE  PLATE DESIGNATION  TEMPLATE EVENT?  \\\n",
       "2924  63.48  26.76          Interface              NaN   \n",
       "\n",
       "                      datetime  \n",
       "2924 2014-12-12 20:16:43+00:00  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Localize (not convert) the naive timestamp to UTC\n",
    "time_center = pd.to_datetime(event_c['datetime'].values[0]).tz_localize('UTC')\n",
    "time_window = pd.to_timedelta(120, unit='s')\n",
    "\n",
    "# Apply mask to timezone-aware datetimes\n",
    "mask = (events_morton['datetime'] >= time_center - time_window) & \\\n",
    "       (events_morton['datetime'] <= time_center + time_window)\n",
    "\n",
    "events_morton.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource, datetime]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Localize (not convert) the naive timestamp to UTC\n",
    "time_center = pd.to_datetime(event_c['datetime'].values[0]).tz_localize('UTC')\n",
    "time_window = pd.to_timedelta(120, unit='s')\n",
    "\n",
    "# Apply mask to timezone-aware datetimes\n",
    "mask = (events_anss['datetime'] >= time_center - time_window) & \\\n",
    "       (events_anss['datetime'] <= time_center + time_window)\n",
    "\n",
    "events_anss.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                 535\n",
       "lat                                   40.53275\n",
       "lon                                 -124.73816\n",
       "depth                                   11.093\n",
       "time                         1263264837.458611\n",
       "orid                                       535\n",
       "nass                                         8\n",
       "p_picks                                      3\n",
       "s_picks                                      5\n",
       "rms                                        0.2\n",
       "nsphz                                      5.0\n",
       "gap                                 258.774701\n",
       "algorithm                                genie\n",
       "id_Morton                                    1\n",
       "dist                                   3.76787\n",
       "dt                             48377289.541389\n",
       "NonDimDist                       403144.079512\n",
       "datetime      2010-01-12 02:53:57.458611+00:00\n",
       "Name: 535, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inaccurate picks: Northern California\n",
    "event_d = _df.loc[(_df['lat']>=40.52)&(_df['lat']<=40.54)&(_df['lon']<=-124.73)&(_df['lon']>=-124.75)].iloc[3]\n",
    "event_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CI YEAR</th>\n",
       "      <th>TSTRING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>SECOND</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>...</th>\n",
       "      <th>dist to nearest stn</th>\n",
       "      <th>tt RMS</th>\n",
       "      <th>ERH</th>\n",
       "      <th>ERZ</th>\n",
       "      <th>STRIKE</th>\n",
       "      <th>DIP</th>\n",
       "      <th>RAKE</th>\n",
       "      <th>PLATE DESIGNATION</th>\n",
       "      <th>TEMPLATE EVENT?</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CI YEAR, TSTRING, YEAR, MONTH, DAY, HOUR, MINUTE, SECOND, LAT, LON, DEPTH, Md, Num P&S with weights > 0.1, max az gap, dist to nearest stn, tt RMS, ERH, ERZ, STRIKE, DIP, RAKE, PLATE DESIGNATION, TEMPLATE EVENT?, datetime]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Localize (not convert) the naive timestamp to UTC\n",
    "time_center = pd.to_datetime(event_d['datetime'])\n",
    "time_window = pd.to_timedelta(120, unit='s')\n",
    "\n",
    "# Apply mask to timezone-aware datetimes\n",
    "mask = (events_morton['datetime'] >= time_center - time_window) & \\\n",
    "       (events_morton['datetime'] <= time_center + time_window)\n",
    "\n",
    "events_morton.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>640</td>\n",
       "      <td>2010-01-12T02:53:36.370Z</td>\n",
       "      <td>40.5075</td>\n",
       "      <td>-124.882</td>\n",
       "      <td>14.078</td>\n",
       "      <td>3.18</td>\n",
       "      <td>ml</td>\n",
       "      <td>37.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.4162</td>\n",
       "      <td>...</td>\n",
       "      <td>52 km W of Ferndale, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.165</td>\n",
       "      <td>17.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2010-01-12 02:53:36.370000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                      time  latitude  longitude   depth   mag  \\\n",
       "640         640  2010-01-12T02:53:36.370Z   40.5075   -124.882  14.078  3.18   \n",
       "\n",
       "    magType   nst    gap    dmin  ...                            place  \\\n",
       "640      ml  37.0  243.0  0.4162  ...  52 km W of Ferndale, California   \n",
       "\n",
       "           type horizontalError depthError magError magNst    status  \\\n",
       "640  earthquake            1.39       0.69    0.165   17.0  reviewed   \n",
       "\n",
       "     locationSource  magSource                         datetime  \n",
       "640              nc         nc 2010-01-12 02:53:36.370000+00:00  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Localize (not convert) the naive timestamp to UTC\n",
    "time_center = pd.to_datetime(event_d['datetime'])\n",
    "time_window = pd.to_timedelta(120, unit='s')\n",
    "\n",
    "# Apply mask to timezone-aware datetimes\n",
    "mask = (events_anss['datetime'] >= time_center - time_window) & \\\n",
    "       (events_anss['datetime'] <= time_center + time_window)\n",
    "\n",
    "events_anss.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>depth</th>\n",
       "      <th>time</th>\n",
       "      <th>orid</th>\n",
       "      <th>nass</th>\n",
       "      <th>p_picks</th>\n",
       "      <th>s_picks</th>\n",
       "      <th>rms</th>\n",
       "      <th>nsphz</th>\n",
       "      <th>gap</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>id_Morton</th>\n",
       "      <th>dist</th>\n",
       "      <th>dt</th>\n",
       "      <th>NonDimDist</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>46.24845</td>\n",
       "      <td>-122.70049</td>\n",
       "      <td>47.728</td>\n",
       "      <td>1.262489e+09</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.443</td>\n",
       "      <td>2.0</td>\n",
       "      <td>252.366215</td>\n",
       "      <td>genie</td>\n",
       "      <td>0</td>\n",
       "      <td>1.142079</td>\n",
       "      <td>4.915355e+07</td>\n",
       "      <td>409612.903718</td>\n",
       "      <td>2010-01-03 03:16:18.553785+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0       lat        lon   depth          time  orid  nass  \\\n",
       "29          29  46.24845 -122.70049  47.728  1.262489e+09    29     8   \n",
       "\n",
       "    p_picks  s_picks    rms  nsphz         gap algorithm  id_Morton      dist  \\\n",
       "29        6        2  0.443    2.0  252.366215     genie          0  1.142079   \n",
       "\n",
       "              dt     NonDimDist                         datetime  \n",
       "29  4.915355e+07  409612.903718 2010-01-03 03:16:18.553785+00:00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inaccurate picks: Columbia River\n",
    "event_e = _df.loc[(_df['lat']>=46.24)&(_df['lat']<=46.26)&(_df['lon']<=-122.69)&(_df['lon']>=-122.71)]\n",
    "event_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CI YEAR</th>\n",
       "      <th>TSTRING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>SECOND</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>...</th>\n",
       "      <th>dist to nearest stn</th>\n",
       "      <th>tt RMS</th>\n",
       "      <th>ERH</th>\n",
       "      <th>ERZ</th>\n",
       "      <th>STRIKE</th>\n",
       "      <th>DIP</th>\n",
       "      <th>RAKE</th>\n",
       "      <th>PLATE DESIGNATION</th>\n",
       "      <th>TEMPLATE EVENT?</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CI YEAR, TSTRING, YEAR, MONTH, DAY, HOUR, MINUTE, SECOND, LAT, LON, DEPTH, Md, Num P&S with weights > 0.1, max az gap, dist to nearest stn, tt RMS, ERH, ERZ, STRIKE, DIP, RAKE, PLATE DESIGNATION, TEMPLATE EVENT?, datetime]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Localize (not convert) the naive timestamp to UTC\n",
    "time_center = pd.to_datetime(event_e['datetime'].values[0]).tz_localize('UTC')\n",
    "time_window = pd.to_timedelta(120, unit='s')\n",
    "\n",
    "# Apply mask to timezone-aware datetimes\n",
    "mask = (events_morton['datetime'] >= time_center - time_window) & \\\n",
    "       (events_morton['datetime'] <= time_center + time_window)\n",
    "\n",
    "events_morton.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, time, latitude, longitude, depth, mag, magType, nst, gap, dmin, rms, net, id, updated, place, type, horizontalError, depthError, magError, magNst, status, locationSource, magSource, datetime]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Localize (not convert) the naive timestamp to UTC\n",
    "time_center = pd.to_datetime(event_e['datetime'].values[0]).tz_localize('UTC')\n",
    "time_window = pd.to_timedelta(120, unit='s')\n",
    "\n",
    "# Apply mask to timezone-aware datetimes\n",
    "mask = (events_anss['datetime'] >= time_center - time_window) & \\\n",
    "       (events_anss['datetime'] <= time_center + time_window)\n",
    "\n",
    "events_anss.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>depth</th>\n",
       "      <th>time</th>\n",
       "      <th>orid</th>\n",
       "      <th>nass</th>\n",
       "      <th>p_picks</th>\n",
       "      <th>s_picks</th>\n",
       "      <th>rms</th>\n",
       "      <th>nsphz</th>\n",
       "      <th>gap</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>id_Morton</th>\n",
       "      <th>dist</th>\n",
       "      <th>dt</th>\n",
       "      <th>NonDimDist</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54736</th>\n",
       "      <td>54736</td>\n",
       "      <td>41.83504</td>\n",
       "      <td>-124.9547</td>\n",
       "      <td>57.795</td>\n",
       "      <td>1.417095e+09</td>\n",
       "      <td>54736</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.51</td>\n",
       "      <td>6.0</td>\n",
       "      <td>167.808554</td>\n",
       "      <td>genie</td>\n",
       "      <td>2838</td>\n",
       "      <td>1.430578</td>\n",
       "      <td>6845.349945</td>\n",
       "      <td>57.044612</td>\n",
       "      <td>2014-11-27 13:28:35.349945+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       lat       lon   depth          time   orid  nass  \\\n",
       "54736       54736  41.83504 -124.9547  57.795  1.417095e+09  54736    11   \n",
       "\n",
       "       p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "54736        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "\n",
       "           dist           dt  NonDimDist                         datetime  \n",
       "54736  1.430578  6845.349945   57.044612 2014-11-27 13:28:35.349945+00:00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inaccurate picks: Offshore OR\n",
    "event_f = _df.loc[(_df['lat']>=41.83)&(_df['lat']<=41.85)&(_df['lon']<=-124.94)&(_df['lon']>=-124.96)]\n",
    "event_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CI YEAR</th>\n",
       "      <th>TSTRING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>SECOND</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>...</th>\n",
       "      <th>dist to nearest stn</th>\n",
       "      <th>tt RMS</th>\n",
       "      <th>ERH</th>\n",
       "      <th>ERZ</th>\n",
       "      <th>STRIKE</th>\n",
       "      <th>DIP</th>\n",
       "      <th>RAKE</th>\n",
       "      <th>PLATE DESIGNATION</th>\n",
       "      <th>TEMPLATE EVENT?</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CI YEAR, TSTRING, YEAR, MONTH, DAY, HOUR, MINUTE, SECOND, LAT, LON, DEPTH, Md, Num P&S with weights > 0.1, max az gap, dist to nearest stn, tt RMS, ERH, ERZ, STRIKE, DIP, RAKE, PLATE DESIGNATION, TEMPLATE EVENT?, datetime]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Localize (not convert) the naive timestamp to UTC\n",
    "time_center = pd.to_datetime(event_f['datetime'].values[0]).tz_localize('UTC')\n",
    "time_window = pd.to_timedelta(120, unit='s')\n",
    "\n",
    "# Apply mask to timezone-aware datetimes\n",
    "mask = (events_morton['datetime'] >= time_center - time_window) & \\\n",
    "       (events_morton['datetime'] <= time_center + time_window)\n",
    "\n",
    "events_morton.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123671</th>\n",
       "      <td>123671</td>\n",
       "      <td>2014-11-27T13:27:41.810Z</td>\n",
       "      <td>38.807835</td>\n",
       "      <td>-122.793503</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.52</td>\n",
       "      <td>md</td>\n",
       "      <td>9.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>...</td>\n",
       "      <td>6 km WSW of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2014-11-27 13:27:41.810000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                      time   latitude   longitude  depth  \\\n",
       "123671      123671  2014-11-27T13:27:41.810Z  38.807835 -122.793503   0.45   \n",
       "\n",
       "         mag magType  nst    gap      dmin  ...                         place  \\\n",
       "123671  0.52      md  9.0  116.0  0.001802  ...  6 km WSW of Cobb, California   \n",
       "\n",
       "              type horizontalError depthError magError magNst     status  \\\n",
       "123671  earthquake             0.6       0.82     0.02    2.0  automatic   \n",
       "\n",
       "        locationSource  magSource                         datetime  \n",
       "123671              nc         nc 2014-11-27 13:27:41.810000+00:00  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Localize (not convert) the naive timestamp to UTC\n",
    "time_center = pd.to_datetime(event_f['datetime'].values[0]).tz_localize('UTC')\n",
    "time_window = pd.to_timedelta(120, unit='s')\n",
    "\n",
    "# Apply mask to timezone-aware datetimes\n",
    "mask = (events_anss['datetime'] >= time_center - time_window) & \\\n",
    "       (events_anss['datetime'] <= time_center + time_window)\n",
    "\n",
    "events_anss.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.read_csv('/wd1/hbito_data/data/datasets_all_regions/origin_2010_2015_reloc_cog_morton_ver3.csv',index_col=0)\n",
    "_df[\"time\"] = _df[\"time\"].apply(datetime.fromtimestamp, tz=timezone.utc)\n",
    "\n",
    "df_arrival = pd.read_csv('/wd1/hbito_data/data/datasets_all_regions/arrival_2010_2015_reloc_cog_ver3.csv',index_col=0)\n",
    "\n",
    "df_assoc = pd.read_csv('/wd1/hbito_data/data/datasets_all_regions/assoc_2010_2015_reloc_cog_ver3.csv',index_col=0)[['orid','arid']]\n",
    "\n",
    "df_picks = df_assoc.merge(df_arrival, on='arid', how='inner')[['orid','arid','sta','iphase','time']]\n",
    "df_picks = df_picks.rename(columns={'time':'time_pick'})\n",
    "df_pick_assignments = _df.merge(df_picks, on='orid', how='inner')\n",
    "\n",
    "df_pick_assignments = df_pick_assignments.rename(columns={'orid':'idx','sta':'station','iphase':'phase','datetime':'time','arid':'pick_idx','lat':'latitude','lon':'longitude'})\n",
    "\n",
    "\n",
    "picks = df_pick_assignments\n",
    "\n",
    "\n",
    "\n",
    "pick_idx = picks.idx.unique()[:]\n",
    "picks_selected = picks[picks.idx.isin(pick_idx)]\n",
    "picks_selected.loc[:, 'phase'] = picks_selected['phase'].str.replace(' ', '')\n",
    "picks_selected.loc[:, 'station'] = picks_selected['station'].str.replace(' ', '')\n",
    "picks_selected.loc[:, 'station'] = picks_selected['station'].apply(lambda x: x + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_pick = event_picks.loc[(event_picks.station==station)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fig3(picks):\n",
    "\n",
    "    # Plot the event and station locations\n",
    "    # Basemap for good picks\n",
    "    m1 = Basemap(projection='merc', llcrnrlat=38, urcrnrlat=51, llcrnrlon=-132, urcrnrlon=-119, resolution='i', ax=axs[0,3])\n",
    "    m1.drawcoastlines()\n",
    "    m1.drawcountries()\n",
    "    m1.drawstates()\n",
    "    m1.drawmapboundary()\n",
    "\n",
    "    # Basemap for inaccurate picks\n",
    "    m2 = Basemap(projection='merc', llcrnrlat=38, urcrnrlat=51, llcrnrlon=-132, urcrnrlon=-119, resolution='i', ax=axs[1,3])\n",
    "    m2.drawcoastlines()\n",
    "    m2.drawcountries()\n",
    "    m2.drawstates()\n",
    "    m2.drawmapboundary()\n",
    "\n",
    "    \n",
    "    def plot_panel_w_waveforms(event_id, axs_x, axs_y, label , color_on_basemap, add_scale, alpha):\n",
    "        event_idx = 52800\n",
    "        event_picks = picks[picks.idx==event_idx]\n",
    "        event_stations = event_picks.station.unique()\n",
    "        # print(event_picks)\n",
    "\n",
    "        otime = UTCDateTime(pd.to_datetime(event_picks.iloc[0].time))\n",
    "        olat = event_picks.iloc[0].latitude\n",
    "        olon = event_picks.iloc[0].longitude\n",
    "        odepth = event_picks.iloc[0].depth\n",
    "\n",
    "        tstring = otime.strftime('%Y%m%dT%H%M%SZ')\n",
    "        # path = dir + f\"{tstring}.png\"\n",
    "        # if os.path.exists(path):\n",
    "        #     print(f\"File {path} already exists. Skipping.\")\n",
    "        #     continue\n",
    "\n",
    "        bulk_sta = []\n",
    "        for sta in event_stations:\n",
    "            network = sta.split('.')[0]\n",
    "            station = sta.split('.')[1]\n",
    "            loc = '*'\n",
    "            ch = '?H?' \n",
    "            t1 = otime- pd.Timedelta(1,'days')\n",
    "            t2 = otime + pd.Timedelta(1,'days')\n",
    "\n",
    "            bulk_sta.append([network,station,loc,ch,t1,t2])\n",
    "            \n",
    "        inv = client_iris.get_stations_bulk(bulk_sta)\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "\n",
    "        distances = []\n",
    "        for network in inv:\n",
    "            network_code = network.code\n",
    "            for sta in network:\n",
    "                station_code = sta.code\n",
    "                slat = sta.latitude\n",
    "                slon = sta.longitude\n",
    "                selev = sta.elevation\n",
    "                \n",
    "                dis1 = locations2degrees(olat, olon, slat, slon)\n",
    "                dist = degrees2kilometers(dis1)\n",
    "\n",
    "                distances.append([network_code,station_code,olat,olon,odepth,slat,slon,selev,dist])\n",
    "                \n",
    "        # Sort distances\n",
    "        distances = sorted(distances, key=lambda item: item[-1])\n",
    "        st = Stream()\n",
    "\n",
    "        starttime = otime - 30\n",
    "        endtime = otime + 200\n",
    "        ch = '?H?'\n",
    "        loc = '*'\n",
    "\n",
    "        # Set up to define the xlim and ylim\n",
    "        max_y = 0\n",
    "        min_y = 0\n",
    "        min_y_count = 0 \n",
    "\n",
    "        max_x = 0\n",
    "        min_x = 0\n",
    "        min_x_count= 0\n",
    "\n",
    "        bulk_ncedc = []\n",
    "        bulk_pnw = []\n",
    "\n",
    "        for item in distances:\n",
    "            network_code, station_code, olat, olon, odepth, slat, slon, selev, dist = item\n",
    "\n",
    "            # Make a bulk request for the waveforms\n",
    "            if network_code in ['NC','BK']:\n",
    "                bulk_ncedc.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "            else:\n",
    "                bulk_pnw.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "            \n",
    "\n",
    "            # Adjust the time window and scaling of the data\n",
    "            station = network_code+'.'+station_code\n",
    "            p_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='P')]\n",
    "            s_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='S')]\n",
    "            # Append p_pick and s_pick to distances\n",
    "            item.extend([p_pick,s_pick])\n",
    "            if len(p_pick)==0 and len(s_pick)==0:\n",
    "                print('No picks for this station. Skipping.')\n",
    "                continue\n",
    "\n",
    "            if len(s_pick) > 0:\n",
    "                if max_x < UTCDateTime(s_pick.iloc[0]['time_pick']) - starttime:\n",
    "                    max_x = UTCDateTime(s_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5) - starttime\n",
    "            elif len(p_pick) > 0:\n",
    "                if max_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime: \n",
    "                    max_x = UTCDateTime(p_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5)- starttime\n",
    "            else:\n",
    "                print('No picks for this station. Skipping.')\n",
    "                continue \n",
    "\n",
    "            if len(p_pick) > 0:\n",
    "                if min_x_count == 0:\n",
    "                    if min_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                        min_x = UTCDateTime(p_pick.iloc[0]['time_pick']) -pd.Timedelta(seconds=5) - starttime\n",
    "                        min_x_count += 1           \n",
    "                else:\n",
    "                    if min_x >= UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                        min_x = UTCDateTime(p_pick.iloc[0]['time_pick'])-pd.Timedelta(seconds=5) - starttime            \n",
    "            elif len(s_pick) > 0:\n",
    "                if min_x_count == 0:\n",
    "                    if min_x < UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                        min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5)- starttime\n",
    "                        min_x_count += 1                \n",
    "                else:\n",
    "                    if min_x >= UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                        min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5) - starttime\n",
    "            else:\n",
    "                print('No picks for this station. Skipping.')\n",
    "                continue    \n",
    "\n",
    "            if min_y_count == 0:\n",
    "                if min_y < dist:\n",
    "                    min_y = dist - 5\n",
    "                    min_y_count += 1           \n",
    "            else:\n",
    "                if min_y >= dist:\n",
    "                    min_y = dist - 5 \n",
    "\n",
    "            max_y = dist + 5\n",
    "\n",
    "            distances\n",
    "\n",
    "        scaling_factor = (1/2) * (max_y - min_y) * add_scale # The last 1/2 added for this panel\n",
    "\n",
    "            \n",
    "        # Download the waveforms\n",
    "        st_ncedc = Stream()\n",
    "        st_pnw = Stream()\n",
    "        if len(bulk_ncedc) > 0:\n",
    "            st_ncedc += client_ncedc.get_waveforms_bulk(bulk_ncedc)\n",
    "\n",
    "        time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "        if len(bulk_pnw) > 0:\n",
    "            st_pnw += client_pnw.get_waveforms_bulk(bulk_pnw)\n",
    "\n",
    "        time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "        st = st_ncedc + st_pnw   \n",
    "\n",
    "        st = Stream(filter(lambda st: st.stats.sampling_rate > 10, st))\n",
    "        st.taper(max_percentage=0.05)\n",
    "        st.filter(type='bandpass', freqmin=2, freqmax=25)\n",
    "        st.merge(fill_value='interpolate')\n",
    "\n",
    "        # # Plot the waveforms\n",
    "        # # print('test1',st)\n",
    "        # fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "      \n",
    "        # m.drawparallels(np.arange(38, 51, 2), labels=[1, 0, 0, 0])\n",
    "        # m.drawmeridians(np.arange(-132, -119, 2), labels=[0, 0, 0, 1],rotation=45)\n",
    "        axs[0,3].set_title('Event Location',fontsize=14)\n",
    "        # # Count the number of stations that have 3 components\n",
    "        # count_1 = 0\n",
    "        # count_2 = 0\n",
    "        # count_3 = 0\n",
    "\n",
    "        for i,item in enumerate(distances):\n",
    "            network_code, station_code, olat, olon, odepth, slat, slon, selev, dist,p_pick,s_pick = item\n",
    "            st_sta = st.select(network=network_code,station=station_code)\n",
    "\n",
    "            # Select only HH or BH channels\n",
    "            _st = Stream()\n",
    "            has_HH = bool(st_sta.select(channel=\"HHZ\"))\n",
    "            has_BH = bool(st_sta.select(channel=\"BHZ\"))\n",
    "            has_EH = bool(st_sta.select(channel=\"EHZ\"))\n",
    "\n",
    "            if has_HH:\n",
    "                # If all HH, BH, EH, and EN channels are present, select only HH\n",
    "                _st += st_sta.select(channel=\"HHZ\")\n",
    "            elif has_BH:\n",
    "                # If BH, EH, and EN channels are present, select only BH\n",
    "                _st += st_sta.select(channel=\"BHZ\")\n",
    "            elif has_EH:\n",
    "                # If only EH and EN channels are present, select only EH\n",
    "                # NTS: This may result in getting only vertical component data - EH? is used for PNSN analog stations\n",
    "                # NTS: This may also be tricky for pulling full day-volumes because the sampling rate shifts for\n",
    "                #      analog stations due to the remote digitization scheme used with analog stations\n",
    "                _st += st_sta.select(channel=\"EHZ\")\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # # Define the desired order of channels\n",
    "            # desired_order = {\n",
    "            #     'Z': ['HHZ', 'BHZ','EHZ'],\n",
    "            #     'N': ['HHN', 'HH1', 'BHN', 'BH1', 'EHN', 'EN1'],\n",
    "            #     'E': ['HHE', 'HH2', 'BHE', 'BH2', 'EHE', 'EN2'],\n",
    "            # }\n",
    "\n",
    "            # Function to map channels to their desired order\n",
    "            # def get_channel_priority(channel):\n",
    "            #     for priority, (key, values) in enumerate(desired_order.items()):\n",
    "            #         if channel in values:\n",
    "            #             return priority\n",
    "            #     return float('inf')  # Return a high value for channels not in the desired order\n",
    "\n",
    "            # # Sort the traces in trim_st based on the desired order\n",
    "            # _st = sorted(_st, key=lambda trace: get_channel_priority(trace.stats.channel))\n",
    "\n",
    "            _st = Stream(_st)\n",
    "            # print(_st)\n",
    "            # for ax in range(len(_st)):\n",
    "            tr = _st[0]\n",
    "            sampling_rate = tr.stats.sampling_rate\n",
    "            channel = tr.stats.channel\n",
    "            \n",
    "            tr = tr.normalize()\n",
    "            \n",
    "            if len(p_pick) > 0:\n",
    "                tp = UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30\n",
    "                i1 = int((tp-5) * sampling_rate)\n",
    "                i2 = int((tp+15) * sampling_rate)\n",
    "            elif len(s_pick) > 0:\n",
    "                ts = UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30\n",
    "                i1 = int((ts-10) * sampling_rate)\n",
    "                i2 = int((ts+10) * sampling_rate)\n",
    "            else:\n",
    "                print(f\"WARNING: No pick time for {network}.{station}.{channel} on {otime}.\")\n",
    "\n",
    "\n",
    "\n",
    "            offsets1 = dist\n",
    "            # print(offsets1)\n",
    "            try: \n",
    "                wave = tr.data\n",
    "                wave = wave / (np.nanmax(wave[i1:i2], axis=-1) * 10)\n",
    "            except:\n",
    "                continue \n",
    "\n",
    "            # Plot the waveform\n",
    "            axs[0,0].plot(tr.times(), wave * scaling_factor + offsets1, \n",
    "                            color='black', alpha=alpha_panel_a, lw=0.5) \n",
    "            if len(p_pick) > 0:\n",
    "                axs[0,0].vlines(UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                                offsets1 + (1/12) * scaling_factor, color='r')\n",
    "            if len(s_pick) > 0:\n",
    "                axs[0,0].vlines(UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                                offsets1 + (1/12) * scaling_factor, color='b')\n",
    "            station = item[0]+'.'+item[1]+'.'\n",
    "            offsets1 = item[-3]\n",
    "            axs[0,0].text(max_x, offsets1-4, \n",
    "                            station, fontsize=8, color='red', verticalalignment='bottom')\n",
    "            \n",
    "\n",
    "            \n",
    "            axs[0,0].set_ylim([min_y-(1/8) * scaling_factor, max_y+(1/8) * scaling_factor])\n",
    "            axs[0,0].set_xlim([min_x, max_x])\n",
    "            axs[0,0].grid(alpha=0.5)\n",
    "            \n",
    "\n",
    "            x_sta,y_sta = m1(slon,slat)\n",
    "            m1.plot(x_sta, y_sta, '^', color='#CC79A7', markersize=6.2)\n",
    "\n",
    "        axs[0,0].set_xlabel('Offset from the Origin Time [s]',fontsize=14)\n",
    "        axs[0,0].set_ylabel('Epicentral Distance [km]',x=0.09,fontsize=14)\n",
    "        axs[0,0].text(min_x, max_y+(1/8) * scaling_factor, \n",
    "                        'a', fontsize=24, color='black', verticalalignment='bottom')\n",
    "\n",
    "        # Update the title of the subplot with the shortened otime\n",
    "        formatted_otime = otime.strftime('%Y-%m-%d %H:%M')\n",
    "        axs[0,0].set_title(f\"{formatted_otime}\", fontsize=14)\n",
    "\n",
    "        # # # Plot the event location\n",
    "        x_event,y_event = m1(olon,olat)\n",
    "        m1.plot(x_event, y_event, 'o',color='#CC79A7', markersize=7.2)\n",
    "        m1.plot(x_event+180, y_event+180, 'o',color='#CC79A7', markersize=7.2,label='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/obspy/signal/filter.py:62: UserWarning: Selected high corner frequency (25) of bandpass is at or above Nyquist (20.0). Applying a high-pass instead.\n",
      "  warnings.warn(msg)\n",
      "/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/obspy/signal/filter.py:62: UserWarning: Selected high corner frequency (25) of bandpass is at or above Nyquist (25.0). Applying a high-pass instead.\n",
      "  warnings.warn(msg)\n",
      "/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/obspy/signal/filter.py:62: UserWarning: Selected high corner frequency (25) of bandpass is at or above Nyquist (25.0). Applying a high-pass instead.\n",
      "  warnings.warn(msg)\n",
      "/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/obspy/signal/filter.py:62: UserWarning: Selected high corner frequency (25) of bandpass is at or above Nyquist (20.0). Applying a high-pass instead.\n",
      "  warnings.warn(msg)\n",
      "/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/obspy/signal/filter.py:62: UserWarning: Selected high corner frequency (25) of bandpass is at or above Nyquist (20.0). Applying a high-pass instead.\n",
      "  warnings.warn(msg)\n",
      "/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/obspy/signal/filter.py:62: UserWarning: Selected high corner frequency (25) of bandpass is at or above Nyquist (25.0). Applying a high-pass instead.\n",
      "  warnings.warn(msg)\n",
      "/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/obspy/signal/filter.py:62: UserWarning: Selected high corner frequency (25) of bandpass is at or above Nyquist (25.0). Applying a high-pass instead.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image size of 11822x216259 pixels is too large. It must be less than 2^16 in each direction.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/matplotlib/backend_bases.py:2193\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2190\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2191\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2192\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2193\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2194\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2195\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2196\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2197\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2198\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2199\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2200\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/matplotlib/backend_bases.py:2043\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2039\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2041\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2042\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2043\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2044\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2045\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2046\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:497\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    451\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:445\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[1;32m    447\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    448\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:383\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_renderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:398\u001b[0m, in \u001b[0;36mFigureCanvasAgg.get_renderer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    396\u001b[0m reuse_renderer \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m==\u001b[39m key)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reuse_renderer:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[43mRendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:70\u001b[0m, in \u001b[0;36mRendererAgg.__init__\u001b[0;34m(self, width, height, dpi)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m width\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m=\u001b[39m height\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer \u001b[38;5;241m=\u001b[39m \u001b[43m_RendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_renderers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_methods()\n",
      "\u001b[0;31mValueError\u001b[0m: Image size of 11822x216259 pixels is too large. It must be less than 2^16 in each direction."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1200 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(18, 12))\n",
    "###################################################\n",
    "event_idx = 52800\n",
    "event_picks = picks[picks.idx==event_idx]\n",
    "event_stations = event_picks.station.unique()\n",
    "# print(event_picks)\n",
    "\n",
    "otime = UTCDateTime(pd.to_datetime(event_picks.iloc[0].time))\n",
    "olat = event_picks.iloc[0].latitude\n",
    "olon = event_picks.iloc[0].longitude\n",
    "odepth = event_picks.iloc[0].depth\n",
    "\n",
    "tstring = otime.strftime('%Y%m%dT%H%M%SZ')\n",
    "# path = dir + f\"{tstring}.png\"\n",
    "# if os.path.exists(path):\n",
    "#     print(f\"File {path} already exists. Skipping.\")\n",
    "#     continue\n",
    "\n",
    "bulk_sta = []\n",
    "for sta in event_stations:\n",
    "    network = sta.split('.')[0]\n",
    "    station = sta.split('.')[1]\n",
    "    loc = '*'\n",
    "    ch = '?H?' \n",
    "    t1 = otime- pd.Timedelta(1,'days')\n",
    "    t2 = otime + pd.Timedelta(1,'days')\n",
    "\n",
    "    bulk_sta.append([network,station,loc,ch,t1,t2])\n",
    "    \n",
    "inv = client_iris.get_stations_bulk(bulk_sta)\n",
    "\n",
    "time.sleep(0.1)\n",
    "\n",
    "\n",
    "distances = []\n",
    "for network in inv:\n",
    "    network_code = network.code\n",
    "    for sta in network:\n",
    "        station_code = sta.code\n",
    "        slat = sta.latitude\n",
    "        slon = sta.longitude\n",
    "        selev = sta.elevation\n",
    "        \n",
    "        dis1 = locations2degrees(olat, olon, slat, slon)\n",
    "        dist = degrees2kilometers(dis1)\n",
    "\n",
    "        distances.append([network_code,station_code,olat,olon,odepth,slat,slon,selev,dist])\n",
    "        \n",
    "# Sort distances\n",
    "distances = sorted(distances, key=lambda item: item[-1])\n",
    "st = Stream()\n",
    "\n",
    "starttime = otime - 30\n",
    "endtime = otime + 200\n",
    "ch = '?H?'\n",
    "loc = '*'\n",
    "\n",
    "# Set up to define the xlim and ylim\n",
    "max_y = 0\n",
    "min_y = 0\n",
    "min_y_count = 0 \n",
    "\n",
    "max_x = 0\n",
    "min_x = 0\n",
    "min_x_count= 0\n",
    "\n",
    "bulk_ncedc = []\n",
    "bulk_pnw = []\n",
    "\n",
    "for item in distances:\n",
    "    network_code, station_code, olat, olon, odepth, slat, slon, selev, dist = item\n",
    "\n",
    "    # Make a bulk request for the waveforms\n",
    "    if network_code in ['NC','BK']:\n",
    "        bulk_ncedc.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "    else:\n",
    "        bulk_pnw.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "    \n",
    "\n",
    "    # Adjust the time window and scaling of the data\n",
    "    station = network_code+'.'+station_code\n",
    "    p_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='P')]\n",
    "    s_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='S')]\n",
    "    # Append p_pick and s_pick to distances\n",
    "    item.extend([p_pick,s_pick])\n",
    "    if len(p_pick)==0 and len(s_pick)==0:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue\n",
    "\n",
    "    if len(s_pick) > 0:\n",
    "        if max_x < UTCDateTime(s_pick.iloc[0]['time_pick']) - starttime:\n",
    "            max_x = UTCDateTime(s_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5) - starttime\n",
    "    elif len(p_pick) > 0:\n",
    "        if max_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime: \n",
    "            max_x = UTCDateTime(p_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5)- starttime\n",
    "    else:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue \n",
    "\n",
    "    if len(p_pick) > 0:\n",
    "        if min_x_count == 0:\n",
    "            if min_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                min_x = UTCDateTime(p_pick.iloc[0]['time_pick']) -pd.Timedelta(seconds=5) - starttime\n",
    "                min_x_count += 1           \n",
    "        else:\n",
    "            if min_x >= UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                min_x = UTCDateTime(p_pick.iloc[0]['time_pick'])-pd.Timedelta(seconds=5) - starttime            \n",
    "    elif len(s_pick) > 0:\n",
    "        if min_x_count == 0:\n",
    "            if min_x < UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5)- starttime\n",
    "                min_x_count += 1                \n",
    "        else:\n",
    "            if min_x >= UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5) - starttime\n",
    "    else:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue    \n",
    "\n",
    "    if min_y_count == 0:\n",
    "        if min_y < dist:\n",
    "            min_y = dist - 5\n",
    "            min_y_count += 1           \n",
    "    else:\n",
    "        if min_y >= dist:\n",
    "            min_y = dist - 5 \n",
    "\n",
    "    max_y = dist + 5\n",
    "\n",
    "    distances\n",
    "\n",
    "\n",
    "alpha_panel_a = 0.5  # Alpha set to 0.5 for this panel \n",
    "add_scale_panel_a = 1/2\n",
    "scaling_factor = (1/2) * (max_y - min_y) * add_scale_panel_a # The last 1/2 added for this panel\n",
    "\n",
    "    \n",
    "# Download the waveforms\n",
    "st_ncedc = Stream()\n",
    "st_pnw = Stream()\n",
    "if len(bulk_ncedc) > 0:\n",
    "    st_ncedc += client_ncedc.get_waveforms_bulk(bulk_ncedc)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "if len(bulk_pnw) > 0:\n",
    "    st_pnw += client_pnw.get_waveforms_bulk(bulk_pnw)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "st = st_ncedc + st_pnw   \n",
    "\n",
    "st = Stream(filter(lambda st: st.stats.sampling_rate > 10, st))\n",
    "st.taper(max_percentage=0.05)\n",
    "st.filter(type='bandpass', freqmin=2, freqmax=25)\n",
    "st.merge(fill_value='interpolate')\n",
    "\n",
    "# # Plot the waveforms\n",
    "# # print('test1',st)\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "# Plot the event and station locations\n",
    "m1 = Basemap(projection='merc', llcrnrlat=38, urcrnrlat=51, llcrnrlon=-132, urcrnrlon=-119, resolution='i', ax=axs[0,3])\n",
    "m1.drawcoastlines()\n",
    "m1.drawcountries()\n",
    "m1.drawstates()\n",
    "m1.drawmapboundary()\n",
    "# m.drawparallels(np.arange(38, 51, 2), labels=[1, 0, 0, 0])\n",
    "# m.drawmeridians(np.arange(-132, -119, 2), labels=[0, 0, 0, 1],rotation=45)\n",
    "axs[0,3].set_title('Event Location',fontsize=14)\n",
    "# # Count the number of stations that have 3 components\n",
    "# count_1 = 0\n",
    "# count_2 = 0\n",
    "# count_3 = 0\n",
    "\n",
    "for i,item in enumerate(distances):\n",
    "    network_code, station_code, olat, olon, odepth, slat, slon, selev, dist,p_pick,s_pick = item\n",
    "    st_sta = st.select(network=network_code,station=station_code)\n",
    "\n",
    "    # Select only HH or BH channels\n",
    "    _st = Stream()\n",
    "    has_HH = bool(st_sta.select(channel=\"HHZ\"))\n",
    "    has_BH = bool(st_sta.select(channel=\"BHZ\"))\n",
    "    has_EH = bool(st_sta.select(channel=\"EHZ\"))\n",
    "\n",
    "    if has_HH:\n",
    "        # If all HH, BH, EH, and EN channels are present, select only HH\n",
    "        _st += st_sta.select(channel=\"HHZ\")\n",
    "    elif has_BH:\n",
    "        # If BH, EH, and EN channels are present, select only BH\n",
    "        _st += st_sta.select(channel=\"BHZ\")\n",
    "    elif has_EH:\n",
    "        # If only EH and EN channels are present, select only EH\n",
    "        # NTS: This may result in getting only vertical component data - EH? is used for PNSN analog stations\n",
    "        # NTS: This may also be tricky for pulling full day-volumes because the sampling rate shifts for\n",
    "        #      analog stations due to the remote digitization scheme used with analog stations\n",
    "        _st += st_sta.select(channel=\"EHZ\")\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # # Define the desired order of channels\n",
    "    # desired_order = {\n",
    "    #     'Z': ['HHZ', 'BHZ','EHZ'],\n",
    "    #     'N': ['HHN', 'HH1', 'BHN', 'BH1', 'EHN', 'EN1'],\n",
    "    #     'E': ['HHE', 'HH2', 'BHE', 'BH2', 'EHE', 'EN2'],\n",
    "    # }\n",
    "\n",
    "    # Function to map channels to their desired order\n",
    "    # def get_channel_priority(channel):\n",
    "    #     for priority, (key, values) in enumerate(desired_order.items()):\n",
    "    #         if channel in values:\n",
    "    #             return priority\n",
    "    #     return float('inf')  # Return a high value for channels not in the desired order\n",
    "\n",
    "    # # Sort the traces in trim_st based on the desired order\n",
    "    # _st = sorted(_st, key=lambda trace: get_channel_priority(trace.stats.channel))\n",
    "\n",
    "    _st = Stream(_st)\n",
    "    # print(_st)\n",
    "    # for ax in range(len(_st)):\n",
    "    tr = _st[0]\n",
    "    sampling_rate = tr.stats.sampling_rate\n",
    "    channel = tr.stats.channel\n",
    "    \n",
    "    tr = tr.normalize()\n",
    "    \n",
    "    if len(p_pick) > 0:\n",
    "        tp = UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30\n",
    "        i1 = int((tp-5) * sampling_rate)\n",
    "        i2 = int((tp+15) * sampling_rate)\n",
    "    elif len(s_pick) > 0:\n",
    "        ts = UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30\n",
    "        i1 = int((ts-10) * sampling_rate)\n",
    "        i2 = int((ts+10) * sampling_rate)\n",
    "    else:\n",
    "        print(f\"WARNING: No pick time for {network}.{station}.{channel} on {otime}.\")\n",
    "\n",
    "\n",
    "\n",
    "    offsets1 = dist\n",
    "    # print(offsets1)\n",
    "    try: \n",
    "        wave = tr.data\n",
    "        wave = wave / (np.nanmax(wave[i1:i2], axis=-1) * 10)\n",
    "    except:\n",
    "        continue \n",
    "\n",
    "    # Plot the waveform\n",
    "    axs[0,0].plot(tr.times(), wave * scaling_factor + offsets1, \n",
    "                    color='black', alpha=alpha_panel_a, lw=0.5) \n",
    "    if len(p_pick) > 0:\n",
    "        axs[0,0].vlines(UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                        offsets1 + (1/12) * scaling_factor, color='r')\n",
    "    if len(s_pick) > 0:\n",
    "        axs[0,0].vlines(UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                        offsets1 + (1/12) * scaling_factor, color='b')\n",
    "    station = item[0]+'.'+item[1]+'.'\n",
    "    offsets1 = item[-3]\n",
    "    axs[0,0].text(max_x, offsets1-4, \n",
    "                    station, fontsize=8, color='red', verticalalignment='bottom')\n",
    "    \n",
    "\n",
    "    \n",
    "    axs[0,0].set_ylim([min_y-(1/8) * scaling_factor, max_y+(1/8) * scaling_factor])\n",
    "    axs[0,0].set_xlim([min_x, max_x])\n",
    "    axs[0,0].grid(alpha=0.5)\n",
    "    \n",
    "\n",
    "    x_sta,y_sta = m1(slon,slat)\n",
    "    m1.plot(x_sta, y_sta, '^', color='#CC79A7', markersize=6.2)\n",
    "\n",
    "axs[0,0].set_xlabel('Offset from the Origin Time [s]',fontsize=14)\n",
    "axs[0,0].set_ylabel('Epicentral Distance [km]',x=0.09,fontsize=14)\n",
    "axs[0,0].text(min_x, max_y+(1/8) * scaling_factor, \n",
    "                'a', fontsize=24, color='black', verticalalignment='bottom')\n",
    "\n",
    "# Update the title of the subplot with the shortened otime\n",
    "formatted_otime = otime.strftime('%Y-%m-%d %H:%M')\n",
    "axs[0,0].set_title(f\"{formatted_otime}\", fontsize=14)\n",
    "\n",
    "# # # Plot the event location\n",
    "x_event,y_event = m1(olon,olat)\n",
    "m1.plot(x_event, y_event, 'o',color='#CC79A7', markersize=7.2)\n",
    "m1.plot(x_event+180, y_event+180, 'o',color='#CC79A7', markersize=7.2,label='a')\n",
    "\n",
    "\n",
    "###################################################\n",
    "event_idx = 535\n",
    "event_picks = picks[picks.idx==event_idx]\n",
    "event_stations = event_picks.station.unique()\n",
    "# print(event_picks)\n",
    "\n",
    "otime = UTCDateTime(pd.to_datetime(event_picks.iloc[0].time))\n",
    "olat = event_picks.iloc[0].latitude\n",
    "olon = event_picks.iloc[0].longitude\n",
    "odepth = event_picks.iloc[0].depth\n",
    "\n",
    "tstring = otime.strftime('%Y%m%dT%H%M%SZ')\n",
    "# path = dir + f\"{tstring}.png\"\n",
    "# if os.path.exists(path):\n",
    "#     print(f\"File {path} already exists. Skipping.\")\n",
    "#     continue\n",
    "\n",
    "bulk_sta = []\n",
    "for sta in event_stations:\n",
    "    network = sta.split('.')[0]\n",
    "    station = sta.split('.')[1]\n",
    "    loc = '*'\n",
    "    ch = '?H?' \n",
    "    t1 = otime- pd.Timedelta(1,'days')\n",
    "    t2 = otime + pd.Timedelta(1,'days')\n",
    "\n",
    "    bulk_sta.append([network,station,loc,ch,t1,t2])\n",
    "    \n",
    "inv = client_iris.get_stations_bulk(bulk_sta)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "\n",
    "distances = []\n",
    "for network in inv:\n",
    "    network_code = network.code\n",
    "    for sta in network:\n",
    "        station_code = sta.code\n",
    "        slat = sta.latitude\n",
    "        slon = sta.longitude\n",
    "        selev = sta.elevation\n",
    "        \n",
    "        dis1 = locations2degrees(olat, olon, slat, slon)\n",
    "        dist = degrees2kilometers(dis1)\n",
    "\n",
    "        distances.append([network_code,station_code,olat,olon,odepth,slat,slon,selev,dist])\n",
    "        \n",
    "# Sort distances\n",
    "distances = sorted(distances, key=lambda item: item[-1])\n",
    "st = Stream()\n",
    "\n",
    "starttime = otime - 30\n",
    "endtime = otime + 200\n",
    "ch = '?H?'\n",
    "loc = '*'\n",
    "\n",
    "# Set up to define the xlim and ylim\n",
    "max_y = 0\n",
    "min_y = 0\n",
    "min_y_count = 0 \n",
    "\n",
    "max_x = 0\n",
    "min_x = 0\n",
    "min_x_count= 0\n",
    "\n",
    "bulk_ncedc = []\n",
    "bulk_pnw = []\n",
    "\n",
    "for item in distances:\n",
    "    network_code, station_code, olat, olon, odepth, slat, slon, selev, dist = item\n",
    "\n",
    "    # Make a bulk request for the waveforms\n",
    "    if network_code in ['NC','BK']:\n",
    "        bulk_ncedc.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "    else:\n",
    "        bulk_pnw.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "    \n",
    "\n",
    "    # Adjust the time window and scaling of the data\n",
    "    station = network_code+'.'+station_code\n",
    "    p_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='P')]\n",
    "    s_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='S')]\n",
    "    # Append p_pick and s_pick to distances\n",
    "    item.extend([p_pick,s_pick])\n",
    "    if len(p_pick)==0 and len(s_pick)==0:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue\n",
    "\n",
    "    if len(s_pick) > 0:\n",
    "        if max_x < UTCDateTime(s_pick.iloc[0]['time_pick']) - starttime:\n",
    "            max_x = UTCDateTime(s_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5) - starttime\n",
    "    elif len(p_pick) > 0:\n",
    "        if max_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime: \n",
    "            max_x = UTCDateTime(p_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5)- starttime\n",
    "    else:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue \n",
    "\n",
    "    if len(p_pick) > 0:\n",
    "        if min_x_count == 0:\n",
    "            if min_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                min_x = UTCDateTime(p_pick.iloc[0]['time_pick']) -pd.Timedelta(seconds=5) - starttime\n",
    "                min_x_count += 1           \n",
    "        else:\n",
    "            if min_x >= UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                min_x = UTCDateTime(p_pick.iloc[0]['time_pick'])-pd.Timedelta(seconds=5) - starttime            \n",
    "    elif len(s_pick) > 0:\n",
    "        if min_x_count == 0:\n",
    "            if min_x < UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5)- starttime\n",
    "                min_x_count += 1                \n",
    "        else:\n",
    "            if min_x >= UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5) - starttime\n",
    "    else:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue    \n",
    "\n",
    "    if min_y_count == 0:\n",
    "        if min_y < dist:\n",
    "            min_y = dist - 5\n",
    "            min_y_count += 1           \n",
    "    else:\n",
    "        if min_y >= dist:\n",
    "            min_y = dist - 5 \n",
    "\n",
    "    max_y = dist + 5\n",
    "\n",
    "    distances\n",
    "\n",
    "alpha_panel_b = 0.1  # Alpha set to 0.5 for this panel \n",
    "add_scale_panel_b = 1/2\n",
    "scaling_factor = (1/2) * (max_y - min_y) * add_scale_panel_b # The last 1/2 added for this panel\n",
    "    \n",
    "# Download the waveforms\n",
    "st_ncedc = Stream()\n",
    "st_pnw = Stream()\n",
    "if len(bulk_ncedc) > 0:\n",
    "    st_ncedc += client_ncedc.get_waveforms_bulk(bulk_ncedc)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "if len(bulk_pnw) > 0:\n",
    "    st_pnw += client_pnw.get_waveforms_bulk(bulk_pnw)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "\n",
    "st = st_ncedc + st_pnw   \n",
    "\n",
    "st = Stream(filter(lambda st: st.stats.sampling_rate > 10, st))\n",
    "st.taper(max_percentage=0.05)\n",
    "st.filter(type='bandpass', freqmin=2, freqmax=25)\n",
    "st.merge(fill_value='interpolate')\n",
    "\n",
    "# Plot the event and station locations\n",
    "m2 = Basemap(projection='merc', llcrnrlat=38, urcrnrlat=51, llcrnrlon=-132, urcrnrlon=-119, resolution='i', ax=axs[1,3])\n",
    "m2.drawcoastlines()\n",
    "m2.drawcountries()\n",
    "m2.drawstates()\n",
    "m2.drawmapboundary()\n",
    "# m.drawparallels(np.arange(38, 51, 2), labels=[1, 0, 0, 0])\n",
    "# m.drawmeridians(np.arange(-132, -119, 2), labels=[0, 0, 0, 1],rotation=45)\n",
    "axs[1,3].set_title('Event Location',fontsize=14)\n",
    "\n",
    "# # Plot the waveforms\n",
    "# # print('test1',st)\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "for i,item in enumerate(distances):\n",
    "    network_code, station_code, olat, olon, odepth, slat, slon, selev, dist,p_pick,s_pick = item\n",
    "    st_sta = st.select(network=network_code,station=station_code)\n",
    "\n",
    "    # Select only HH or BH channels\n",
    "    _st = Stream()\n",
    "    has_HH = bool(st_sta.select(channel=\"HHZ\"))\n",
    "    has_BH = bool(st_sta.select(channel=\"BHZ\"))\n",
    "    has_EH = bool(st_sta.select(channel=\"EHZ\"))\n",
    "\n",
    "    if has_HH:\n",
    "        # If all HH, BH, EH, and EN channels are present, select only HH\n",
    "        _st += st_sta.select(channel=\"HHZ\")\n",
    "    elif has_BH:\n",
    "        # If BH, EH, and EN channels are present, select only BH\n",
    "        _st += st_sta.select(channel=\"BHZ\")\n",
    "    elif has_EH:\n",
    "        # If only EH and EN channels are present, select only EH\n",
    "        # NTS: This may result in getting only vertical component data - EH? is used for PNSN analog stations\n",
    "        # NTS: This may also be tricky for pulling full day-volumes because the sampling rate shifts for\n",
    "        #      analog stations due to the remote digitization scheme used with analog stations\n",
    "        _st += st_sta.select(channel=\"EHZ\")\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # # Define the desired order of channels\n",
    "    # desired_order = {\n",
    "    #     'Z': ['HHZ', 'BHZ','EHZ'],\n",
    "    #     'N': ['HHN', 'HH1', 'BHN', 'BH1', 'EHN', 'EN1'],\n",
    "    #     'E': ['HHE', 'HH2', 'BHE', 'BH2', 'EHE', 'EN2'],\n",
    "    # }\n",
    "\n",
    "    # Function to map channels to their desired order\n",
    "    # def get_channel_priority(channel):\n",
    "    #     for priority, (key, values) in enumerate(desired_order.items()):\n",
    "    #         if channel in values:\n",
    "    #             return priority\n",
    "    #     return float('inf')  # Return a high value for channels not in the desired order\n",
    "\n",
    "    # # Sort the traces in trim_st based on the desired order\n",
    "    # _st = sorted(_st, key=lambda trace: get_channel_priority(trace.stats.channel))\n",
    "\n",
    "    _st = Stream(_st)\n",
    "    # print(_st)\n",
    "    # for ax in range(len(_st)):\n",
    "    tr = _st[0]\n",
    "    sampling_rate = tr.stats.sampling_rate\n",
    "    channel = tr.stats.channel\n",
    "    \n",
    "    tr = tr.normalize()\n",
    "    \n",
    "    if len(p_pick) > 0:\n",
    "        tp = UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30\n",
    "        i1 = int((tp-5) * sampling_rate)\n",
    "        i2 = int((tp+15) * sampling_rate)\n",
    "    elif len(s_pick) > 0:\n",
    "        ts = UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30\n",
    "        i1 = int((ts-10) * sampling_rate)\n",
    "        i2 = int((ts+10) * sampling_rate)\n",
    "    else:\n",
    "        print(f\"WARNING: No pick time for {network}.{station}.{channel} on {otime}.\")\n",
    "\n",
    "\n",
    "\n",
    "    offsets1 = dist\n",
    "    # print(offsets1)\n",
    "    try: \n",
    "        wave = tr.data\n",
    "        wave = wave / (np.nanmax(wave[i1:i2], axis=-1) * 10)\n",
    "    except:\n",
    "        continue \n",
    "\n",
    "    # Plot the waveform\n",
    "    axs[1,0].plot(tr.times(), wave * scaling_factor + offsets1, \n",
    "                    color='black', alpha=alpha_panel_b, lw=0.5)\n",
    "    if len(p_pick) > 0:\n",
    "        axs[1,0].vlines(UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                        offsets1 + (1/12) * scaling_factor, color='r')\n",
    "    if len(s_pick) > 0:\n",
    "        axs[1,0].vlines(UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                        offsets1 + (1/12) * scaling_factor, color='b')\n",
    "    station = item[0]+'.'+item[1]+'.'\n",
    "    offsets1 = item[-3]\n",
    "    axs[1,0].text(max_x, offsets1-4, \n",
    "                    station, fontsize=8, color='red', verticalalignment='bottom')\n",
    "    \n",
    "\n",
    "    \n",
    "    axs[1,0].set_ylim([min_y-(1/8) * scaling_factor, max_y+(1/8) * scaling_factor])\n",
    "    axs[1,0].set_xlim([min_x, max_x])\n",
    "    axs[1,0].grid(alpha=0.5)\n",
    "    \n",
    "    \n",
    "\n",
    "    x_sta,y_sta = m1(slon,slat)\n",
    "    m2.plot(x_sta, y_sta, '^', color='#009E73', markersize=6.5)\n",
    "axs[1,0].set_xlabel('Offset from the Origin Time [s]',fontsize=14)\n",
    "axs[1,0].set_ylabel('Epicentral Distance [km]',x=0.09,fontsize=14)\n",
    "axs[1,0].text(min_x, max_y+(1/8) * scaling_factor, \n",
    "                'd', fontsize=24, color='black', verticalalignment='bottom')\n",
    "\n",
    "# Update the title of the subplot with the shortened otime\n",
    "formatted_otime = otime.strftime('%Y-%m-%d %H:%M')\n",
    "axs[0,1].set_title(f\"{formatted_otime}\", fontsize=14)\n",
    "\n",
    "# # # Plot the event location\n",
    "x_event,y_event = m1(olon,olat)\n",
    "m2.plot(x_event, y_event, 'o',color='#009E73', markersize=7.2)\n",
    "m2.plot(x_event+180, y_event+180, 'o',color='#009E73', markersize=7.2,label='d')\n",
    "\n",
    "###################################################\n",
    "event_idx = 20052\n",
    "event_picks = picks[picks.idx==event_idx]\n",
    "event_stations = event_picks.station.unique()\n",
    "# print(event_picks)\n",
    "\n",
    "otime = UTCDateTime(pd.to_datetime(event_picks.iloc[0].time))\n",
    "olat = event_picks.iloc[0].latitude\n",
    "olon = event_picks.iloc[0].longitude\n",
    "odepth = event_picks.iloc[0].depth\n",
    "\n",
    "tstring = otime.strftime('%Y%m%dT%H%M%SZ')\n",
    "# path = dir + f\"{tstring}.png\"\n",
    "# if os.path.exists(path):\n",
    "#     print(f\"File {path} already exists. Skipping.\")\n",
    "#     continue\n",
    "\n",
    "bulk_sta = []\n",
    "for sta in event_stations:\n",
    "    network = sta.split('.')[0]\n",
    "    station = sta.split('.')[1]\n",
    "    loc = '*'\n",
    "    ch = '?H?' \n",
    "    t1 = otime- pd.Timedelta(1,'days')\n",
    "    t2 = otime + pd.Timedelta(1,'days')\n",
    "\n",
    "    bulk_sta.append([network,station,loc,ch,t1,t2])\n",
    "    \n",
    "inv = client_iris.get_stations_bulk(bulk_sta)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "\n",
    "distances = []\n",
    "for network in inv:\n",
    "    network_code = network.code\n",
    "    for sta in network:\n",
    "        station_code = sta.code\n",
    "        slat = sta.latitude\n",
    "        slon = sta.longitude\n",
    "        selev = sta.elevation\n",
    "        \n",
    "        dis1 = locations2degrees(olat, olon, slat, slon)\n",
    "        dist = degrees2kilometers(dis1)\n",
    "\n",
    "        distances.append([network_code,station_code,olat,olon,odepth,slat,slon,selev,dist])\n",
    "        \n",
    "# Sort distances\n",
    "distances = sorted(distances, key=lambda item: item[-1])\n",
    "st = Stream()\n",
    "\n",
    "starttime = otime - 30\n",
    "endtime = otime + 200\n",
    "ch = '?H?'\n",
    "loc = '*'\n",
    "\n",
    "# Set up to define the xlim and ylim\n",
    "max_y = 0\n",
    "min_y = 0\n",
    "min_y_count = 0 \n",
    "\n",
    "max_x = 0\n",
    "min_x = 0\n",
    "min_x_count= 0\n",
    "\n",
    "bulk_ncedc = []\n",
    "bulk_pnw = []\n",
    "\n",
    "for item in distances:\n",
    "    network_code, station_code, olat, olon, odepth, slat, slon, selev, dist = item\n",
    "\n",
    "    # Make a bulk request for the waveforms\n",
    "    if network_code in ['NC','BK']:\n",
    "        bulk_ncedc.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "    else:\n",
    "        bulk_pnw.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "    \n",
    "\n",
    "    # Adjust the time window and scaling of the data\n",
    "    station = network_code+'.'+station_code\n",
    "    p_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='P')]\n",
    "    s_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='S')]\n",
    "    # Append p_pick and s_pick to distances\n",
    "    item.extend([p_pick,s_pick])\n",
    "    if len(p_pick)==0 and len(s_pick)==0:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue\n",
    "\n",
    "    if len(s_pick) > 0:\n",
    "        if max_x < UTCDateTime(s_pick.iloc[0]['time_pick']) - starttime:\n",
    "            max_x = UTCDateTime(s_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5) - starttime\n",
    "    elif len(p_pick) > 0:\n",
    "        if max_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime: \n",
    "            max_x = UTCDateTime(p_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5)- starttime\n",
    "    else:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue \n",
    "\n",
    "    if len(p_pick) > 0:\n",
    "        if min_x_count == 0:\n",
    "            if min_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                min_x = UTCDateTime(p_pick.iloc[0]['time_pick']) -pd.Timedelta(seconds=5) - starttime\n",
    "                min_x_count += 1           \n",
    "        else:\n",
    "            if min_x >= UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                min_x = UTCDateTime(p_pick.iloc[0]['time_pick'])-pd.Timedelta(seconds=5) - starttime            \n",
    "    elif len(s_pick) > 0:\n",
    "        if min_x_count == 0:\n",
    "            if min_x < UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5)- starttime\n",
    "                min_x_count += 1                \n",
    "        else:\n",
    "            if min_x >= UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5) - starttime\n",
    "    else:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue    \n",
    "\n",
    "    if min_y_count == 0:\n",
    "        if min_y < dist:\n",
    "            min_y = dist - 5\n",
    "            min_y_count += 1           \n",
    "    else:\n",
    "        if min_y >= dist:\n",
    "            min_y = dist - 5 \n",
    "\n",
    "    max_y = dist + 5\n",
    "\n",
    "    distances\n",
    "\n",
    "scaling_factor = (1/2) * (max_y - min_y)\n",
    "    \n",
    "# Download the waveforms\n",
    "st_ncedc = Stream()\n",
    "st_pnw = Stream()\n",
    "if len(bulk_ncedc) > 0:\n",
    "    st_ncedc += client_ncedc.get_waveforms_bulk(bulk_ncedc)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "if len(bulk_pnw) > 0:\n",
    "    st_pnw += client_pnw.get_waveforms_bulk(bulk_pnw)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "\n",
    "st = st_ncedc + st_pnw   \n",
    "\n",
    "st = Stream(filter(lambda st: st.stats.sampling_rate > 10, st))\n",
    "st.taper(max_percentage=0.05)\n",
    "st.filter(type='bandpass', freqmin=2, freqmax=25)\n",
    "st.merge(fill_value='interpolate')\n",
    "\n",
    "# # Plot the waveforms\n",
    "# # print('test1',st)\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "for i,item in enumerate(distances):\n",
    "    network_code, station_code, olat, olon, odepth, slat, slon, selev, dist,p_pick,s_pick = item\n",
    "    st_sta = st.select(network=network_code,station=station_code)\n",
    "\n",
    "    # Select only HH or BH channels\n",
    "    _st = Stream()\n",
    "    has_HH = bool(st_sta.select(channel=\"HHZ\"))\n",
    "    has_BH = bool(st_sta.select(channel=\"BHZ\"))\n",
    "    has_EH = bool(st_sta.select(channel=\"EHZ\"))\n",
    "\n",
    "    if has_HH:\n",
    "        # If all HH, BH, EH, and EN channels are present, select only HH\n",
    "        _st += st_sta.select(channel=\"HHZ\")\n",
    "    elif has_BH:\n",
    "        # If BH, EH, and EN channels are present, select only BH\n",
    "        _st += st_sta.select(channel=\"BHZ\")\n",
    "    elif has_EH:\n",
    "        # If only EH and EN channels are present, select only EH\n",
    "        # NTS: This may result in getting only vertical component data - EH? is used for PNSN analog stations\n",
    "        # NTS: This may also be tricky for pulling full day-volumes because the sampling rate shifts for\n",
    "        #      analog stations due to the remote digitization scheme used with analog stations\n",
    "        _st += st_sta.select(channel=\"EHZ\")\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # # Define the desired order of channels\n",
    "    # desired_order = {\n",
    "    #     'Z': ['HHZ', 'BHZ','EHZ'],\n",
    "    #     'N': ['HHN', 'HH1', 'BHN', 'BH1', 'EHN', 'EN1'],\n",
    "    #     'E': ['HHE', 'HH2', 'BHE', 'BH2', 'EHE', 'EN2'],\n",
    "    # }\n",
    "\n",
    "    # Function to map channels to their desired order\n",
    "    # def get_channel_priority(channel):\n",
    "    #     for priority, (key, values) in enumerate(desired_order.items()):\n",
    "    #         if channel in values:\n",
    "    #             return priority\n",
    "    #     return float('inf')  # Return a high value for channels not in the desired order\n",
    "\n",
    "    # # Sort the traces in trim_st based on the desired order\n",
    "    # _st = sorted(_st, key=lambda trace: get_channel_priority(trace.stats.channel))\n",
    "\n",
    "    _st = Stream(_st)\n",
    "    # print(_st)\n",
    "    # for ax in range(len(_st)):\n",
    "    tr = _st[0]\n",
    "    sampling_rate = tr.stats.sampling_rate\n",
    "    channel = tr.stats.channel\n",
    "    \n",
    "    tr = tr.normalize()\n",
    "    \n",
    "    if len(p_pick) > 0:\n",
    "        tp = UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30\n",
    "        i1 = int((tp-5) * sampling_rate)\n",
    "        i2 = int((tp+15) * sampling_rate)\n",
    "    elif len(s_pick) > 0:\n",
    "        ts = UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30\n",
    "        i1 = int((ts-10) * sampling_rate)\n",
    "        i2 = int((ts+10) * sampling_rate)\n",
    "    else:\n",
    "        print(f\"WARNING: No pick time for {network}.{station}.{channel} on {otime}.\")\n",
    "\n",
    "\n",
    "\n",
    "    offsets1 = dist\n",
    "    # print(offsets1)\n",
    "    try: \n",
    "        wave = tr.data\n",
    "        wave = wave / (np.nanmax(wave[i1:i2], axis=-1) * 10)\n",
    "    except:\n",
    "        continue \n",
    "\n",
    "    # Plot the waveform\n",
    "    axs[0,1].plot(tr.times(), wave * scaling_factor + offsets1, \n",
    "                    color='black', alpha=0.7, lw=0.5)\n",
    "    if len(p_pick) > 0:\n",
    "        axs[0,1].vlines(UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                        offsets1 + (1/12) * scaling_factor, color='r')\n",
    "    if len(s_pick) > 0:\n",
    "        axs[0,1].vlines(UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                        offsets1 + (1/12) * scaling_factor, color='b')\n",
    "    station = item[0]+'.'+item[1]+'.'\n",
    "    offsets1 = item[-3]\n",
    "    axs[0,1].text(max_x, offsets1-4, \n",
    "                    station, fontsize=8, color='red', verticalalignment='bottom')\n",
    "    \n",
    "\n",
    "    \n",
    "    axs[0,1].set_ylim([min_y-(1/8) * scaling_factor, max_y+(1/8) * scaling_factor])\n",
    "    axs[0,1].set_xlim([min_x, max_x])\n",
    "    axs[0,1].grid(alpha=0.5)\n",
    "    \n",
    "    \n",
    "\n",
    "    x_sta,y_sta = m1(slon,slat)\n",
    "    m1.plot(x_sta, y_sta, '^', color='#E69F00', markersize=6.2)\n",
    "axs[0,1].set_xlabel('Offset from the Origin Time [s]',fontsize=14)\n",
    "# axs[1,0].set_ylabel('Epicentral Distance [km]',x=0.09,fontsize=14)\n",
    "axs[0,1].text(min_x, max_y+(1/8) * scaling_factor, \n",
    "                'b', fontsize=24, color='black', verticalalignment='bottom')\n",
    "\n",
    "# Update the title of the subplot with the shortened otime\n",
    "formatted_otime = otime.strftime('%Y-%m-%d %H:%M')\n",
    "axs[0,2].set_title(f\"{formatted_otime}\", fontsize=14)\n",
    "\n",
    "# # # Plot the event location\n",
    "x_event,y_event = m1(olon,olat)\n",
    "m1.plot(x_event, y_event, 'o',color='#E69F00', markersize=7.2)\n",
    "m1.plot(x_event+180, y_event+180, 'o',color='#E69F00', markersize=7.2,label='b')\n",
    "\n",
    "###################################################\n",
    "event_idx = 55331\n",
    "event_picks = picks[picks.idx==event_idx]\n",
    "event_stations = event_picks.station.unique()\n",
    "# print(event_picks)\n",
    "\n",
    "otime = UTCDateTime(pd.to_datetime(event_picks.iloc[0].time))\n",
    "olat = event_picks.iloc[0].latitude\n",
    "olon = event_picks.iloc[0].longitude\n",
    "odepth = event_picks.iloc[0].depth\n",
    "\n",
    "tstring = otime.strftime('%Y%m%dT%H%M%SZ')\n",
    "# path = dir + f\"{tstring}.png\"\n",
    "# if os.path.exists(path):\n",
    "#     print(f\"File {path} already exists. Skipping.\")\n",
    "#     continue\n",
    "\n",
    "bulk_sta = []\n",
    "for sta in event_stations:\n",
    "    network = sta.split('.')[0]\n",
    "    station = sta.split('.')[1]\n",
    "    loc = '*'\n",
    "    ch = '?H?' \n",
    "    t1 = otime- pd.Timedelta(1,'days')\n",
    "    t2 = otime + pd.Timedelta(1,'days')\n",
    "\n",
    "    bulk_sta.append([network,station,loc,ch,t1,t2])\n",
    "    \n",
    "inv = client_iris.get_stations_bulk(bulk_sta)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "\n",
    "distances = []\n",
    "for network in inv:\n",
    "    network_code = network.code\n",
    "    for sta in network:\n",
    "        station_code = sta.code\n",
    "        slat = sta.latitude\n",
    "        slon = sta.longitude\n",
    "        selev = sta.elevation\n",
    "        \n",
    "        dis1 = locations2degrees(olat, olon, slat, slon)\n",
    "        dist = degrees2kilometers(dis1)\n",
    "\n",
    "        distances.append([network_code,station_code,olat,olon,odepth,slat,slon,selev,dist])\n",
    "        \n",
    "# Sort distances\n",
    "distances = sorted(distances, key=lambda item: item[-1])\n",
    "st = Stream()\n",
    "\n",
    "starttime = otime - 30\n",
    "endtime = otime + 200\n",
    "ch = '?H?'\n",
    "loc = '*'\n",
    "\n",
    "# Set up to define the xlim and ylim\n",
    "max_y = 0\n",
    "min_y = 0\n",
    "min_y_count = 0 \n",
    "\n",
    "max_x = 0\n",
    "min_x = 0\n",
    "min_x_count= 0\n",
    "\n",
    "bulk_ncedc = []\n",
    "bulk_pnw = []\n",
    "\n",
    "for item in distances:\n",
    "    network_code, station_code, olat, olon, odepth, slat, slon, selev, dist = item\n",
    "\n",
    "    # Make a bulk request for the waveforms\n",
    "    if network_code in ['NC','BK']:\n",
    "        bulk_ncedc.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "    else:\n",
    "        bulk_pnw.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "    \n",
    "\n",
    "    # Adjust the time window and scaling of the data\n",
    "    station = network_code+'.'+station_code\n",
    "    p_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='P')]\n",
    "    s_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='S')]\n",
    "    # Append p_pick and s_pick to distances\n",
    "    item.extend([p_pick,s_pick])\n",
    "    if len(p_pick)==0 and len(s_pick)==0:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue\n",
    "\n",
    "    if len(s_pick) > 0:\n",
    "        if max_x < UTCDateTime(s_pick.iloc[0]['time_pick']) - starttime:\n",
    "            max_x = UTCDateTime(s_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5) - starttime\n",
    "    elif len(p_pick) > 0:\n",
    "        if max_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime: \n",
    "            max_x = UTCDateTime(p_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5)- starttime\n",
    "    else:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue \n",
    "\n",
    "    if len(p_pick) > 0:\n",
    "        if min_x_count == 0:\n",
    "            if min_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                min_x = UTCDateTime(p_pick.iloc[0]['time_pick']) -pd.Timedelta(seconds=5) - starttime\n",
    "                min_x_count += 1           \n",
    "        else:\n",
    "            if min_x >= UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                min_x = UTCDateTime(p_pick.iloc[0]['time_pick'])-pd.Timedelta(seconds=5) - starttime            \n",
    "    elif len(s_pick) > 0:\n",
    "        if min_x_count == 0:\n",
    "            if min_x < UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5)- starttime\n",
    "                min_x_count += 1                \n",
    "        else:\n",
    "            if min_x >= UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5) - starttime\n",
    "    else:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue    \n",
    "\n",
    "    if min_y_count == 0:\n",
    "        if min_y < dist:\n",
    "            min_y = dist - 5\n",
    "            min_y_count += 1           \n",
    "    else:\n",
    "        if min_y >= dist:\n",
    "            min_y = dist - 5 \n",
    "\n",
    "    max_y = dist + 5\n",
    "\n",
    "    distances\n",
    "\n",
    "scaling_factor = (1/2) * (max_y - min_y)\n",
    "    \n",
    "# Download the waveforms\n",
    "st_ncedc = Stream()\n",
    "st_pnw = Stream()\n",
    "if len(bulk_ncedc) > 0:\n",
    "    st_ncedc += client_ncedc.get_waveforms_bulk(bulk_ncedc)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "if len(bulk_pnw) > 0:\n",
    "    st_pnw += client_pnw.get_waveforms_bulk(bulk_pnw)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "\n",
    "st = st_ncedc + st_pnw   \n",
    "\n",
    "st = Stream(filter(lambda st: st.stats.sampling_rate > 10, st))\n",
    "st.taper(max_percentage=0.05)\n",
    "st.filter(type='bandpass', freqmin=2, freqmax=25)\n",
    "st.merge(fill_value='interpolate')\n",
    "\n",
    "# # Plot the waveforms\n",
    "# # print('test1',st)\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "for i,item in enumerate(distances):\n",
    "    network_code, station_code, olat, olon, odepth, slat, slon, selev, dist,p_pick,s_pick = item\n",
    "    st_sta = st.select(network=network_code,station=station_code)\n",
    "\n",
    "    # Select only HH or BH channels\n",
    "    _st = Stream()\n",
    "    has_HH = bool(st_sta.select(channel=\"HHZ\"))\n",
    "    has_BH = bool(st_sta.select(channel=\"BHZ\"))\n",
    "    has_EH = bool(st_sta.select(channel=\"EHZ\"))\n",
    "\n",
    "    if has_HH:\n",
    "        # If all HH, BH, EH, and EN channels are present, select only HH\n",
    "        _st += st_sta.select(channel=\"HHZ\")\n",
    "    elif has_BH:\n",
    "        # If BH, EH, and EN channels are present, select only BH\n",
    "        _st += st_sta.select(channel=\"BHZ\")\n",
    "    elif has_EH:\n",
    "        # If only EH and EN channels are present, select only EH\n",
    "        # NTS: This may result in getting only vertical component data - EH? is used for PNSN analog stations\n",
    "        # NTS: This may also be tricky for pulling full day-volumes because the sampling rate shifts for\n",
    "        #      analog stations due to the remote digitization scheme used with analog stations\n",
    "        _st += st_sta.select(channel=\"EHZ\")\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # # Define the desired order of channels\n",
    "    # desired_order = {\n",
    "    #     'Z': ['HHZ', 'BHZ','EHZ'],\n",
    "    #     'N': ['HHN', 'HH1', 'BHN', 'BH1', 'EHN', 'EN1'],\n",
    "    #     'E': ['HHE', 'HH2', 'BHE', 'BH2', 'EHE', 'EN2'],\n",
    "    # }\n",
    "\n",
    "    # Function to map channels to their desired order\n",
    "    # def get_channel_priority(channel):\n",
    "    #     for priority, (key, values) in enumerate(desired_order.items()):\n",
    "    #         if channel in values:\n",
    "    #             return priority\n",
    "    #     return float('inf')  # Return a high value for channels not in the desired order\n",
    "\n",
    "    # # Sort the traces in trim_st based on the desired order\n",
    "    # _st = sorted(_st, key=lambda trace: get_channel_priority(trace.stats.channel))\n",
    "\n",
    "    _st = Stream(_st)\n",
    "    # print(_st)\n",
    "    # for ax in range(len(_st)):\n",
    "    tr = _st[0]\n",
    "    sampling_rate = tr.stats.sampling_rate\n",
    "    channel = tr.stats.channel\n",
    "    \n",
    "    tr = tr.normalize()\n",
    "    \n",
    "    if len(p_pick) > 0:\n",
    "        tp = UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30\n",
    "        i1 = int((tp-5) * sampling_rate)\n",
    "        i2 = int((tp+15) * sampling_rate)\n",
    "    elif len(s_pick) > 0:\n",
    "        ts = UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30\n",
    "        i1 = int((ts-10) * sampling_rate)\n",
    "        i2 = int((ts+10) * sampling_rate)\n",
    "    else:\n",
    "        print(f\"WARNING: No pick time for {network}.{station}.{channel} on {otime}.\")\n",
    "\n",
    "\n",
    "\n",
    "    offsets1 = dist\n",
    "    # print(offsets1)\n",
    "    try: \n",
    "        wave = tr.data\n",
    "        wave = wave / (np.nanmax(wave[i1:i2], axis=-1) * 10)\n",
    "    except:\n",
    "        continue \n",
    "\n",
    "    # Plot the waveform\n",
    "    axs[0,2].plot(tr.times(), wave * scaling_factor + offsets1, \n",
    "                    color='black', alpha=0.7, lw=0.5)\n",
    "    if len(p_pick) > 0:\n",
    "        axs[0,2].vlines(UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                        offsets1 + (1/12) * scaling_factor, color='r')\n",
    "    if len(s_pick) > 0:\n",
    "        axs[0,2].vlines(UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                        offsets1 + (1/12) * scaling_factor, color='b')\n",
    "    station = item[0]+'.'+item[1]+'.'\n",
    "    offsets1 = item[-3]\n",
    "    axs[0,2].text(max_x, offsets1-4, \n",
    "                    station, fontsize=8, color='red', verticalalignment='bottom')\n",
    "    \n",
    "\n",
    "    \n",
    "    axs[0,2].set_ylim([min_y-(1/8) * scaling_factor, max_y+(1/8) * scaling_factor])\n",
    "    axs[0,2].set_xlim([min_x, max_x])\n",
    "    axs[0,2].grid(alpha=0.5)\n",
    "    \n",
    "    \n",
    "\n",
    "    x_sta,y_sta = m1(slon,slat)\n",
    "    m1.plot(x_sta, y_sta, '^', color='#0072B2', markersize=6.2)\n",
    "axs[0,2].set_xlabel('Offset from the Origin Time [s]',fontsize=14)\n",
    "# axs[1,0].set_ylabel('Epicentral Distance [km]',x=0.09,fontsize=14)\n",
    "axs[0,2].text(min_x, max_y+(1/8) * scaling_factor, \n",
    "                'c', fontsize=24, color='black', verticalalignment='bottom')\n",
    "# Update the title of the subplot with the shortened otime\n",
    "formatted_otime = otime.strftime('%Y-%m-%d %H:%M')\n",
    "axs[1,0].set_title(f\"{formatted_otime}\", fontsize=14)\n",
    "\n",
    "\n",
    "# # # Plot the event location\n",
    "x_event,y_event = m1(olon,olat)\n",
    "m1.plot(x_event, y_event, 'o',color='#0072B2', markersize=7.2)\n",
    "m1.plot(x_event+180, y_event+180, 'o',color='#0072B2', markersize=7.2,label='c')\n",
    "\n",
    "###################################################\n",
    "event_idx = 29\n",
    "event_picks = picks[picks.idx==event_idx]\n",
    "event_stations = event_picks.station.unique()\n",
    "# print(event_picks)\n",
    "\n",
    "otime = UTCDateTime(pd.to_datetime(event_picks.iloc[0].time))\n",
    "olat = event_picks.iloc[0].latitude\n",
    "olon = event_picks.iloc[0].longitude\n",
    "odepth = event_picks.iloc[0].depth\n",
    "\n",
    "tstring = otime.strftime('%Y%m%dT%H%M%SZ')\n",
    "# path = dir + f\"{tstring}.png\"\n",
    "# if os.path.exists(path):\n",
    "#     print(f\"File {path} already exists. Skipping.\")\n",
    "#     continue\n",
    "\n",
    "bulk_sta = []\n",
    "for sta in event_stations:\n",
    "    network = sta.split('.')[0]\n",
    "    station = sta.split('.')[1]\n",
    "    loc = '*'\n",
    "    ch = '?H?' \n",
    "    t1 = otime- pd.Timedelta(1,'days')\n",
    "    t2 = otime + pd.Timedelta(1,'days')\n",
    "\n",
    "    bulk_sta.append([network,station,loc,ch,t1,t2])\n",
    "    \n",
    "inv = client_iris.get_stations_bulk(bulk_sta)\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "\n",
    "distances = []\n",
    "for network in inv:\n",
    "    network_code = network.code\n",
    "    for sta in network:\n",
    "        station_code = sta.code\n",
    "        slat = sta.latitude\n",
    "        slon = sta.longitude\n",
    "        selev = sta.elevation\n",
    "        \n",
    "        dis1 = locations2degrees(olat, olon, slat, slon)\n",
    "        dist = degrees2kilometers(dis1)\n",
    "\n",
    "        distances.append([network_code,station_code,olat,olon,odepth,slat,slon,selev,dist])\n",
    "        \n",
    "# Sort distances\n",
    "distances = sorted(distances, key=lambda item: item[-1])\n",
    "st = Stream()\n",
    "\n",
    "starttime = otime - 30\n",
    "endtime = otime + 200\n",
    "ch = '?H?'\n",
    "loc = '*'\n",
    "\n",
    "# Set up to define the xlim and ylim\n",
    "max_y = 0\n",
    "min_y = 0\n",
    "min_y_count = 0 \n",
    "\n",
    "max_x = 0\n",
    "min_x = 0\n",
    "min_x_count= 0\n",
    "\n",
    "bulk_ncedc = []\n",
    "bulk_pnw = []\n",
    "\n",
    "for item in distances:\n",
    "    network_code, station_code, olat, olon, odepth, slat, slon, selev, dist = item\n",
    "\n",
    "    # Make a bulk request for the waveforms\n",
    "    if network_code in ['NC','BK']:\n",
    "        bulk_ncedc.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "    else:\n",
    "        bulk_pnw.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "    \n",
    "\n",
    "    # Adjust the time window and scaling of the data\n",
    "    station = network_code+'.'+station_code\n",
    "    p_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='P')]\n",
    "    s_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='S')]\n",
    "    # Append p_pick and s_pick to distances\n",
    "    item.extend([p_pick,s_pick])\n",
    "    if len(p_pick)==0 and len(s_pick)==0:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue\n",
    "\n",
    "    if len(s_pick) > 0:\n",
    "        if max_x < UTCDateTime(s_pick.iloc[0]['time_pick']) - starttime:\n",
    "            max_x = UTCDateTime(s_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5) - starttime\n",
    "    elif len(p_pick) > 0:\n",
    "        if max_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime: \n",
    "            max_x = UTCDateTime(p_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5)- starttime\n",
    "    else:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue \n",
    "\n",
    "    if len(p_pick) > 0:\n",
    "        if min_x_count == 0:\n",
    "            if min_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                min_x = UTCDateTime(p_pick.iloc[0]['time_pick']) -pd.Timedelta(seconds=5) - starttime\n",
    "                min_x_count += 1           \n",
    "        else:\n",
    "            if min_x >= UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                min_x = UTCDateTime(p_pick.iloc[0]['time_pick'])-pd.Timedelta(seconds=5) - starttime            \n",
    "    elif len(s_pick) > 0:\n",
    "        if min_x_count == 0:\n",
    "            if min_x < UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5)- starttime\n",
    "                min_x_count += 1                \n",
    "        else:\n",
    "            if min_x >= UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5) - starttime\n",
    "    else:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue    \n",
    "\n",
    "    if min_y_count == 0:\n",
    "        if min_y < dist:\n",
    "            min_y = dist - 5\n",
    "            min_y_count += 1           \n",
    "    else:\n",
    "        if min_y >= dist:\n",
    "            min_y = dist - 5 \n",
    "\n",
    "    max_y = dist + 5\n",
    "\n",
    "    distances\n",
    "\n",
    "scaling_factor = (1/2) * (max_y - min_y)\n",
    "    \n",
    "# Download the waveforms\n",
    "st_ncedc = Stream()\n",
    "st_pnw = Stream()\n",
    "if len(bulk_ncedc) > 0:\n",
    "    st_ncedc += client_ncedc.get_waveforms_bulk(bulk_ncedc)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "if len(bulk_pnw) > 0:\n",
    "    st_pnw += client_pnw.get_waveforms_bulk(bulk_pnw)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "\n",
    "st = st_ncedc + st_pnw   \n",
    "\n",
    "st = Stream(filter(lambda st: st.stats.sampling_rate > 10, st))\n",
    "st.taper(max_percentage=0.05)\n",
    "st.filter(type='bandpass', freqmin=2, freqmax=25)\n",
    "st.merge(fill_value='interpolate')\n",
    "\n",
    "# # Plot the waveforms\n",
    "# # print('test1',st)\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "for i,item in enumerate(distances):\n",
    "    network_code, station_code, olat, olon, odepth, slat, slon, selev, dist,p_pick,s_pick = item\n",
    "    st_sta = st.select(network=network_code,station=station_code)\n",
    "\n",
    "    # Select only HH or BH channels\n",
    "    _st = Stream()\n",
    "    has_HH = bool(st_sta.select(channel=\"HHZ\"))\n",
    "    has_BH = bool(st_sta.select(channel=\"BHZ\"))\n",
    "    has_EH = bool(st_sta.select(channel=\"EHZ\"))\n",
    "\n",
    "    if has_HH:\n",
    "        # If all HH, BH, EH, and EN channels are present, select only HH\n",
    "        _st += st_sta.select(channel=\"HHZ\")\n",
    "    elif has_BH:\n",
    "        # If BH, EH, and EN channels are present, select only BH\n",
    "        _st += st_sta.select(channel=\"BHZ\")\n",
    "    elif has_EH:\n",
    "        # If only EH and EN channels are present, select only EH\n",
    "        # NTS: This may result in getting only vertical component data - EH? is used for PNSN analog stations\n",
    "        # NTS: This may also be tricky for pulling full day-volumes because the sampling rate shifts for\n",
    "        #      analog stations due to the remote digitization scheme used with analog stations\n",
    "        _st += st_sta.select(channel=\"EHZ\")\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # # Define the desired order of channels\n",
    "    # desired_order = {\n",
    "    #     'Z': ['HHZ', 'BHZ','EHZ'],\n",
    "    #     'N': ['HHN', 'HH1', 'BHN', 'BH1', 'EHN', 'EN1'],\n",
    "    #     'E': ['HHE', 'HH2', 'BHE', 'BH2', 'EHE', 'EN2'],\n",
    "    # }\n",
    "\n",
    "    # Function to map channels to their desired order\n",
    "    # def get_channel_priority(channel):\n",
    "    #     for priority, (key, values) in enumerate(desired_order.items()):\n",
    "    #         if channel in values:\n",
    "    #             return priority\n",
    "    #     return float('inf')  # Return a high value for channels not in the desired order\n",
    "\n",
    "    # # Sort the traces in trim_st based on the desired order\n",
    "    # _st = sorted(_st, key=lambda trace: get_channel_priority(trace.stats.channel))\n",
    "\n",
    "    _st = Stream(_st)\n",
    "    # print(_st)\n",
    "    # for ax in range(len(_st)):\n",
    "    tr = _st[0]\n",
    "    sampling_rate = tr.stats.sampling_rate\n",
    "    channel = tr.stats.channel\n",
    "    \n",
    "    tr = tr.normalize()\n",
    "    \n",
    "    if len(p_pick) > 0:\n",
    "        tp = UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30\n",
    "        i1 = int((tp-5) * sampling_rate)\n",
    "        i2 = int((tp+15) * sampling_rate)\n",
    "    elif len(s_pick) > 0:\n",
    "        ts = UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30\n",
    "        i1 = int((ts-10) * sampling_rate)\n",
    "        i2 = int((ts+10) * sampling_rate)\n",
    "    else:\n",
    "        print(f\"WARNING: No pick time for {network}.{station}.{channel} on {otime}.\")\n",
    "\n",
    "\n",
    "\n",
    "    offsets1 = dist\n",
    "    # print(offsets1)\n",
    "    try: \n",
    "        wave = tr.data\n",
    "        wave = wave / (np.nanmax(wave[i1:i2], axis=-1) * 10)\n",
    "    except:\n",
    "        continue \n",
    "\n",
    "    # Plot the waveform\n",
    "    axs[1,1].plot(tr.times(), wave * scaling_factor + offsets1, \n",
    "                    color='black', alpha=0.7, lw=0.5)\n",
    "    if len(p_pick) > 0:\n",
    "        axs[1,1].vlines(UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                        offsets1 + (1/12) * scaling_factor, color='r')\n",
    "    if len(s_pick) > 0:\n",
    "        axs[1,1].vlines(UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                        offsets1 + (1/12) * scaling_factor, color='b')\n",
    "    station = item[0]+'.'+item[1]+'.'\n",
    "    offsets1 = item[-3]\n",
    "    axs[1,1].text(max_x, offsets1-4, \n",
    "                    station, fontsize=8, color='red', verticalalignment='bottom')\n",
    "    \n",
    "\n",
    "    \n",
    "    axs[1,1].set_ylim([min_y-(1/8) * scaling_factor, max_y+(1/8) * scaling_factor])\n",
    "    axs[1,1].set_xlim([min_x, max_x])\n",
    "    axs[1,1].grid(alpha=0.5)\n",
    "    \n",
    "    \n",
    "\n",
    "    x_sta,y_sta = m1(slon,slat)\n",
    "    m2.plot(x_sta, y_sta, '^', color='#56B4E9', markersize=6.2)\n",
    "axs[1,1].set_xlabel('Offset from the Origin Time [s]',fontsize=14)\n",
    "# axs[1,0].set_ylabel('Epicentral Distance [km]',x=0.09,fontsize=14)\n",
    "axs[1,1].text(min_x, max_y+(1/8) * scaling_factor, \n",
    "                'e', fontsize=24, color='black', verticalalignment='bottom')\n",
    "# Update the title of the subplot with the shortened otime\n",
    "formatted_otime = otime.strftime('%Y-%m-%d %H:%M')\n",
    "axs[1,1].set_title(f\"{formatted_otime}\", fontsize=14)\n",
    "\n",
    "\n",
    "# # # Plot the event location\n",
    "x_event,y_event = m1(olon,olat)\n",
    "m2.plot(x_event, y_event, 'o',color='#56B4E9', markersize=7.2)\n",
    "m2.plot(x_event+180, y_event+180, 'o',color='#56B4E9', markersize=7.2,label='e')\n",
    "\n",
    "###################################################\n",
    "event_idx = 54736\n",
    "event_picks = picks[picks.idx==event_idx]\n",
    "event_stations = event_picks.station.unique()\n",
    "# print(event_picks)\n",
    "\n",
    "otime = UTCDateTime(pd.to_datetime(event_picks.iloc[0].time))\n",
    "olat = event_picks.iloc[0].latitude\n",
    "olon = event_picks.iloc[0].longitude\n",
    "odepth = event_picks.iloc[0].depth\n",
    "\n",
    "tstring = otime.strftime('%Y%m%dT%H%M%SZ')\n",
    "# path = dir + f\"{tstring}.png\"\n",
    "# if os.path.exists(path):\n",
    "#     print(f\"File {path} already exists. Skipping.\")\n",
    "#     continue\n",
    "\n",
    "bulk_sta = []\n",
    "for sta in event_stations:\n",
    "    network = sta.split('.')[0]\n",
    "    station = sta.split('.')[1]\n",
    "    loc = '*'\n",
    "    ch = '?H?' \n",
    "    t1 = otime- pd.Timedelta(1,'days')\n",
    "    t2 = otime + pd.Timedelta(1,'days')\n",
    "\n",
    "    bulk_sta.append([network,station,loc,ch,t1,t2])\n",
    "    \n",
    "inv = client_iris.get_stations_bulk(bulk_sta)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "\n",
    "distances = []\n",
    "for network in inv:\n",
    "    network_code = network.code\n",
    "    for sta in network:\n",
    "        station_code = sta.code\n",
    "        slat = sta.latitude\n",
    "        slon = sta.longitude\n",
    "        selev = sta.elevation\n",
    "        \n",
    "        dis1 = locations2degrees(olat, olon, slat, slon)\n",
    "        dist = degrees2kilometers(dis1)\n",
    "\n",
    "        distances.append([network_code,station_code,olat,olon,odepth,slat,slon,selev,dist])\n",
    "        \n",
    "# Sort distances\n",
    "distances = sorted(distances, key=lambda item: item[-1])\n",
    "st = Stream()\n",
    "\n",
    "starttime = otime - 30\n",
    "endtime = otime + 200\n",
    "ch = '?H?'\n",
    "loc = '*'\n",
    "\n",
    "# Set up to define the xlim and ylim\n",
    "max_y = 0\n",
    "min_y = 0\n",
    "min_y_count = 0 \n",
    "\n",
    "max_x = 0\n",
    "min_x = 0\n",
    "min_x_count= 0\n",
    "\n",
    "bulk_ncedc = []\n",
    "bulk_pnw = []\n",
    "\n",
    "for item in distances:\n",
    "    network_code, station_code, olat, olon, odepth, slat, slon, selev, dist = item\n",
    "\n",
    "    # Make a bulk request for the waveforms\n",
    "    if network_code in ['NC','BK']:\n",
    "        bulk_ncedc.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "    else:\n",
    "        bulk_pnw.append([network_code,station_code,loc,ch,starttime,endtime])\n",
    "    \n",
    "\n",
    "    # Adjust the time window and scaling of the data\n",
    "    station = network_code+'.'+station_code\n",
    "    p_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='P')]\n",
    "    s_pick = event_picks.loc[(event_picks.station==station)&(event_picks.phase=='S')]\n",
    "    # Append p_pick and s_pick to distances\n",
    "    item.extend([p_pick,s_pick])\n",
    "    if len(p_pick)==0 and len(s_pick)==0:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue\n",
    "\n",
    "    if len(s_pick) > 0:\n",
    "        if max_x < UTCDateTime(s_pick.iloc[0]['time_pick']) - starttime:\n",
    "            max_x = UTCDateTime(s_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5) - starttime\n",
    "    elif len(p_pick) > 0:\n",
    "        if max_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime: \n",
    "            max_x = UTCDateTime(p_pick.iloc[0]['time_pick']) + pd.Timedelta(seconds=5)- starttime\n",
    "    else:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue \n",
    "\n",
    "    if len(p_pick) > 0:\n",
    "        if min_x_count == 0:\n",
    "            if min_x < UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                min_x = UTCDateTime(p_pick.iloc[0]['time_pick']) -pd.Timedelta(seconds=5) - starttime\n",
    "                min_x_count += 1           \n",
    "        else:\n",
    "            if min_x >= UTCDateTime(p_pick.iloc[0]['time_pick']) - starttime:\n",
    "                min_x = UTCDateTime(p_pick.iloc[0]['time_pick'])-pd.Timedelta(seconds=5) - starttime            \n",
    "    elif len(s_pick) > 0:\n",
    "        if min_x_count == 0:\n",
    "            if min_x < UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5)- starttime\n",
    "                min_x_count += 1                \n",
    "        else:\n",
    "            if min_x >= UTCDateTime(s_pick.iloc[0]['time_pick'])- starttime:\n",
    "                min_x = UTCDateTime(s_pick.iloc[0]['time_pick']) - pd.Timedelta(seconds=5) - starttime\n",
    "    else:\n",
    "        print('No picks for this station. Skipping.')\n",
    "        continue    \n",
    "\n",
    "    if min_y_count == 0:\n",
    "        if min_y < dist:\n",
    "            min_y = dist - 5\n",
    "            min_y_count += 1           \n",
    "    else:\n",
    "        if min_y >= dist:\n",
    "            min_y = dist - 5 \n",
    "\n",
    "    max_y = dist + 5\n",
    "\n",
    "    distances\n",
    "\n",
    "scaling_factor = (1/2) * (max_y - min_y)\n",
    "    \n",
    "# Download the waveforms\n",
    "st_ncedc = Stream()\n",
    "st_pnw = Stream()\n",
    "if len(bulk_ncedc) > 0:\n",
    "    st_ncedc += client_ncedc.get_waveforms_bulk(bulk_ncedc)\n",
    "\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "if len(bulk_pnw) > 0:\n",
    "    st_pnw += client_pnw.get_waveforms_bulk(bulk_pnw)\n",
    "\n",
    "time.sleep(0.1) # Pause the execution for 0.1 sec\n",
    "\n",
    "\n",
    "st = st_ncedc + st_pnw   \n",
    "\n",
    "st = Stream(filter(lambda st: st.stats.sampling_rate > 10, st))\n",
    "st.taper(max_percentage=0.05)\n",
    "st.filter(type='bandpass', freqmin=2, freqmax=25)\n",
    "st.merge(fill_value='interpolate')\n",
    "\n",
    "# # Plot the waveforms\n",
    "# # print('test1',st)\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "for i,item in enumerate(distances):\n",
    "    network_code, station_code, olat, olon, odepth, slat, slon, selev, dist,p_pick,s_pick = item\n",
    "    st_sta = st.select(network=network_code,station=station_code)\n",
    "\n",
    "    # Select only HH or BH channels\n",
    "    _st = Stream()\n",
    "    has_HH = bool(st_sta.select(channel=\"HHZ\"))\n",
    "    has_BH = bool(st_sta.select(channel=\"BHZ\"))\n",
    "    has_EH = bool(st_sta.select(channel=\"EHZ\"))\n",
    "\n",
    "    if has_HH:\n",
    "        # If all HH, BH, EH, and EN channels are present, select only HH\n",
    "        _st += st_sta.select(channel=\"HHZ\")\n",
    "    elif has_BH:\n",
    "        # If BH, EH, and EN channels are present, select only BH\n",
    "        _st += st_sta.select(channel=\"BHZ\")\n",
    "    elif has_EH:\n",
    "        # If only EH and EN channels are present, select only EH\n",
    "        # NTS: This may result in getting only vertical component data - EH? is used for PNSN analog stations\n",
    "        # NTS: This may also be tricky for pulling full day-volumes because the sampling rate shifts for\n",
    "        #      analog stations due to the remote digitization scheme used with analog stations\n",
    "        _st += st_sta.select(channel=\"EHZ\")\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # # Define the desired order of channels\n",
    "    # desired_order = {\n",
    "    #     'Z': ['HHZ', 'BHZ','EHZ'],\n",
    "    #     'N': ['HHN', 'HH1', 'BHN', 'BH1', 'EHN', 'EN1'],\n",
    "    #     'E': ['HHE', 'HH2', 'BHE', 'BH2', 'EHE', 'EN2'],\n",
    "    # }\n",
    "\n",
    "    # Function to map channels to their desired order\n",
    "    # def get_channel_priority(channel):\n",
    "    #     for priority, (key, values) in enumerate(desired_order.items()):\n",
    "    #         if channel in values:\n",
    "    #             return priority\n",
    "    #     return float('inf')  # Return a high value for channels not in the desired order\n",
    "\n",
    "    # # Sort the traces in trim_st based on the desired order\n",
    "    # _st = sorted(_st, key=lambda trace: get_channel_priority(trace.stats.channel))\n",
    "\n",
    "    _st = Stream(_st)\n",
    "    # print(_st)\n",
    "    # for ax in range(len(_st)):\n",
    "    tr = _st[0]\n",
    "    sampling_rate = tr.stats.sampling_rate\n",
    "    channel = tr.stats.channel\n",
    "    \n",
    "    tr = tr.normalize()\n",
    "    \n",
    "    if len(p_pick) > 0:\n",
    "        tp = UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30\n",
    "        i1 = int((tp-5) * sampling_rate)\n",
    "        i2 = int((tp+15) * sampling_rate)\n",
    "    elif len(s_pick) > 0:\n",
    "        ts = UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30\n",
    "        i1 = int((ts-10) * sampling_rate)\n",
    "        i2 = int((ts+10) * sampling_rate)\n",
    "    else:\n",
    "        print(f\"WARNING: No pick time for {network}.{station}.{channel} on {otime}.\")\n",
    "\n",
    "\n",
    "\n",
    "    offsets1 = dist\n",
    "    # print(offsets1)\n",
    "    try: \n",
    "        wave = tr.data\n",
    "        wave = wave / (np.nanmax(wave[i1:i2], axis=-1) * 10)\n",
    "    except:\n",
    "        continue \n",
    "\n",
    "    # Plot the waveform\n",
    "    axs[1,2].plot(tr.times(), wave * scaling_factor + offsets1, \n",
    "                    color='black', alpha=0.7, lw=0.5)\n",
    "    if len(p_pick) > 0:\n",
    "        axs[1,2].vlines(UTCDateTime(p_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                        offsets1 + (1/12) * scaling_factor, color='r')\n",
    "    if len(s_pick) > 0:\n",
    "        axs[1,2].vlines(UTCDateTime(s_pick.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/12) * scaling_factor, \n",
    "                        offsets1 + (1/12) * scaling_factor, color='b')\n",
    "    station = item[0]+'.'+item[1]+'.'\n",
    "    offsets1 = item[-3]\n",
    "    axs[1,2].text(max_x, offsets1-4, \n",
    "                    station, fontsize=8, color='red', verticalalignment='bottom')\n",
    "    \n",
    "\n",
    "    \n",
    "    axs[1,2].set_ylim([min_y-(1/8) * scaling_factor, max_y+(1/8) * scaling_factor])\n",
    "    axs[1,2].set_xlim([min_x, max_x])\n",
    "    axs[1,2].grid(alpha=0.5)\n",
    "    \n",
    "    \n",
    "\n",
    "    x_sta,y_sta = m1(slon,slat)\n",
    "    m2.plot(x_sta, y_sta, '^', color='#D55E00', markersize=6.2)\n",
    "axs[1,2].set_xlabel('Offset from the Origin Time [s]',fontsize=14)\n",
    "# axs[1,0].set_ylabel('Epicentral Distance [km]',x=0.09,fontsize=14)\n",
    "axs[1,2].text(min_x, max_y+(1/8) * scaling_factor, \n",
    "                'f', fontsize=24, color='black', verticalalignment='bottom')\n",
    "\n",
    "# Update the title of the subplot with the shortened otime\n",
    "formatted_otime = otime.strftime('%Y-%m-%d %H:%M')\n",
    "axs[1,2].set_title(f\"{formatted_otime}\", fontsize=14)\n",
    "\n",
    "\n",
    "\n",
    "# # # Plot the event location\n",
    "x_event,y_event = m1(olon,olat)\n",
    "m2.plot(x_event, y_event, 'o',color='#D55E00', markersize=7.2)\n",
    "m2.plot(x_event+180, y_event+180, 'o',color='#D55E00', markersize=7.2,label='f')\n",
    "\n",
    "###################################################\n",
    "axs[0,3].legend(loc='upper right', fontsize=14,handletextpad=0)\n",
    "axs[1,3].legend(loc='upper right', fontsize=14,handletextpad=0)\n",
    "\n",
    "###################################################\n",
    "\n",
    "\n",
    "fig.savefig(f\"/wd1/hbito_data/data/datasets_all_regions/fig3/fig3_panel_a_scale_by_{str(add_scale_panel_a).replace('.', 'over')}_alpha_{str(alpha_panel_a).replace('.', '_')}_panel_b_scale_by_{str(add_scale_panel_b).replace('.', 'over')}_alpha_{str(alpha_panel_b).replace('.', '_')}.png\",format='png')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['7D',\n",
       "  'M15D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  42.210701,\n",
       "  -124.907402,\n",
       "  -933.0,\n",
       "  41.953914244880146,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848380  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848380    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848380  1.430578  6845.349945   57.044612    848380  7D.M15D     P   \n",
       "  \n",
       "             time_pick  \n",
       "  848380  1.417095e+09  ,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: []],\n",
       " ['7D',\n",
       "  'G34D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  42.5723,\n",
       "  -125.448601,\n",
       "  -3089.0,\n",
       "  91.51830034992189,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: [],\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848385  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848385    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848385  1.430578  6845.349945   57.044612    848385  7D.G34D     S   \n",
       "  \n",
       "             time_pick  \n",
       "  848385  1.417095e+09  ],\n",
       " ['7D',\n",
       "  'M14D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  42.913601,\n",
       "  -124.977898,\n",
       "  -997.0,\n",
       "  119.94564838364458,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848381  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848381    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848381  1.430578  6845.349945   57.044612    848381  7D.M14D     P   \n",
       "  \n",
       "             time_pick  \n",
       "  848381  1.417095e+09  ,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848386  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848386    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848386  1.430578  6845.349945   57.044612    848386  7D.M14D     S   \n",
       "  \n",
       "             time_pick  \n",
       "  848386  1.417095e+09  ],\n",
       " ['7D',\n",
       "  'J09D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  43.151402,\n",
       "  -124.727097,\n",
       "  -252.0,\n",
       "  147.55737195063037,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: [],\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848387  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848387    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848387  1.430578  6845.349945   57.044612    848387  7D.J09D     S   \n",
       "  \n",
       "             time_pick  \n",
       "  848387  1.417095e+09  ],\n",
       " ['7D',\n",
       "  'FS13D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  40.493698,\n",
       "  -124.803398,\n",
       "  -2291.2,\n",
       "  149.68714310549788,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848383  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848383    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx   station phase  \\\n",
       "  848383  1.430578  6845.349945   57.044612    848383  7D.FS13D     P   \n",
       "  \n",
       "             time_pick  \n",
       "  848383  1.417095e+09  ,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: []],\n",
       " ['7D',\n",
       "  'FS02D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  40.326,\n",
       "  -124.800201,\n",
       "  -947.9,\n",
       "  168.29644801948245,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848382  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848382    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx   station phase  \\\n",
       "  848382  1.430578  6845.349945   57.044612    848382  7D.FS02D     P   \n",
       "  \n",
       "             time_pick  \n",
       "  848382  1.417095e+09  ,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: []],\n",
       " ['7D',\n",
       "  'G36D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  42.4618,\n",
       "  -126.8965,\n",
       "  -3779.6,\n",
       "  174.5905982724045,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: [],\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848388  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848388    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848388  1.430578  6845.349945   57.044612    848388  7D.G36D     S   \n",
       "  \n",
       "             time_pick  \n",
       "  848388  1.417095e+09  ],\n",
       " ['7D',\n",
       "  'J18D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  43.9772,\n",
       "  -125.4814,\n",
       "  -3050.0,\n",
       "  242.0277623231244,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848384  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848384    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848384  1.430578  6845.349945   57.044612    848384  7D.J18D     P   \n",
       "  \n",
       "             time_pick  \n",
       "  848384  1.417095e+09  ,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848389  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848389    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848389  1.430578  6845.349945   57.044612    848389  7D.J18D     S   \n",
       "  \n",
       "             time_pick  \n",
       "  848389  1.417095e+09  ],\n",
       " ['7D',\n",
       "  'J25D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  44.456699,\n",
       "  -124.630997,\n",
       "  -136.0,\n",
       "  292.69497288639667,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: [],\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848390  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848390    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848390  1.430578  6845.349945   57.044612    848390  7D.J25D     S   \n",
       "  \n",
       "             time_pick  \n",
       "  848390  1.417095e+09  ]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distances of a successful run\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['7D',\n",
       "  'M15D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  42.210701,\n",
       "  -124.907402,\n",
       "  -933.0,\n",
       "  41.953914244880146,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848380  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848380    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848380  1.430578  6845.349945   57.044612    848380  7D.M15D     P   \n",
       "  \n",
       "             time_pick  \n",
       "  848380  1.417095e+09  ,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: []],\n",
       " ['7D',\n",
       "  'G34D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  42.5723,\n",
       "  -125.448601,\n",
       "  -3089.0,\n",
       "  91.51830034992189,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: [],\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848385  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848385    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848385  1.430578  6845.349945   57.044612    848385  7D.G34D     S   \n",
       "  \n",
       "             time_pick  \n",
       "  848385  1.417095e+09  ],\n",
       " ['7D',\n",
       "  'M14D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  42.913601,\n",
       "  -124.977898,\n",
       "  -997.0,\n",
       "  119.94564838364458,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848381  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848381    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848381  1.430578  6845.349945   57.044612    848381  7D.M14D     P   \n",
       "  \n",
       "             time_pick  \n",
       "  848381  1.417095e+09  ,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848386  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848386    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848386  1.430578  6845.349945   57.044612    848386  7D.M14D     S   \n",
       "  \n",
       "             time_pick  \n",
       "  848386  1.417095e+09  ],\n",
       " ['7D',\n",
       "  'J09D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  43.151402,\n",
       "  -124.727097,\n",
       "  -252.0,\n",
       "  147.55737195063037,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: [],\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848387  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848387    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848387  1.430578  6845.349945   57.044612    848387  7D.J09D     S   \n",
       "  \n",
       "             time_pick  \n",
       "  848387  1.417095e+09  ],\n",
       " ['7D',\n",
       "  'FS13D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  40.493698,\n",
       "  -124.803398,\n",
       "  -2291.2,\n",
       "  149.68714310549788,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848383  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848383    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx   station phase  \\\n",
       "  848383  1.430578  6845.349945   57.044612    848383  7D.FS13D     P   \n",
       "  \n",
       "             time_pick  \n",
       "  848383  1.417095e+09  ,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: []],\n",
       " ['7D',\n",
       "  'FS02D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  40.326,\n",
       "  -124.800201,\n",
       "  -947.9,\n",
       "  168.29644801948245,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848382  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848382    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx   station phase  \\\n",
       "  848382  1.430578  6845.349945   57.044612    848382  7D.FS02D     P   \n",
       "  \n",
       "             time_pick  \n",
       "  848382  1.417095e+09  ,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: []],\n",
       " ['7D',\n",
       "  'G36D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  42.4618,\n",
       "  -126.8965,\n",
       "  -3779.6,\n",
       "  174.5905982724045,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: [],\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848388  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848388    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848388  1.430578  6845.349945   57.044612    848388  7D.G36D     S   \n",
       "  \n",
       "             time_pick  \n",
       "  848388  1.417095e+09  ],\n",
       " ['7D',\n",
       "  'J18D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  43.9772,\n",
       "  -125.4814,\n",
       "  -3050.0,\n",
       "  242.0277623231244,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848384  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848384    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848384  1.430578  6845.349945   57.044612    848384  7D.J18D     P   \n",
       "  \n",
       "             time_pick  \n",
       "  848384  1.417095e+09  ,\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848389  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848389    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848389  1.430578  6845.349945   57.044612    848389  7D.J18D     S   \n",
       "  \n",
       "             time_pick  \n",
       "  848389  1.417095e+09  ],\n",
       " ['7D',\n",
       "  'J25D',\n",
       "  41.83504,\n",
       "  -124.9547,\n",
       "  57.795,\n",
       "  44.456699,\n",
       "  -124.630997,\n",
       "  -136.0,\n",
       "  292.69497288639667,\n",
       "  Empty DataFrame\n",
       "  Columns: [latitude, longitude, depth, time, idx, nass, p_picks, s_picks, rms, nsphz, gap, algorithm, id_Morton, dist, dt, NonDimDist, pick_idx, station, phase, time_pick]\n",
       "  Index: [],\n",
       "          latitude  longitude   depth                             time    idx  \\\n",
       "  848390  41.83504  -124.9547  57.795 2014-11-27 13:28:35.349945+00:00  54736   \n",
       "  \n",
       "          nass  p_picks  s_picks   rms  nsphz         gap algorithm  id_Morton  \\\n",
       "  848390    11        5        6  1.51    6.0  167.808554     genie       2838   \n",
       "  \n",
       "              dist           dt  NonDimDist  pick_idx  station phase  \\\n",
       "  848390  1.430578  6845.349945   57.044612    848390  7D.J25D     S   \n",
       "  \n",
       "             time_pick  \n",
       "  848390  1.417095e+09  ]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distances of the unsuccessful run\n",
    "distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "end test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
