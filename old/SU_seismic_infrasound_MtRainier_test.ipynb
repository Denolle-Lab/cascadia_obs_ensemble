{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f6cb81",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Surface Event Analysis with seismic and infrasound\n",
    "\n",
    "This notebooks focuses on data from Mt Rainier by plotting the SU events and the possible infrasound records.\n",
    "\n",
    "\n",
    "Updated 08/17/2023\n",
    "Marine Denolle\n",
    "(mdenolle@uw.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021dc6f",
   "metadata": {},
   "source": [
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf759fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/data/wsd01/pnwstore/')\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import Figure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import obspy\n",
    "from obspy.core import UTCDateTime\n",
    "from obspy.clients.fdsn.client import Client\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "from geopy import distance\n",
    "from datetime import datetime\n",
    "import rasterio as rio\n",
    "import torch\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "from utils import *\n",
    "\n",
    "\n",
    "import seisbench.models as sbm\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "from ELEP.elep.ensemble_statistics import ensemble_statistics\n",
    "from ELEP.elep.ensemble_coherence import ensemble_semblance \n",
    "from ELEP.elep.ensemble_learners import ensemble_regressor_cnn\n",
    "from mbf_elep_func import apply_mbf\n",
    "from ELEP.elep import mbf, mbf_utils\n",
    "from ELEP.elep import trigger_func\n",
    "from ELEP.elep.trigger_func import picks_summary_simple\n",
    "\n",
    "from ELEP.elep.mbf_utils import make_LogFq, make_LinFq, rec_filter_coeff, create_obspy_trace\n",
    "from ELEP.elep.mbf import MB_filter as MBF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd30de3d",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c32de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define clients to download the station data\n",
    "# client = WaveformClient() # we ignore PNWdatastore for now\n",
    "client2 = Client('IRIS')\n",
    "\n",
    "t_before = 15 #number of seconds before pick time\n",
    "# t_after = 15 #number of seconds after pick time\n",
    "t_before_raw = 1200 #number of seconds before pick time before removing instrumental response\n",
    "# t_after_raw = 1200 #number of seconds after pick time before removing instrumental response\n",
    "t_around = 10\n",
    "fs = 40 #sampling rate that all waveforms are resampled to\n",
    "window = 150 #window length of the signal (this will help with phase picking with EqT next). \n",
    "# Use 150 seconds @ 40 Hz gives 6001 points. \n",
    "pr = 98 #percentile\n",
    "thr = 5 #SNR threshold\n",
    "station_distance_threshold = 25\n",
    "pi = np.pi\n",
    "v_s = 1000 #shear wave velocity at the surface\n",
    "\n",
    "# range of dates that we are looking at\n",
    "t_beginning = UTCDateTime(2001,1,1,0,0,0) \n",
    "t_end = UTCDateTime(2023,8,2,23,59)\n",
    "twin=6000\n",
    "\n",
    "smooth_length = 5 # constant for smoothing the waveform envelopes\n",
    "low_cut = 1 #low frequency threshold\n",
    "high_cut = 12 #high frequency threshold\n",
    "az_thr = 1000 #threshold of distance in meters from source location\n",
    "step = 100 #step every 100 m\n",
    "t_step = 1 #step every second\n",
    "ratio = 5.6915196 #used to define the grid \n",
    "colors = list(plt.cm.tab10(np.arange(10)))*3\n",
    "radius = 6371e3 # radius of the earth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c89405",
   "metadata": {},
   "source": [
    "## Download eqT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fb0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.makedirs(\"/Users/marinedenolle/.seisbench/models/v3/eqtransformer\",exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba4eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/congcy/ELEP/raw/main/docs/tutorials/data/pnw.pt.v1 -O ~/.seisbench/models/v3/eqtransformer/pnw.pt.v1\n",
    "# !wget https://github.com/congcy/ELEP/raw/main/docs/tutorials/data/pnw.json.v1 -O ~/.seisbench/models/v3/eqtransformer/pnw.json.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6faefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ML picker parameters\n",
    "paras_semblance = {'dt':0.025, 'semblance_order':4, 'window_flag':True, \n",
    "                   'semblance_win':0.5, 'weight_flag':'max'}\n",
    "p_thrd, s_thrd = 0.01, 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f29d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download models\n",
    "pretrain_list = [\"pnw\",\"ethz\",\"instance\",\"scedc\",\"stead\",\"geofon\",\"neic\"]\n",
    "pn_pnw_model = sbm.EQTransformer.from_pretrained('pnw')\n",
    "pn_ethz_model = sbm.EQTransformer.from_pretrained(\"ethz\")\n",
    "pn_instance_model = sbm.EQTransformer.from_pretrained(\"instance\")\n",
    "pn_scedc_model = sbm.EQTransformer.from_pretrained(\"scedc\")\n",
    "pn_stead_model = sbm.EQTransformer.from_pretrained(\"stead\")\n",
    "pn_geofon_model = sbm.EQTransformer.from_pretrained(\"geofon\")\n",
    "pn_neic_model = sbm.EQTransformer.from_pretrained(\"neic\")\n",
    "\n",
    "list_models = [pn_pnw_model,pn_ethz_model,pn_scedc_model,pn_neic_model,pn_geofon_model,pn_stead_model,pn_instance_model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c71ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_pnw_model.to(device);\n",
    "pn_ethz_model.to(device);\n",
    "pn_scedc_model.to(device);\n",
    "pn_neic_model.to(device);\n",
    "pn_geofon_model.to(device);\n",
    "pn_stead_model.to(device);\n",
    "pn_instance_model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22a659",
   "metadata": {},
   "source": [
    "### 1. Volcano Data (network and station, labeled with volcano name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b099703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this data includes all stations within 50km of each volcano and the lat, lon, elev of each station\n",
    "df = pd.read_csv('../data/station/Volcano_Metadata_50km.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9656e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# center latitude, center longitude, elevation(m), left_trim, right_trim, bottom_trim, top_trim \n",
    "volc_lat_lon = {}\n",
    "volc_lat_lon['Mt_Rainier'] = [46.8528857, -121.7603744, 4392.5, 10000, 3000, 15000, 7000]\n",
    "volc_lat_lon['Mt_Adams'] = [46.202621, -121.4906384, 3743.2, 5000, 3000, 4000, 2000]\n",
    "volc_lat_lon['Mt_Baker'] = [48.7773426,  -121.8132008, 3287.6, 0, 0, 0, 2000]\n",
    "# change the lat and lon of mt st helens to the middle of the dome instead of the highest point\n",
    "volc_lat_lon['Mt_St_Helens'] =[46.200472222222224,-122.18883611111112,2549, 10000, 10000, 17000, 15000] #[46.1912, -122.1944, 2549]\n",
    "volc_lat_lon['Glacier_Peak'] = [48.1112273, -121.1139922, 3213, 14000, 10000, 8000, 10000]\n",
    "volc_lat_lon['Mt_Hood']=[45.373221, -121.696509, 3428.7, 18000, 50000, 35000, 65000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18ca268",
   "metadata": {},
   "source": [
    "### 3. Surface Event Data from PNSN\n",
    "\n",
    "Read files straight from PNSN data base. Extract station and network code, phase pick time (seen as start_time). this should be converted to pick_time0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3894296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'net', 'sta', 'location', 'seedchan', 'iphase', 'quality',\n",
      "       'orid', 'etype', 'evid'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "f1 = pd.read_csv(\"../data/events/su_picks.txt\",sep=\"|\")\n",
    "f1.head()\n",
    "print(f1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1bf5dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>net</th>\n",
       "      <th>sta</th>\n",
       "      <th>evt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-05 13:35:05</td>\n",
       "      <td>UW</td>\n",
       "      <td>YEL</td>\n",
       "      <td>801538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-05 14:37:57</td>\n",
       "      <td>UW</td>\n",
       "      <td>YEL</td>\n",
       "      <td>801553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-18 21:25:51</td>\n",
       "      <td>UW</td>\n",
       "      <td>SEP</td>\n",
       "      <td>807903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-18 21:25:52</td>\n",
       "      <td>UW</td>\n",
       "      <td>YEL</td>\n",
       "      <td>807903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-18 21:25:52</td>\n",
       "      <td>UW</td>\n",
       "      <td>SHW</td>\n",
       "      <td>807903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date net  sta  evt_id\n",
       "0 2001-01-05 13:35:05  UW  YEL  801538\n",
       "1 2001-01-05 14:37:57  UW  YEL  801553\n",
       "2 2001-01-18 21:25:51  UW  SEP  807903\n",
       "3 2001-01-18 21:25:52  UW  YEL  807903\n",
       "4 2001-01-18 21:25:52  UW  SHW  807903"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up the spaces in the file\n",
    "format='%Y/%m/%d %H:%M:%S'\n",
    "test=f1[\"date\"].values.tolist()\n",
    "start_time_temp = [  datetime.strptime(x.strip(),'%Y/%m/%d %H:%M:%S') for x in f1[\"date\"].values.tolist()]\n",
    "# # Ignore events prior to t_beginning\n",
    "ik=np.where(np.array(start_time_temp)>datetime(2001,1,1))[0][0]\n",
    "\n",
    "# select only net, sta, evid, startime for event past the start date.\n",
    "\n",
    "start_time = start_time_temp[ik:]\n",
    "net=[ x.strip() for x in f1[\"net\"].values.tolist()][ik:]\n",
    "sta=[ x.strip() for x in f1[\"sta\"].values.tolist()][ik:]\n",
    "evt_id=[ x for x in f1[\"orid\"].values.tolist()][ik:]\n",
    "all_stas=set(sta)\n",
    "\n",
    "\n",
    "f2=pd.DataFrame({\"date\":start_time,\"net\":net,\"sta\":sta,\"evt_id\":evt_id})\n",
    "f2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a8fc2",
   "metadata": {},
   "source": [
    "## Ensemble picking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ab0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "fqmin = low_cut\n",
    "fqmax = high_cut\n",
    "dt = 0.025; fs = 40\n",
    "nfqs = 10\n",
    "nt = 6000; nc = 3\n",
    "fq_list = make_LogFq(fqmin, fqmax, dt, nfqs)\n",
    "coeff_HP, coeff_LP = rec_filter_coeff(fq_list, dt)\n",
    "MBF_paras = {'f_min':fqmin, 'f_max':fqmax, 'nfqs':nfqs, 'frequencies':fq_list, 'CN_HP':coeff_HP, 'CN_LP':coeff_LP, \\\n",
    "    'dt':dt, 'fs':fs, 'nt':nt, 'nc':nc, 'npoles': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e0f9109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Network Station   Latitude   Longitude  Elevation  \\\n",
      "0      CC    ARAT  46.789000 -121.853000   1822.440   \n",
      "1      CC    COPP  46.797980 -121.828750   1895.000   \n",
      "2      CC    CRBN  46.988155 -121.961026    500.080   \n",
      "3      CC    GTWY  46.740208 -121.916966    617.235   \n",
      "4      CC    KAUT  46.730263 -121.857381    689.000   \n",
      "\n",
      "                      Sitename            StartTime              EndTime  \n",
      "0                 Mount Ararat  2020-08-06T00:00:00  2599-12-31T23:59:59  \n",
      "1                         COPP  2022-09-20T11:00:00  2599-12-31T23:59:59  \n",
      "2  Carbon River Ranger Station  2020-10-22T00:00:00  2599-12-31T23:59:59  \n",
      "3     Gateway Entrance Station  2020-10-28T20:00:00  2599-12-31T23:59:59  \n",
      "4         Kautz Creek Helibase  2020-09-02T00:00:00  2599-12-31T23:59:59  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     ARAT\n",
       "1     COPP\n",
       "2     CRBN\n",
       "3     GTWY\n",
       "4     KAUT\n",
       "5     MILD\n",
       "6     OPCH\n",
       "7     PARA\n",
       "8     PR01\n",
       "9     PR02\n",
       "10    PR03\n",
       "11    PR04\n",
       "12    PR05\n",
       "13    SIFT\n",
       "14    STYX\n",
       "15    TABR\n",
       "16    TAVI\n",
       "17     WOW\n",
       "Name: Station, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of infrasound stations in Mt Rainier\n",
    "df_infra = pd.read_csv(\"../data/station/MtRainier-infra-stations.txt\",sep=\"|\")\n",
    "print(df_infra.head())\n",
    "df_infra[\"Station\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d22081",
   "metadata": {},
   "source": [
    "## Full stack:\n",
    "\n",
    "1. Downdload waveforms (filtering and SNR measurements, duration measurements, envelope). Note that we download infrasound for fun.\n",
    "3. Phase picking (transfer learned, semblance, and envelope)\n",
    "4. plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1eba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UW RCS\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pdf = PdfPages('../plots/SeisInfra_MtRainier.pdf')\n",
    "nfigure=0\n",
    "for n in range(len(evt_id)): \n",
    "    if start_time[n]<datetime(2021,1,1):continue  \n",
    "    event_ID = str(evt_id[n])\n",
    "    otime = UTCDateTime(start_time[n])\n",
    "    networks=net[n]\n",
    "    stations=sta[n]\n",
    "    print(net[n],sta[n])\n",
    "    if sta[n]==\"LON\" or sta[n]==\"LO2\": continue\n",
    "    try:\n",
    "        associated_volcano = df[df['Station']== sta[n]]['Volcano_Name'].values[0]\n",
    "    except:\n",
    "        pass\n",
    "    if associated_volcano!=\"Mt_Rainier\":continue            \n",
    "    # get info for stations within 50km of volcano that event ocurred at\n",
    "    stations = df[df['Volcano_Name'] == associated_volcano]['Station'].values.tolist()\n",
    "    networks = df[df['Volcano_Name'] == associated_volcano]['Network'].values.tolist()\n",
    "    latitudes = df[df['Volcano_Name'] == associated_volcano]['Latitude'].values.tolist()\n",
    "    longitudes = df[df['Volcano_Name'] == associated_volcano]['Longitude'].values.tolist()\n",
    "    elevations = df[df['Volcano_Name']== associated_volcano]['Elevation'].values.tolist()\n",
    "\n",
    "    #################### WAVEFORM DOWNLOAD #######################\n",
    "        #Download all waveforms for that event based on stations and times\n",
    "    # try:\n",
    "    bulk=[]\n",
    "    for m in range(0, len(networks)):\n",
    "        bulk.append([networks[m], stations[m], '*', '*H*', otime-t_before_raw, otime+t_before_raw])\n",
    "    st = client2.get_waveforms_bulk(bulk)\n",
    "\n",
    "    bulk2=[]\n",
    "    for m in range(0, len(df_infra[\"Station\"])):\n",
    "        bulk2.append([\"CC\", df_infra[\"Station\"][m], '01', 'BDF', otime-t_before_raw, otime+t_before_raw])\n",
    "    infra = client2.get_waveforms_bulk(bulk2)\n",
    "    #remove unwanted data\n",
    "    for tr in st:\n",
    "        cha = tr.stats.channel\n",
    "        try:\n",
    "            if len(tr.data)/tr.stats.sampling_rate < 239.9:\n",
    "                st.remove(tr)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #resampling the data to 40Hz for each trace\n",
    "    st = resample(st,fs) \n",
    "    infra = resample(infra,fs) \n",
    "\n",
    "    # #Plotting all traces for one event with channel z, SNR>10, and bandpasses between 2-12Hz\n",
    "    evt_data = obspy.Stream()\n",
    "    evt_infradata = obspy.Stream()\n",
    "    SNR,SNR_weight, no_weight,stas,nets,max_amp_times,durations,data_env_dict,t_diff = [],[],[],[],[],[],[],{},{}\n",
    "    nfigure+=1\n",
    "    if nfigure<50:\n",
    "        fig = plt.figure(figsize = (11,8), dpi=400)\n",
    "        fig.suptitle(str(otime)+\" \"+associated_volcano)\n",
    "        plt.rcParams.update({'font.size': 14})\n",
    "        ax = plt.subplot(1,1,1)\n",
    "        iplot = 0\n",
    "    zz = st.select(component=\"Z\")\n",
    "    for i,ii in enumerate(zz):\n",
    "        network = ii.stats.network\n",
    "        station = ii.stats.station\n",
    "        ii.detrend(type = 'demean')\n",
    "        ii.filter('bandpass',freqmin=low_cut,freqmax=high_cut,corners=2,zerophase=True)\n",
    "        signal_window = ii.copy()\n",
    "        noise_window = ii.copy()\n",
    "        signal_window.trim(otime - t_before, otime - t_before + window) # trim the signal at the first pick time of the PNSN data, with loose 40s before\n",
    "        noise_window.trim(otime - window -t_before, otime - t_before) # noise window of the same length\n",
    "        if not len(signal_window.data) or not len(signal_window.data): continue\n",
    "        snr = (20 * np.log(np.percentile(np.abs(signal_window.data),pr) \n",
    "                        / np.percentile(np.abs(noise_window.data),pr))/np.log(10))\n",
    "        max_amp_time = np.argmax(noise_window.data)/fs\n",
    "        if snr<thr: \n",
    "            st.remove(ii)\n",
    "            continue\n",
    "        evt_data.append(signal_window)\n",
    "        stas.append(ii.stats.station)\n",
    "        t = signal_window.times()\n",
    "        if nfigure<50:\n",
    "            ax.plot(t-t_before,signal_window.data/np.max(np.abs(signal_window.data))+iplot*1.5)\n",
    "            ax.set_xlabel('time (seconds)')\n",
    "            ax.set_xlim((-t_before,100))\n",
    "            ax.set_yticks([])\n",
    "            plt.text(80, iplot*1.5, station)\n",
    "            iplot += 1\n",
    "\n",
    "    sta_available,ind = np.unique(np.array(stas),return_index=True)\n",
    "    sta_available=sta_available[np.argsort(ind)]\n",
    "    if len(sta_available)==0:continue\n",
    "#       Plot the infrasound as well\n",
    "\n",
    "    evt_infradata = obspy.Stream()\n",
    "    stas_infra=[]\n",
    "    for i,ii in enumerate(infra):\n",
    "        ii.filter('bandpass',freqmin=low_cut,freqmax=high_cut-5,corners=2,zerophase=True)\n",
    "        signal_window = ii.copy()\n",
    "        signal_window.trim(otime - t_before, otime - t_before  + window) # trim the signal at the first pick time of the PNSN data, with loose 40s before\n",
    "        if not len(signal_window.data): continue\n",
    "        t1 = signal_window.times()\n",
    "        if nfigure<50:\n",
    "            ax.plot(t1-t_before,signal_window.data/np.max(np.abs(signal_window.data))+iplot*1.5,color='0.8',linewidth=0.8)\n",
    "            ax.text(80, iplot*1.5, signal_window.stats.station)\n",
    "            iplot+=1\n",
    "            ax.set_xlim((-t_before,100))\n",
    "        evt_infradata.append(signal_window)\n",
    "        stas_infra.append(ii.stats.station)\n",
    "\n",
    "    sta_infra_available,ind = np.unique(np.array(stas_infra),return_index=True)\n",
    "    sta_infra_available=sta_infra_available[np.argsort(ind)]\n",
    "    if len(sta_infra_available)==0:continue\n",
    "\n",
    "    # PHASE PICKING\n",
    "        # test the new function\n",
    "    smb_peak,smb_peak_mbf = apply_mbf(evt_data, sta_available, \\\n",
    "            list_models, MBF_paras, paras_semblance, t_before,t_around)\n",
    "    smb_peak_infra,smb_peak_mbf_infra = apply_mbf(evt_infradata, sta_infra_available, \\\n",
    "            list_models, MBF_paras, paras_semblance, t_before+40,t_around+40)\n",
    "\n",
    "    print(\"reference time: \",otime)\n",
    "    print(\"relative picks from seismometers\")\n",
    "    print(sta_available)\n",
    "    print(smb_peak_mbf)\n",
    "    print(\"relative picks from infrasound\")\n",
    "    print(sta_infra_available)\n",
    "    print(smb_peak_mbf_infra)\n",
    "\n",
    "    if nfigure<50:\n",
    "        iplot=0\n",
    "        for i in range(len(sta_available)):\n",
    "            ax.vlines(smb_peak_mbf[i], ymin = iplot*1.5-.5, ymax = iplot*1.5+.5, color = 'r')\n",
    "            iplot+=1\n",
    "        for i in range(len(sta_infra_available)):\n",
    "            if np.abs(smb_peak_mbf_infra[i])>0.5:\n",
    "                ax.vlines(smb_peak_mbf_infra[i]+40, ymin = iplot*1.5-.5, ymax = iplot*1.5+.5, color = 'r')\n",
    "            iplot+=1\n",
    "\n",
    "        plt.grid(True)\n",
    "        pdf.savefig(fig)\n",
    "        print(\"Plotted\")\n",
    "        fig.savefig('../plots/waveforms_seismic_infrasound_'+event_ID+associated_volcano+'.png')\n",
    "        plt.show()\n",
    "        del fig\n",
    "        nfigure+=1\n",
    "\n",
    "    if nfigure==50 :pdf.close()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cb5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_before,t_around)\n",
    "print(t_before+40,t_around+60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3e220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo-py38-shared"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
