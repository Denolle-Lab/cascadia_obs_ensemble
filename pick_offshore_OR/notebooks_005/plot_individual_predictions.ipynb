{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa488163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from obspy.clients.fdsn import Client\n",
    "import numpy as np\n",
    "import obspy\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from obspy.clients.fdsn.client import Client\n",
    "from obspy.core.utcdatetime import UTCDateTime\n",
    "from obspy import Stream\n",
    "\n",
    "from pnwstore.mseed import WaveformClient\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "import pandas as pd\n",
    "import gc\n",
    "import seisbench.models as sbm\n",
    "from ELEP.elep.ensemble_statistics import ensemble_statistics\n",
    "from ELEP.elep.ensemble_coherence import ensemble_semblance \n",
    "from ELEP.elep.trigger_func import picks_summary_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bf13f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Define clients\n",
    "client_inventory = Client('IRIS')\n",
    "client_waveform = WaveformClient()\n",
    "client_ncedc = Client('NCEDC')\n",
    "\n",
    "twin = 6000     # length of time window\n",
    "step = 3000     # step length\n",
    "l_blnd, r_blnd = 500, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ccbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(batch_pred)\n",
    "\n",
    "    pretrain_list = ['original', 'ethz', 'instance', 'scedc', 'stead']\n",
    "    \n",
    "    plt.figure(figsize = (10, 3))\n",
    "\n",
    "    iwin = np.random.randint(100)\n",
    "    cat_p = metadata.loc[iwin, 'trace_P_arrival_sample']\n",
    "    plt.figure(figsize = (10, 8))\n",
    "    plt.subplots_adjust(hspace = 0.1)\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.title(f\"P-wave (index {iwin})\")\n",
    "    for ipre, pretrain in enumerate(pretrain_list):\n",
    "        if not np.isnan(pretrain_peak[0, iwin, ipre]):\n",
    "            plt.plot(batch_pred[0, ipre, iwin, :], \n",
    "                 label = f\"{pretrain} ($\\\\Delta t = ${np.abs(pretrain_peak[0, iwin, ipre] - cat_p)/100} sec)\")\n",
    "        else:\n",
    "            plt.plot(batch_pred[0, ipre, iwin, :], \n",
    "                 label = f\"{pretrain} (N/A)\")\n",
    "    plt.ylabel(\"Prediction\", fontsize = 15); \n",
    "    plt.ylim([0, 1]); plt.xlim([0, twin]); plt.xticks([]);\n",
    "    plt.hlines(p_thrd, 0, twin, linestyle = '--', color = 'k')\n",
    "    plt.legend(ncols = 2, loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveforms(idx,mycatalog,mycatalog_picks,network)\n",
    "    # Plot the earthquake moveout for one of the unmatched events for all stations \n",
    "    # event = new_events_deg.iloc[idx]\n",
    "    event=mycatalog\n",
    "    picks = mycatalog_picks\n",
    "    pick_sta = np.unique(picks['station'])\n",
    "\n",
    "    # otime = UTCDateTime(event['datetime'])\n",
    "    otime =UTCDateTime(event[\"datetime\"].iloc[idx])\n",
    "    distances = []\n",
    "\n",
    "    # Assuming networks_stas is a list of tuples with network and station identifiers\n",
    "    for station in pick_sta:\n",
    "        try:\n",
    "            sta_inv = client2.get_stations(network=network,\n",
    "                                           station=station, channel=\"?H?\", \n",
    "                                           starttime=otime - 1e4, endtime=otime + 1e4)[0][0]\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch for {network} {station} {otime}: {e}\")\n",
    "            continue\n",
    "\n",
    "        slat = sta_inv.latitude\n",
    "        slon = sta_inv.longitude\n",
    "        olat = event['latitude']\n",
    "        olon = event['longitude']\n",
    "\n",
    "        dis1 = locations2degrees(olat, olon, slat, slon)\n",
    "        dist = degrees2kilometers(dis1)\n",
    "        distances.append([None,station,dist])\n",
    "\n",
    "    # Sort distances\n",
    "    distances = sorted(distances, key=lambda item: item[-1])\n",
    "    distances = distances[0:11]\n",
    "    # print(distances)\n",
    "    # print(otime)\n",
    "    plt.figure(dpi=150)\n",
    "    for i, ii in enumerate(distances):\n",
    "        st = client.get_waveforms(network=\"*\",\n",
    "                                  station=ii[1], channel=\"?HZ\", starttime=otime-30, endtime=otime+120)\n",
    "        st = obspy.Stream(filter(lambda st:st.stats.sampling_rate>10, st))\n",
    "        st.filter(type='bandpass',freqmin=4,freqmax=15)\n",
    "\n",
    "        trim_st = st.copy()\n",
    "        if len(trim_st)>0:\n",
    "            trim_st = trim_st.normalize()\n",
    "            offsets1  = ii[2]\n",
    "            offsets2 = 0\n",
    "    #         for ii in range(len(trim_st)):\n",
    "            wave=trim_st[0].data\n",
    "            wave=wave/np.nanmax(wave,axis=-1,keepdims=True)\n",
    "            plt.plot(trim_st[0].times(),wave *30+offsets1, \n",
    "                     color = 'black', alpha=0.7, lw=0.5)    \n",
    "    #         time_pick = [[x['time_pick'], x['phase']] for _, x in mycatalog[mycatalog['idx'] == idx].iterrows() \n",
    "    #                      if x['station'] == sta]\n",
    "    #         if len(time_pick) > 0:\n",
    "    #             for p in time_pick:\n",
    "    #                 if p[1] == 'P':\n",
    "            plt.text(trim_st[0].times()[0]-5, trim_st[0].data[0] * 10 + offsets1-2, \n",
    "                         [ii[1]], fontsize=8, verticalalignment='bottom')\n",
    "\n",
    "    #         plt.vlines(ii[2]/5, offsets1-5, \n",
    "    #                          offsets1+5, color='r')\n",
    "            sta_picks = picks.loc[picks['station']==ii[1]]\n",
    "\n",
    "            p_picks = sta_picks.loc[sta_picks['phase']=='P']\n",
    "            s_picks = sta_picks.loc[sta_picks['phase']=='S']\n",
    "\n",
    "\n",
    "            if len(p_picks)>0:\n",
    "                plt.vlines(UTCDateTime(p_picks.iloc[0]['time_pick'])-otime+30, offsets1-5, \n",
    "                             offsets1+5, color='r')\n",
    "\n",
    "            if len(s_picks)>0:\n",
    "                plt.vlines(UTCDateTime(s_picks.iloc[0]['time_pick'])-otime+30, offsets1-5, \n",
    "                             offsets1+5, color='b')\n",
    "\n",
    "    #                 else:\n",
    "    #                     plt.vlines(p[0], offsets1[ii]*0.5+offsets2[i]-1, \n",
    "    #                                      offsets1[ii]*0.5+offsets2[i]+1, color='b')\n",
    "        else:                 \n",
    "            pass \n",
    "    plt.title(f\"Event Offshore Oregon (Z component): Origin Time={otime}, Latitude={round(event['latitude'].iloc[0],2)}, Longtitude={round(event['longitude'].iloc[0],2)}\")\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.ylabel('Distance [km]')\n",
    "    plt.ylim(0,420)\n",
    "    plt.xlim(20,150)\n",
    "\n",
    "    plt.grid(alpha=0.5)\n",
    "\n",
    "    plt.savefig(\"event_offshore_OR_Z_010.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7224bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detection(network,station,t1,t2,filepath,twin,step,l_blnd,r_blnd,lat,lon,elev):\n",
    "    # Define tstring\n",
    "    tstring = t1.strftime('%Y%m%d')\n",
    "\n",
    "    if os.path.exists(filepath+station+'_'+tstring+'.csv'):\n",
    "        print('File '+filepath+station+'_'+tstring+'.csv already exists')\n",
    "        return\n",
    "    # print the file path \n",
    "    print('test1')\n",
    "    print(filepath+station+'_'+tstring+'.csv')\n",
    "\t# Load data\n",
    "\t# Reshape data\n",
    "\t# Predict on base models\n",
    "\t# Stack\n",
    "\t# Create and write csv file. Define file name using the station code and the input filepath\n",
    "    \n",
    "    \n",
    "    network = network\n",
    "#     channels = '[HB][HN][BH]?'\n",
    "#     channels = 'HH?,HN?,BH?' \n",
    "    channels = '?H?'\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Get waveforms and filter\n",
    "    \n",
    "    try:\n",
    "        if network in ['NC', 'BK']:\n",
    "            # Query waveforms\n",
    "            _sdata = client_ncedc.get_waveforms(network=network, station=station, location=\"*\", channel=channels,\n",
    "                                               starttime=UTCDateTime(t1), endtime=UTCDateTime(t2))\n",
    "        else: \n",
    "            _sdata = client_waveform.get_waveforms(network=network, station=station, channel=channels, \n",
    "                                              starttime=UTCDateTime(t1), endtime=UTCDateTime(t2))\n",
    "    except obspy.clients.fdsn.header.FDSNNoDataException:\n",
    "        print(f\"WARNING: No data for {network}.{station}.{channels} on {t1}.\")\n",
    "        return\n",
    "    \n",
    "#     sdata = sdata.select(channel = \"[HB]H?\")\n",
    "        \n",
    "# Create a new stream\n",
    "    sdata = Stream()\n",
    "# Check for HH and BH channels presence\n",
    "    has_HH = bool(_sdata.select(channel=\"HH?\"))\n",
    "    has_BH = bool(_sdata.select(channel=\"BH?\"))\n",
    "\n",
    "    # Apply selection logic based on channel presence\n",
    "    if has_HH and has_BH:\n",
    "        # If both HH and BH channels are present, select only HH\n",
    "        sdata += _sdata.select(channel=\"HH?\")\n",
    "    elif has_HH:\n",
    "        # If only HH channels are present\n",
    "        sdata += _sdata.select(channel=\"HH?\")\n",
    "    elif has_BH:\n",
    "        # If only BH channels are present\n",
    "        sdata += _sdata.select(channel=\"BH?\")\n",
    "\n",
    "    ###############################\n",
    "    # If no data returned, skipping\n",
    "    if len(sdata) == 0:\n",
    "        logging.warning(\"No stream returned. Skipping.\")\n",
    "        return\n",
    "    ###############################\n",
    "    \n",
    "    sdata.filter(type='bandpass',freqmin=4,freqmax=15)\n",
    "    \n",
    "    ###############################\n",
    "    sdata.merge(fill_value='interpolate') # fill gaps if there are any.\n",
    "    ###############################\n",
    "\n",
    "    # Get the necassary information about the station\n",
    "    delta = sdata[0].stats.delta\n",
    "    starttime = sdata[0].stats.starttime\n",
    "    fs = sdata[0].stats.sampling_rate\n",
    "    dt = 1/fs\n",
    "    \n",
    "\n",
    "    # Make all the traces in the stream have the same lengths\n",
    "    max_starttime = max([tr.stats.starttime for tr in sdata])\n",
    "    min_endtime = min([tr.stats.endtime for tr in sdata])\n",
    "    \n",
    "    for tr in sdata:\n",
    "        tr.trim(starttime=max_starttime,endtime=min_endtime, nearest_sample=True)    \n",
    "        \n",
    "    # Reshaping data\n",
    "    arr_sdata = np.array(sdata)\n",
    "    npts = arr_sdata.shape[1]\n",
    "    ############################### avoiding errors at the end of a stream\n",
    "   #nseg = int(np.ceil((npts - twin) / step)) + 1\n",
    "    nseg = int(np.floor((npts - twin) / step)) + 1\n",
    "    ###############################\n",
    "    windows = np.zeros(shape=(nseg, 3, twin), dtype= np.float32)\n",
    "    tap = 0.5 * (1 + np.cos(np.linspace(np.pi, 2 * np.pi, 6)))\n",
    "    \n",
    "    # Define the parameters for semblance\n",
    "    paras_semblance = {'dt':dt, 'semblance_order':2, 'window_flag':True, \n",
    "                   'semblance_win':0.5, 'weight_flag':'max'}\n",
    "    p_thrd, s_thrd = 0.05, 0.05\n",
    "\n",
    "    windows_std = np.zeros(shape=(nseg, 3, twin), dtype= np.float32)\n",
    "    windows_max = np.zeros(shape=(nseg, 3, twin), dtype= np.float32)\n",
    "    windows = np.zeros(shape=(nseg, 3, twin), dtype= np.float32)\n",
    "    windows_idx = np.zeros(nseg, dtype=np.int32)\n",
    "\n",
    "    for iseg in range(nseg):\n",
    "        idx = iseg * step\n",
    "        windows[iseg, :] = arr_sdata[:, idx:idx + twin]\n",
    "        windows[iseg, :] -= np.mean(windows[iseg, :], axis=-1, keepdims=True)\n",
    "        # original use std norm\n",
    "        windows_std[iseg, :] = windows[iseg, :] / np.std(windows[iseg, :]) + 1e-10\n",
    "        # others use max norm\n",
    "        windows_max[iseg, :] = windows[iseg, :] / (np.max(np.abs(windows[iseg, :]), axis=-1, keepdims=True))\n",
    "        windows_idx[iseg] = idx\n",
    "\n",
    "    # taper\n",
    "    windows_std[:, :, :6] *= tap; windows_std[:, :, -6:] *= tap[::-1]; \n",
    "    windows_max[:, :, :6] *= tap; windows_max[:, :, -6:] *= tap[::-1];\n",
    "    del windows\n",
    "\n",
    "    print(f\"Window data shape: {windows_std.shape}\")\n",
    "    \n",
    "    # Predict on base models\n",
    "    \n",
    "    pretrain_list = ['original', 'ethz', 'instance', 'scedc', 'stead']\n",
    "\n",
    "    # dim 0: 0 = P, 1 = S\n",
    "    batch_pred = np.zeros([2, len(pretrain_list), nseg, twin], dtype = np.float32) \n",
    "    for ipre, pretrain in enumerate(pretrain_list):\n",
    "        print('test10')\n",
    "        t0 = time.time()\n",
    "        eqt = sbm.EQTransformer.from_pretrained(pretrain)\n",
    "        eqt.to(device);\n",
    "        eqt._annotate_args['overlap'] = ('Overlap between prediction windows in samples \\\n",
    "                                        (only for window prediction models)', step)\n",
    "        eqt._annotate_args['blinding'] = ('Number of prediction samples to discard on \\\n",
    "                                         each side of each window prediction', (l_blnd, r_blnd))\n",
    "        eqt.eval();\n",
    "        if pretrain == 'original':\n",
    "            # batch prediction through torch model\n",
    "            windows_std_tt = torch.Tensor(windows_std)\n",
    "            _torch_pred = eqt(windows_std_tt.to(device))\n",
    "        else:\n",
    "            windows_max_tt = torch.Tensor(windows_max)\n",
    "            _torch_pred = eqt(windows_max_tt.to(device))\n",
    "        batch_pred[0, ipre, :] = _torch_pred[1].detach().cpu().numpy()\n",
    "        batch_pred[1, ipre, :] = _torch_pred[2].detach().cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize = (10, 3))\n",
    "    \n",
    "    for ipre in (pretrain_list)   \n",
    "        d_p = batch_pred[0,]\n",
    "        plt.plot(d.T)\n",
    "        plt.vlines(metadata.loc[iwin, 'trace_P_arrival_sample'], d.max(), d.min(), \n",
    "                   color = 'b', label = \"catalog P pick\", linewidth = 2, linestyle = '--')\n",
    "        plt.vlines(metadata.loc[iwin, 'trace_S_arrival_sample'], d.max(), d.min(), \n",
    "                   color = 'r', label = \"catalog S pick\", linewidth = 2, linestyle = '--')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        plt.xlabel(\"Time\", fontsize = 15)\n",
    "        plt.ylabel(\"Raw Waveform\", fontsize = 15)\n",
    "        plt.xlim([metadata.loc[iwin, 'trace_P_arrival_sample'] - 1000,\n",
    "                  metadata.loc[iwin, 'trace_S_arrival_sample'] + 1000]); \n",
    "        plt.ylim([d.min(), d.max()])\n",
    "\n",
    "#     # clean up memory\n",
    "#     del _torch_pred, windows_max_tt, windows_std_tt\n",
    "#     del windows_std, windows_max\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     print(f\"All prediction shape: {batch_pred.shape}\")\n",
    "    \n",
    "#     ####################### You don't need this\n",
    "# #     pretrain_pred = np.zeros([2, len(pretrain_list), npts], dtype = np.float32)\n",
    "# #     for ipre, pretrain in enumerate(pretrain_list):\n",
    "# #        # 0 for P-wave\n",
    "# #         pretrain_pred[0, ipre, :] = stacking(batch_pred[0, ipre, :], npts, l_blnd, r_blnd)\n",
    "# # \n",
    "# #        # 1 for S-wave\n",
    "# #        pretrain_pred[1, ipre, :] = stacking(batch_pred[1, ipre, :], npts, l_blnd, r_blnd)\n",
    "#     ####################### You don't need this\n",
    "    \n",
    "#     smb_pred = np.zeros([2, nseg, twin], dtype = np.float32)\n",
    "#     # calculate the semblance\n",
    "#     ## the semblance may takes a while bit to calculate\n",
    "    \n",
    "#     ############################# remove tqdm (extra progress bar)\n",
    "# #     for iseg in tqdm(range(nseg)):\n",
    "#     for iseg in range(nseg):\n",
    "#     #############################\n",
    "#         # 0 for P-wave\n",
    "#         smb_pred[0, iseg, :] = ensemble_semblance(batch_pred[0, :, iseg, :], paras_semblance)\n",
    "\n",
    "#         # 1 for P-wave\n",
    "#         smb_pred[1, iseg, :] = ensemble_semblance(batch_pred[1, :, iseg, :], paras_semblance)\n",
    "\n",
    "#     ## ... and stack\n",
    "#     # 0 for P-wave\n",
    "#     ####################### add a nseg argument here\n",
    "#     #smb_p = stacking(smb_pred[0, :], npts, l_blnd, r_blnd)\n",
    "#     smb_p = stacking(smb_pred[0, :], npts, l_blnd, r_blnd, nseg)\n",
    "\n",
    "#     # 1 for P-wave\n",
    "#     #smb_s = stacking(smb_pred[1, :], npts, l_blnd, r_blnd)\n",
    "#     smb_s = stacking(smb_pred[1, :], npts, l_blnd, r_blnd, nseg)\n",
    "#     #######################\n",
    "#     # clean-up RAM\n",
    "#     del smb_pred, batch_pred\n",
    "\n",
    "#     p_index = picks_summary_simple(smb_p, p_thrd)\n",
    "#     s_index = picks_summary_simple(smb_s, s_thrd)\n",
    "#     print(f\"{len(p_index)} P picks\\n{len(s_index)} S picks\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa49f153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba87ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5faccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2fa5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24825282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed10e556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
