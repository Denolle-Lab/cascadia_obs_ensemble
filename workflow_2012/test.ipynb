{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b670d2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbito/cascadia_obs_ensemble/workflow_2012/picking_utils.py:166: RuntimeWarning: invalid value encountered in divide\n",
      "  windows_max[iseg, :] = windows[iseg, :] / (np.max(np.abs(windows[iseg, :]), axis=-1, keepdims=True))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 88\u001b[0m\n\u001b[1;32m     86\u001b[0m network \u001b[38;5;241m=\u001b[39m task_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     87\u001b[0m station \u001b[38;5;241m=\u001b[39m task_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 88\u001b[0m \u001b[43mrun_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstation\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtwin\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml_blnd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mr_blnd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# @dask.delayed\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# def loop_days(task,filepath,twin,step,l_blnd,r_blnd):\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# #     # Add scheduler = 'single-threaded'\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# # \tdask.compute(lazy_results, scheduler='single-threaded') \u001b[39;00m\n",
      "File \u001b[0;32m~/cascadia_obs_ensemble/workflow_2012/picking_utils.py:194\u001b[0m, in \u001b[0;36mrun_detection\u001b[0;34m(network, station, t1, t2, filepath, twin, step, l_blnd, r_blnd)\u001b[0m\n\u001b[1;32m    192\u001b[0m                                  each side of each window prediction', (l_blnd, r_blnd))\n\u001b[1;32m    193\u001b[0m eqt.eval();\n\u001b[0;32m--> 194\u001b[0m if pretrain == 'original':\n\u001b[1;32m    195\u001b[0m     # batch prediction through torch model\n\u001b[1;32m    196\u001b[0m     windows_std_tt = torch.Tensor(windows_std)\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/seisbench/models/eqtransformer.py:248\u001b[0m, in \u001b[0;36mEQTransformer.forward\u001b[0;34m(self, x, logits)\u001b[0m\n\u001b[1;32m    245\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_d(x)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# Detection part\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m detection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder_d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits:\n\u001b[1;32m    250\u001b[0m     detection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_d(detection)\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/seisbench/models/eqtransformer.py:473\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrops:\n\u001b[1;32m    471\u001b[0m             x \u001b[38;5;241m=\u001b[39m x[:, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 473\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from obspy.clients.fdsn import Client\n",
    "import numpy as np\n",
    "import obspy\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from obspy.clients.fdsn.client import Client\n",
    "from obspy.core.utcdatetime import UTCDateTime\n",
    "from obspy import Stream\n",
    "\n",
    "from pnwstore.mseed import WaveformClient\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "import pandas as pd\n",
    "import gc\n",
    "import seisbench.models as sbm\n",
    "from ELEP.elep.ensemble_statistics import ensemble_statistics\n",
    "from ELEP.elep.ensemble_coherence import ensemble_semblance \n",
    "from ELEP.elep.trigger_func import picks_summary_simple\n",
    "from picking_utils import run_detection, stacking\n",
    "import glob\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Define clients\n",
    "client_inventory = Client('IRIS')\n",
    "client_waveform = WaveformClient()\n",
    "client_ncedc = Client('NCEDC')\n",
    "\n",
    "# Parameters\n",
    "year1 = 2012\n",
    "filepath = \"../data/catalog_picks/\"\n",
    "os.makedirs(filepath,exist_ok=True)\n",
    "\n",
    "twin = 6000     # length of time window\n",
    "step = 3000     # step length\n",
    "l_blnd, r_blnd = 500, 500\n",
    "\n",
    "# Now create your list of days to loop over!\n",
    "t1 = datetime.datetime(year=year1,month=1,day=1)\n",
    "t2 = datetime.datetime(year=year1+1,month=1,day=1)\n",
    "time_bins = pd.to_datetime(np.arange(t1,t2,pd.Timedelta(1,'days')))\n",
    "\n",
    "inventory = client_inventory.get_stations(network=\"C8,7D,7A,CN,NV,UW,UO,NC,BK,TA,OO,PB,X6,Z5,X9\", station=\"*\", minlatitude=40,minlongitude=-127,maxlatitude=50,maxlongitude=-123, starttime=t1.strftime('%Y%m%d'),endtime=t2.strftime('%Y%m%d'))\n",
    "\n",
    "\n",
    "\n",
    "# Make a list of networks and stations\n",
    "networks_stas = []\n",
    "for i in range(len(inventory)):\n",
    "    network = inventory[i].code\n",
    "    \n",
    "    for j in range(len(inventory[i])):\n",
    "        networks_stas.append([network,inventory[i].stations[j].code])\n",
    "\n",
    "networks_stas =np.array(networks_stas)\n",
    "    \n",
    "# download models\n",
    "pretrain_list = [\"pnw\",\"ethz\",\"instance\",\"scedc\",\"stead\",\"geofon\"]\n",
    "pn_pnw_model = sbm.EQTransformer.from_pretrained('pnw')\n",
    "pn_ethz_model = sbm.EQTransformer.from_pretrained(\"ethz\")\n",
    "pn_instance_model = sbm.EQTransformer.from_pretrained(\"instance\")\n",
    "pn_scedc_model = sbm.EQTransformer.from_pretrained(\"scedc\")\n",
    "pn_stead_model = sbm.EQTransformer.from_pretrained(\"stead\")\n",
    "pn_geofon_model = sbm.EQTransformer.from_pretrained(\"geofon\")\n",
    "\n",
    "# Combine that list of days with the list of stations and networks\n",
    "# We are essentially creating a list of the number of tasks we have to do with the information that is unique to each task; we will do them in parallel\n",
    "task_list = []\n",
    "for i in range(len(networks_stas)):\n",
    "\tfor t in time_bins:\n",
    "\t\ttask_list.append([networks_stas[i][0], networks_stas[i][1],t])\n",
    "        \n",
    "# Now we start setting up a parallel operation using a package called Dask.\n",
    "t1 = obspy.UTCDateTime(task_list[0][2])\n",
    "t2 = obspy.UTCDateTime(t1 + pd.Timedelta(1,'days'))\n",
    "network = task_list[0][0]\n",
    "station = task_list[0][1]\n",
    "run_detection(network,station,t1,t2,filepath,twin,step,l_blnd,r_blnd)\n",
    "# @dask.delayed\n",
    "# def loop_days(task,filepath,twin,step,l_blnd,r_blnd):\n",
    "\n",
    "#     # Define the parameters that are specific to each task\n",
    "#     t1 = obspy.UTCDateTime(task[2])\n",
    "#     t2 = obspy.UTCDateTime(t1 + pd.Timedelta(1,'days'))\n",
    "#     network = task[0]\n",
    "#     station = task[1]\n",
    "\n",
    "#     #print network and station\n",
    "#     # Call to the function that will perform the operation and write the results to file\n",
    "#     run_detection(network,station,t1,t2,filepath,twin,step,l_blnd,r_blnd)\n",
    "    \n",
    "#     return\n",
    "\n",
    "\n",
    "# # # Now we set up the parallel operation\n",
    "# # # The below builds a framework for the computer to run in parallel. This doesn't actually execute anything.\n",
    "# lazy_results = [loop_days(task,filepath,twin,step,l_blnd,r_blnd) for task in task_list]\n",
    "    \n",
    "\n",
    "# # # The below actually executes the parallel operation!\n",
    "# # # It's nice to do it with the ProgressBar so you can see how long things are taking.\n",
    "# # # Each operation should also write a file so that is another way to check on progress.\n",
    "# # with ProgressBar():\n",
    "# #     #################################\n",
    "# #     # Add scheduler = 'single-threaded'\n",
    "# # \tdask.compute(lazy_results, scheduler='single-threaded') \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0abdc948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f374cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze > ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd66c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Usage:   \r\n",
      "  pip <command> [options]\r\n",
      "\r\n",
      "Commands:\r\n",
      "  install                     Install packages.\r\n",
      "  download                    Download packages.\r\n",
      "  uninstall                   Uninstall packages.\r\n",
      "  freeze                      Output installed packages in requirements format.\r\n",
      "  list                        List installed packages.\r\n",
      "  show                        Show information about installed packages.\r\n",
      "  check                       Verify installed packages have compatible dependencies.\r\n",
      "  search                      Search PyPI for packages.\r\n",
      "  wheel                       Build wheels from your requirements.\r\n",
      "  hash                        Compute hashes of package archives.\r\n",
      "  completion                  A helper command used for command completion.\r\n",
      "  help                        Show help for commands.\r\n",
      "\r\n",
      "General Options:\r\n",
      "  -h, --help                  Show help.\r\n",
      "  --isolated                  Run pip in an isolated mode, ignoring\r\n",
      "                              environment variables and user configuration.\r\n",
      "  -v, --verbose               Give more output. Option is additive, and can be\r\n",
      "                              used up to 3 times.\r\n",
      "  -V, --version               Show version and exit.\r\n",
      "  -q, --quiet                 Give less output. Option is additive, and can be\r\n",
      "                              used up to 3 times (corresponding to WARNING,\r\n",
      "                              ERROR, and CRITICAL logging levels).\r\n",
      "  --log <path>                Path to a verbose appending log.\r\n",
      "  --proxy <proxy>             Specify a proxy in the form\r\n",
      "                              [user:passwd@]proxy.server:port.\r\n",
      "  --retries <retries>         Maximum number of retries each connection should\r\n",
      "                              attempt (default 5 times).\r\n",
      "  --timeout <sec>             Set the socket timeout (default 15 seconds).\r\n",
      "  --exists-action <action>    Default action when a path already exists:\r\n",
      "                              (s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort.\r\n",
      "  --trusted-host <hostname>   Mark this host as trusted, even though it does\r\n",
      "                              not have valid or any HTTPS.\r\n",
      "  --cert <path>               Path to alternate CA bundle.\r\n",
      "  --client-cert <path>        Path to SSL client certificate, a single file\r\n",
      "                              containing the private key and the certificate\r\n",
      "                              in PEM format.\r\n",
      "  --cache-dir <dir>           Store the cache data in <dir>.\r\n",
      "  --no-cache-dir              Disable the cache.\r\n",
      "  --disable-pip-version-check\r\n",
      "                              Don't periodically check PyPI to determine\r\n",
      "                              whether a new version of pip is available for\r\n",
      "                              download. Implied with --no-index.\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7127a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hbito\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/IPython/core/magics/osm.py:428: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9a64366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f50cc71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hbito/cascadia_obs_ensemble\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter_share/miniconda3/envs/seismo/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd hbito/cascadia_obs_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff12693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m/            LICENSE  README.md         \u001b[01;34mworkflow_2012\u001b[0m/\r\n",
      "environment.yml  \u001b[01;34mold\u001b[0m/     requirements.txt  \u001b[01;34mworkflow_all_stations\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8340f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27e188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
