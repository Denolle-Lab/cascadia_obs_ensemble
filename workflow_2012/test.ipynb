{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b670d2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hbito/cascadia_obs_ensemble/workflow_2012/picking_utils.py:166: RuntimeWarning: invalid value encountered in divide\n",
      "  windows_max[iseg, :] = windows[iseg, :] / (np.max(np.abs(windows[iseg, :]), axis=-1, keepdims=True))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All prediction shape: (2, 5, 3599, 6000)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'twin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m network \u001b[38;5;241m=\u001b[39m task_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     86\u001b[0m station \u001b[38;5;241m=\u001b[39m task_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 87\u001b[0m \u001b[43mrun_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstation\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtwin\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml_blnd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mr_blnd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# @dask.delayed\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# def loop_days(task,filepath,twin,step,l_blnd,r_blnd):\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# #     # Add scheduler = 'single-threaded'\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# # \tdask.compute(lazy_results, scheduler='single-threaded') \u001b[39;00m\n",
      "File \u001b[0;32m~/cascadia_obs_ensemble/workflow_2012/picking_utils.py:237\u001b[0m, in \u001b[0;36mrun_detection\u001b[0;34m(network, station, t1, t2, filepath, twin, step, l_blnd, r_blnd)\u001b[0m\n\u001b[1;32m    231\u001b[0m     smb_pred[\u001b[38;5;241m1\u001b[39m, iseg, :] \u001b[38;5;241m=\u001b[39m ensemble_semblance(batch_pred[\u001b[38;5;241m1\u001b[39m, :, iseg, :], paras_semblance)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m## ... and stack\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# 0 for P-wave\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m####################### add a nseg argument here\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m#smb_p = stacking(smb_pred[0, :], npts, l_blnd, r_blnd)\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m smb_p \u001b[38;5;241m=\u001b[39m \u001b[43mstacking\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmb_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_blnd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_blnd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnseg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# 1 for P-wave\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m#smb_s = stacking(smb_pred[1, :], npts, l_blnd, r_blnd)\u001b[39;00m\n\u001b[1;32m    241\u001b[0m smb_s \u001b[38;5;241m=\u001b[39m stacking(smb_pred[\u001b[38;5;241m1\u001b[39m, :], npts, l_blnd, r_blnd, nseg)\n",
      "File \u001b[0;32m~/cascadia_obs_ensemble/workflow_2012/picking_utils.py:39\u001b[0m, in \u001b[0;36mstacking\u001b[0;34m(data, npts, l_blnd, r_blnd, nseg)\u001b[0m\n\u001b[1;32m     37\u001b[0m stack \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(npts, np\u001b[38;5;241m.\u001b[39mnan, dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     38\u001b[0m _data[:, :l_blnd] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan; _data[:, \u001b[38;5;241m-\u001b[39mr_blnd:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m---> 39\u001b[0m stack[:\u001b[43mtwin\u001b[49m] \u001b[38;5;241m=\u001b[39m _data[\u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iseg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nseg\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     41\u001b[0m     idx \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m*\u001b[39m(iseg\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'twin' is not defined"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from obspy.clients.fdsn import Client\n",
    "import numpy as np\n",
    "import obspy\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from obspy.clients.fdsn.client import Client\n",
    "from obspy.core.utcdatetime import UTCDateTime\n",
    "from obspy import Stream\n",
    "\n",
    "from pnwstore.mseed import WaveformClient\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "import pandas as pd\n",
    "import gc\n",
    "import seisbench.models as sbm\n",
    "from ELEP.elep.ensemble_statistics import ensemble_statistics\n",
    "from ELEP.elep.ensemble_coherence import ensemble_semblance \n",
    "from ELEP.elep.trigger_func import picks_summary_simple\n",
    "from picking_utils import run_detection, stacking\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Define clients\n",
    "client_inventory = Client('IRIS')\n",
    "client_waveform = WaveformClient()\n",
    "client_ncedc = Client('NCEDC')\n",
    "\n",
    "# Parameters\n",
    "year1 = 2012\n",
    "filepath = \"../data/catalog_picks/\"\n",
    "os.makedirs(filepath,exist_ok=True)\n",
    "\n",
    "twin = 6000     # length of time window\n",
    "step = 3000     # step length\n",
    "l_blnd, r_blnd = 500, 500\n",
    "\n",
    "# Now create your list of days to loop over!\n",
    "t1 = datetime.datetime(year=year1,month=1,day=1)\n",
    "t2 = datetime.datetime(year=year1+1,month=1,day=1)\n",
    "time_bins = pd.to_datetime(np.arange(t1,t2,pd.Timedelta(1,'days')))\n",
    "\n",
    "inventory = client_inventory.get_stations(network=\"C8,7D,7A,CN,NV,UW,UO,NC,BK,TA,OO,PB,X6,Z5,X9\", station=\"*\", minlatitude=40,minlongitude=-127,maxlatitude=50,maxlongitude=-123, starttime=t1.strftime('%Y%m%d'),endtime=t2.strftime('%Y%m%d'))\n",
    "\n",
    "\n",
    "\n",
    "# Make a list of networks and stations\n",
    "networks_stas = []\n",
    "for i in range(len(inventory)):\n",
    "    network = inventory[i].code\n",
    "    \n",
    "    for j in range(len(inventory[i])):\n",
    "        networks_stas.append([network,inventory[i].stations[j].code])\n",
    "\n",
    "networks_stas =np.array(networks_stas)\n",
    "    \n",
    "# download models\n",
    "pretrain_list = [\"pnw\",\"ethz\",\"instance\",\"scedc\",\"stead\",\"geofon\"]\n",
    "pn_pnw_model = sbm.EQTransformer.from_pretrained('pnw')\n",
    "pn_ethz_model = sbm.EQTransformer.from_pretrained(\"ethz\")\n",
    "pn_instance_model = sbm.EQTransformer.from_pretrained(\"instance\")\n",
    "pn_scedc_model = sbm.EQTransformer.from_pretrained(\"scedc\")\n",
    "pn_stead_model = sbm.EQTransformer.from_pretrained(\"stead\")\n",
    "pn_geofon_model = sbm.EQTransformer.from_pretrained(\"geofon\")\n",
    "\n",
    "# Combine that list of days with the list of stations and networks\n",
    "# We are essentially creating a list of the number of tasks we have to do with the information that is unique to each task; we will do them in parallel\n",
    "task_list = []\n",
    "for i in range(len(networks_stas)):\n",
    "\tfor t in time_bins:\n",
    "\t\ttask_list.append([networks_stas[i][0], networks_stas[i][1],t])\n",
    "        \n",
    "# Now we start setting up a parallel operation using a package called Dask.\n",
    "t1 = obspy.UTCDateTime(task_list[0][2])\n",
    "t2 = obspy.UTCDateTime(t1 + pd.Timedelta(1,'days'))\n",
    "network = task_list[0][0]\n",
    "station = task_list[0][1]\n",
    "run_detection(network,station,t1,t2,filepath,twin,step,l_blnd,r_blnd)\n",
    "# @dask.delayed\n",
    "# def loop_days(task,filepath,twin,step,l_blnd,r_blnd):\n",
    "\n",
    "#     # Define the parameters that are specific to each task\n",
    "#     t1 = obspy.UTCDateTime(task[2])\n",
    "#     t2 = obspy.UTCDateTime(t1 + pd.Timedelta(1,'days'))\n",
    "#     network = task[0]\n",
    "#     station = task[1]\n",
    "\n",
    "#     #print network and station\n",
    "#     # Call to the function that will perform the operation and write the results to file\n",
    "#     run_detection(network,station,t1,t2,filepath,twin,step,l_blnd,r_blnd)\n",
    "    \n",
    "#     return\n",
    "\n",
    "\n",
    "# # # Now we set up the parallel operation\n",
    "# # # The below builds a framework for the computer to run in parallel. This doesn't actually execute anything.\n",
    "# lazy_results = [loop_days(task,filepath,twin,step,l_blnd,r_blnd) for task in task_list]\n",
    "    \n",
    "\n",
    "# # # The below actually executes the parallel operation!\n",
    "# # # It's nice to do it with the ProgressBar so you can see how long things are taking.\n",
    "# # # Each operation should also write a file so that is another way to check on progress.\n",
    "# # with ProgressBar():\n",
    "# #     #################################\n",
    "# #     # Add scheduler = 'single-threaded'\n",
    "# # \tdask.compute(lazy_results, scheduler='single-threaded') \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f374cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze > ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd66c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Usage:   \r\n",
      "  pip <command> [options]\r\n",
      "\r\n",
      "Commands:\r\n",
      "  install                     Install packages.\r\n",
      "  download                    Download packages.\r\n",
      "  uninstall                   Uninstall packages.\r\n",
      "  freeze                      Output installed packages in requirements format.\r\n",
      "  list                        List installed packages.\r\n",
      "  show                        Show information about installed packages.\r\n",
      "  check                       Verify installed packages have compatible dependencies.\r\n",
      "  search                      Search PyPI for packages.\r\n",
      "  wheel                       Build wheels from your requirements.\r\n",
      "  hash                        Compute hashes of package archives.\r\n",
      "  completion                  A helper command used for command completion.\r\n",
      "  help                        Show help for commands.\r\n",
      "\r\n",
      "General Options:\r\n",
      "  -h, --help                  Show help.\r\n",
      "  --isolated                  Run pip in an isolated mode, ignoring\r\n",
      "                              environment variables and user configuration.\r\n",
      "  -v, --verbose               Give more output. Option is additive, and can be\r\n",
      "                              used up to 3 times.\r\n",
      "  -V, --version               Show version and exit.\r\n",
      "  -q, --quiet                 Give less output. Option is additive, and can be\r\n",
      "                              used up to 3 times (corresponding to WARNING,\r\n",
      "                              ERROR, and CRITICAL logging levels).\r\n",
      "  --log <path>                Path to a verbose appending log.\r\n",
      "  --proxy <proxy>             Specify a proxy in the form\r\n",
      "                              [user:passwd@]proxy.server:port.\r\n",
      "  --retries <retries>         Maximum number of retries each connection should\r\n",
      "                              attempt (default 5 times).\r\n",
      "  --timeout <sec>             Set the socket timeout (default 15 seconds).\r\n",
      "  --exists-action <action>    Default action when a path already exists:\r\n",
      "                              (s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort.\r\n",
      "  --trusted-host <hostname>   Mark this host as trusted, even though it does\r\n",
      "                              not have valid or any HTTPS.\r\n",
      "  --cert <path>               Path to alternate CA bundle.\r\n",
      "  --client-cert <path>        Path to SSL client certificate, a single file\r\n",
      "                              containing the private key and the certificate\r\n",
      "                              in PEM format.\r\n",
      "  --cache-dir <dir>           Store the cache data in <dir>.\r\n",
      "  --no-cache-dir              Disable the cache.\r\n",
      "  --disable-pip-version-check\r\n",
      "                              Don't periodically check PyPI to determine\r\n",
      "                              whether a new version of pip is available for\r\n",
      "                              download. Implied with --no-index.\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7127a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    ":"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
