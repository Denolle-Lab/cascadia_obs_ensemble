{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9659be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install basemap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92e5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import obspy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.clients.fdsn import Client as FDSNClient\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "\n",
    "from pnwstore.mseed import WaveformClient\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "from tqdm import tqdm\n",
    "from obspy.geodetics import locations2degrees, degrees2kilometers\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, '../'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "from plot_utils import *\n",
    "from qc_utils import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce408df1",
   "metadata": {},
   "source": [
    "## Morton Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd019d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CI YEAR</th>\n",
       "      <th>TSTRING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>SECOND</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>...</th>\n",
       "      <th>dist to nearest stn</th>\n",
       "      <th>tt RMS</th>\n",
       "      <th>ERH</th>\n",
       "      <th>ERZ</th>\n",
       "      <th>STRIKE</th>\n",
       "      <th>DIP</th>\n",
       "      <th>RAKE</th>\n",
       "      <th>PLATE DESIGNATION</th>\n",
       "      <th>TEMPLATE EVENT?</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.37</td>\n",
       "      <td>47.3217</td>\n",
       "      <td>-123.2708</td>\n",
       "      <td>...</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interface</td>\n",
       "      <td>Catalog</td>\n",
       "      <td>2011-07-26 01:02:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.72</td>\n",
       "      <td>44.2888</td>\n",
       "      <td>-124.3340</td>\n",
       "      <td>...</td>\n",
       "      <td>163.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>13.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-26 01:02:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>44.3017</td>\n",
       "      <td>-124.3180</td>\n",
       "      <td>...</td>\n",
       "      <td>131.1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>35.4</td>\n",
       "      <td>22.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-26 01:02:08+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.17</td>\n",
       "      <td>48.2635</td>\n",
       "      <td>-124.9298</td>\n",
       "      <td>...</td>\n",
       "      <td>44.4</td>\n",
       "      <td>0.77</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-26 07:31:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.63</td>\n",
       "      <td>48.3032</td>\n",
       "      <td>-124.9157</td>\n",
       "      <td>...</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>T</td>\n",
       "      <td>2011-07-26 09:50:27+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CI YEAR       TSTRING    YEAR  MONTH   DAY  HOUR  MINUTE  SECOND      LAT  \\\n",
       "0      1.0  2.011073e+13  2011.0    7.0  26.0   1.0     2.0    7.37  47.3217   \n",
       "1      1.0  2.011073e+13  2011.0    7.0  26.0   1.0     2.0    7.72  44.2888   \n",
       "2      1.0  2.011073e+13  2011.0    7.0  26.0   1.0     2.0    8.56  44.3017   \n",
       "3      1.0  2.011073e+13  2011.0    7.0  26.0   7.0    31.0    2.17  48.2635   \n",
       "4      1.0  2.011073e+13  2011.0    7.0  26.0   9.0    50.0   27.63  48.3032   \n",
       "\n",
       "        LON  ...  dist to nearest stn  tt RMS   ERH   ERZ  STRIKE  DIP  RAKE  \\\n",
       "0 -123.2708  ...                 27.4    0.19   0.8   1.2     NaN  NaN   NaN   \n",
       "1 -124.3340  ...                163.8    0.06  13.1   3.2     NaN  NaN   NaN   \n",
       "2 -124.3180  ...                131.1    0.50  35.4  22.2     NaN  NaN   NaN   \n",
       "3 -124.9298  ...                 44.4    0.77   3.5   6.4     NaN  NaN   NaN   \n",
       "4 -124.9157  ...                 46.1    0.94   4.0   6.9     NaN  NaN   NaN   \n",
       "\n",
       "   PLATE DESIGNATION  TEMPLATE EVENT?                  datetime  \n",
       "0          Interface          Catalog 2011-07-26 01:02:07+00:00  \n",
       "1        Upper Plate              NaN 2011-07-26 01:02:07+00:00  \n",
       "2        Upper Plate              NaN 2011-07-26 01:02:08+00:00  \n",
       "3        Upper Plate              NaN 2011-07-26 07:31:02+00:00  \n",
       "4        Upper Plate                T 2011-07-26 09:50:27+00:00  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Morton's catalog\n",
    "events_morton = pd.read_csv('../data/ds01.csv')\n",
    "# Convert the TSTRING to datetime\n",
    "events_morton['datetime'] = pd.to_datetime(events_morton['TSTRING'], format='%Y%m%d%H%M%S', utc=True)\n",
    "# Get the events in the Morton catalog \n",
    "t1 = pd.Timestamp('2011-1-1 00:00:00.000000+0000', tz='UTC')\n",
    "t2 = pd.Timestamp('2015-12-31 23:59:59.999999+0000', tz='UTC')\n",
    "\n",
    "events_morton= events_morton.loc[(events_morton['datetime'] > t1) & (events_morton['datetime'] < t2) ]\n",
    "\n",
    "events_morton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e58514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CI YEAR</th>\n",
       "      <th>TSTRING</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MINUTE</th>\n",
       "      <th>SECOND</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>...</th>\n",
       "      <th>dist to nearest stn</th>\n",
       "      <th>tt RMS</th>\n",
       "      <th>ERH</th>\n",
       "      <th>ERZ</th>\n",
       "      <th>STRIKE</th>\n",
       "      <th>DIP</th>\n",
       "      <th>RAKE</th>\n",
       "      <th>PLATE DESIGNATION</th>\n",
       "      <th>TEMPLATE EVENT?</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.37</td>\n",
       "      <td>47.3217</td>\n",
       "      <td>-123.2708</td>\n",
       "      <td>...</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interface</td>\n",
       "      <td>Catalog</td>\n",
       "      <td>2011-07-26 01:02:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.72</td>\n",
       "      <td>44.2888</td>\n",
       "      <td>-124.3340</td>\n",
       "      <td>...</td>\n",
       "      <td>163.8</td>\n",
       "      <td>0.06</td>\n",
       "      <td>13.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-26 01:02:07+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>44.3017</td>\n",
       "      <td>-124.3180</td>\n",
       "      <td>...</td>\n",
       "      <td>131.1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>35.4</td>\n",
       "      <td>22.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-26 01:02:08+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.17</td>\n",
       "      <td>48.2635</td>\n",
       "      <td>-124.9298</td>\n",
       "      <td>...</td>\n",
       "      <td>44.4</td>\n",
       "      <td>0.77</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-07-26 07:31:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.011073e+13</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>27.63</td>\n",
       "      <td>48.3032</td>\n",
       "      <td>-124.9157</td>\n",
       "      <td>...</td>\n",
       "      <td>46.1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>T</td>\n",
       "      <td>2011-07-26 09:50:27+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.015101e+13</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.83</td>\n",
       "      <td>40.5895</td>\n",
       "      <td>-124.0455</td>\n",
       "      <td>...</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Slab</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-10-07 08:01:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.015101e+13</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>40.5380</td>\n",
       "      <td>-123.7217</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-10-07 08:07:08+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.015101e+13</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>26.69</td>\n",
       "      <td>40.5822</td>\n",
       "      <td>-124.0432</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Slab</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-10-07 11:31:26+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.015101e+13</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.52</td>\n",
       "      <td>40.2710</td>\n",
       "      <td>-124.3777</td>\n",
       "      <td>...</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper Plate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-10-07 18:11:09+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.015101e+13</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>50.37</td>\n",
       "      <td>40.1602</td>\n",
       "      <td>-123.8320</td>\n",
       "      <td>...</td>\n",
       "      <td>29.4</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.3</td>\n",
       "      <td>18.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-10-07 21:45:50+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5282 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CI YEAR       TSTRING    YEAR  MONTH   DAY  HOUR  MINUTE  SECOND  \\\n",
       "0         1.0  2.011073e+13  2011.0    7.0  26.0   1.0     2.0    7.37   \n",
       "1         1.0  2.011073e+13  2011.0    7.0  26.0   1.0     2.0    7.72   \n",
       "2         1.0  2.011073e+13  2011.0    7.0  26.0   1.0     2.0    8.56   \n",
       "3         1.0  2.011073e+13  2011.0    7.0  26.0   7.0    31.0    2.17   \n",
       "4         1.0  2.011073e+13  2011.0    7.0  26.0   9.0    50.0   27.63   \n",
       "...       ...           ...     ...    ...   ...   ...     ...     ...   \n",
       "5277      4.0  2.015101e+13  2015.0   10.0   7.0   8.0     1.0   50.83   \n",
       "5278      4.0  2.015101e+13  2015.0   10.0   7.0   8.0     7.0    8.40   \n",
       "5279      4.0  2.015101e+13  2015.0   10.0   7.0  11.0    31.0   26.69   \n",
       "5280      4.0  2.015101e+13  2015.0   10.0   7.0  18.0    11.0    9.52   \n",
       "5281      4.0  2.015101e+13  2015.0   10.0   7.0  21.0    45.0   50.37   \n",
       "\n",
       "          LAT       LON  ...  dist to nearest stn  tt RMS   ERH   ERZ  STRIKE  \\\n",
       "0     47.3217 -123.2708  ...                 27.4    0.19   0.8   1.2     NaN   \n",
       "1     44.2888 -124.3340  ...                163.8    0.06  13.1   3.2     NaN   \n",
       "2     44.3017 -124.3180  ...                131.1    0.50  35.4  22.2     NaN   \n",
       "3     48.2635 -124.9298  ...                 44.4    0.77   3.5   6.4     NaN   \n",
       "4     48.3032 -124.9157  ...                 46.1    0.94   4.0   6.9     NaN   \n",
       "...       ...       ...  ...                  ...     ...   ...   ...     ...   \n",
       "5277  40.5895 -124.0455  ...                  5.4    0.14   0.9   0.8     NaN   \n",
       "5278  40.5380 -123.7217  ...                 14.9    0.09   3.3  13.5     NaN   \n",
       "5279  40.5822 -124.0432  ...                  5.6    0.05   1.7   0.8     NaN   \n",
       "5280  40.2710 -124.3777  ...                  7.9    0.19   0.7   0.2     NaN   \n",
       "5281  40.1602 -123.8320  ...                 29.4    0.22   1.3  18.6     NaN   \n",
       "\n",
       "      DIP  RAKE  PLATE DESIGNATION  TEMPLATE EVENT?                  datetime  \n",
       "0     NaN   NaN          Interface          Catalog 2011-07-26 01:02:07+00:00  \n",
       "1     NaN   NaN        Upper Plate              NaN 2011-07-26 01:02:07+00:00  \n",
       "2     NaN   NaN        Upper Plate              NaN 2011-07-26 01:02:08+00:00  \n",
       "3     NaN   NaN        Upper Plate              NaN 2011-07-26 07:31:02+00:00  \n",
       "4     NaN   NaN        Upper Plate                T 2011-07-26 09:50:27+00:00  \n",
       "...   ...   ...                ...              ...                       ...  \n",
       "5277  NaN   NaN               Slab              NaN 2015-10-07 08:01:50+00:00  \n",
       "5278  NaN   NaN        Upper Plate              NaN 2015-10-07 08:07:08+00:00  \n",
       "5279  NaN   NaN               Slab              NaN 2015-10-07 11:31:26+00:00  \n",
       "5280  NaN   NaN        Upper Plate              NaN 2015-10-07 18:11:09+00:00  \n",
       "5281  NaN   NaN              Undef              NaN 2015-10-07 21:45:50+00:00  \n",
       "\n",
       "[5282 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_morton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24957dc",
   "metadata": {},
   "source": [
    "## ANSS Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca384628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>...</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-01T00:21:06.570Z</td>\n",
       "      <td>38.809834</td>\n",
       "      <td>-122.793663</td>\n",
       "      <td>1.746</td>\n",
       "      <td>0.88</td>\n",
       "      <td>md</td>\n",
       "      <td>14.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>...</td>\n",
       "      <td>6 km WSW of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.010</td>\n",
       "      <td>16.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2011-01-01 00:21:06.570000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01T02:04:41.480Z</td>\n",
       "      <td>38.789001</td>\n",
       "      <td>-122.747002</td>\n",
       "      <td>-0.844</td>\n",
       "      <td>0.28</td>\n",
       "      <td>md</td>\n",
       "      <td>5.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>...</td>\n",
       "      <td>4 km SSW of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.200</td>\n",
       "      <td>6.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2011-01-01 02:04:41.480000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01T02:53:49.640Z</td>\n",
       "      <td>38.817333</td>\n",
       "      <td>-122.821167</td>\n",
       "      <td>1.929</td>\n",
       "      <td>1.03</td>\n",
       "      <td>md</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>...</td>\n",
       "      <td>8 km W of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.060</td>\n",
       "      <td>13.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2011-01-01 02:53:49.640000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01T03:11:04.720Z</td>\n",
       "      <td>38.841835</td>\n",
       "      <td>-122.829002</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.43</td>\n",
       "      <td>md</td>\n",
       "      <td>7.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>...</td>\n",
       "      <td>9 km WNW of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.150</td>\n",
       "      <td>7.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2011-01-01 03:11:04.720000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01T03:32:55.630Z</td>\n",
       "      <td>38.835833</td>\n",
       "      <td>-122.807000</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.16</td>\n",
       "      <td>md</td>\n",
       "      <td>9.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>...</td>\n",
       "      <td>7 km WNW of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.123</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2011-01-01 03:32:55.630000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131527</th>\n",
       "      <td>131527</td>\n",
       "      <td>2015-12-31T22:15:46.650Z</td>\n",
       "      <td>38.837502</td>\n",
       "      <td>-122.825333</td>\n",
       "      <td>1.450</td>\n",
       "      <td>0.18</td>\n",
       "      <td>md</td>\n",
       "      <td>6.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>...</td>\n",
       "      <td>9 km W of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.110</td>\n",
       "      <td>2.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2015-12-31 22:15:46.650000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131528</th>\n",
       "      <td>131528</td>\n",
       "      <td>2015-12-31T22:18:13.120Z</td>\n",
       "      <td>41.856400</td>\n",
       "      <td>-119.599200</td>\n",
       "      <td>8.700</td>\n",
       "      <td>1.40</td>\n",
       "      <td>ml</td>\n",
       "      <td>6.0</td>\n",
       "      <td>210.1</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>...</td>\n",
       "      <td>45 km E of Fort Bidwell, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.210</td>\n",
       "      <td>3.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>nn</td>\n",
       "      <td>nn</td>\n",
       "      <td>2015-12-31 22:18:13.120000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131529</th>\n",
       "      <td>131529</td>\n",
       "      <td>2015-12-31T23:19:21.650Z</td>\n",
       "      <td>38.823334</td>\n",
       "      <td>-122.765663</td>\n",
       "      <td>1.680</td>\n",
       "      <td>0.54</td>\n",
       "      <td>md</td>\n",
       "      <td>7.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>...</td>\n",
       "      <td>3 km W of Cobb, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2015-12-31 23:19:21.650000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131530</th>\n",
       "      <td>131530</td>\n",
       "      <td>2015-12-31T23:22:20.730Z</td>\n",
       "      <td>38.841000</td>\n",
       "      <td>-122.878166</td>\n",
       "      <td>1.730</td>\n",
       "      <td>0.77</td>\n",
       "      <td>md</td>\n",
       "      <td>8.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>...</td>\n",
       "      <td>12 km ENE of Cloverdale, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.180</td>\n",
       "      <td>3.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2015-12-31 23:22:20.730000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131531</th>\n",
       "      <td>131531</td>\n",
       "      <td>2015-12-31T23:53:17.350Z</td>\n",
       "      <td>40.457667</td>\n",
       "      <td>-124.763000</td>\n",
       "      <td>24.960</td>\n",
       "      <td>2.32</td>\n",
       "      <td>md</td>\n",
       "      <td>16.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>0.325200</td>\n",
       "      <td>...</td>\n",
       "      <td>44 km WSW of Ferndale, California</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.72</td>\n",
       "      <td>0.324</td>\n",
       "      <td>18.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "      <td>2015-12-31 23:53:17.350000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131532 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                      time   latitude   longitude   depth  \\\n",
       "0                0  2011-01-01T00:21:06.570Z  38.809834 -122.793663   1.746   \n",
       "1                1  2011-01-01T02:04:41.480Z  38.789001 -122.747002  -0.844   \n",
       "2                2  2011-01-01T02:53:49.640Z  38.817333 -122.821167   1.929   \n",
       "3                3  2011-01-01T03:11:04.720Z  38.841835 -122.829002   1.076   \n",
       "4                4  2011-01-01T03:32:55.630Z  38.835833 -122.807000   0.947   \n",
       "...            ...                       ...        ...         ...     ...   \n",
       "131527      131527  2015-12-31T22:15:46.650Z  38.837502 -122.825333   1.450   \n",
       "131528      131528  2015-12-31T22:18:13.120Z  41.856400 -119.599200   8.700   \n",
       "131529      131529  2015-12-31T23:19:21.650Z  38.823334 -122.765663   1.680   \n",
       "131530      131530  2015-12-31T23:22:20.730Z  38.841000 -122.878166   1.730   \n",
       "131531      131531  2015-12-31T23:53:17.350Z  40.457667 -124.763000  24.960   \n",
       "\n",
       "         mag magType   nst    gap      dmin  ...  \\\n",
       "0       0.88      md  14.0   73.0  0.001802  ...   \n",
       "1       0.28      md   5.0  122.0  0.009910  ...   \n",
       "2       1.03      md  40.0   44.0  0.010810  ...   \n",
       "3       0.43      md   7.0   77.0  0.013510  ...   \n",
       "4       0.16      md   9.0  112.0  0.012610  ...   \n",
       "...      ...     ...   ...    ...       ...  ...   \n",
       "131527  0.18      md   6.0  180.0  0.008108  ...   \n",
       "131528  1.40      ml   6.0  210.1  0.175000  ...   \n",
       "131529  0.54      md   7.0   99.0  0.008108  ...   \n",
       "131530  0.77      md   8.0   95.0  0.007207  ...   \n",
       "131531  2.32      md  16.0  301.0  0.325200  ...   \n",
       "\n",
       "                                      place        type horizontalError  \\\n",
       "0              6 km WSW of Cobb, California  earthquake            0.30   \n",
       "1              4 km SSW of Cobb, California  earthquake            0.42   \n",
       "2                8 km W of Cobb, California  earthquake            0.14   \n",
       "3              9 km WNW of Cobb, California  earthquake            0.43   \n",
       "4              7 km WNW of Cobb, California  earthquake            0.33   \n",
       "...                                     ...         ...             ...   \n",
       "131527           9 km W of Cobb, California  earthquake            0.66   \n",
       "131528  45 km E of Fort Bidwell, California  earthquake             NaN   \n",
       "131529           3 km W of Cobb, California  earthquake            0.50   \n",
       "131530  12 km ENE of Cloverdale, California  earthquake            0.58   \n",
       "131531    44 km WSW of Ferndale, California  earthquake            0.99   \n",
       "\n",
       "       depthError magError magNst     status  locationSource  magSource  \\\n",
       "0            0.56    0.010   16.0  automatic              nc         nc   \n",
       "1            2.39    0.200    6.0  automatic              nc         nc   \n",
       "2            0.19    0.060   13.0   reviewed              nc         nc   \n",
       "3            0.88    0.150    7.0  automatic              nc         nc   \n",
       "4            0.72    0.123    2.0   reviewed              nc         nc   \n",
       "...           ...      ...    ...        ...             ...        ...   \n",
       "131527       1.08    0.110    2.0  automatic              nc         nc   \n",
       "131528       3.40    0.210    3.0   reviewed              nn         nn   \n",
       "131529       1.54    0.030    2.0  automatic              nc         nc   \n",
       "131530       1.02    0.180    3.0  automatic              nc         nc   \n",
       "131531       4.72    0.324   18.0   reviewed              nc         nc   \n",
       "\n",
       "                               datetime  \n",
       "0      2011-01-01 00:21:06.570000+00:00  \n",
       "1      2011-01-01 02:04:41.480000+00:00  \n",
       "2      2011-01-01 02:53:49.640000+00:00  \n",
       "3      2011-01-01 03:11:04.720000+00:00  \n",
       "4      2011-01-01 03:32:55.630000+00:00  \n",
       "...                                 ...  \n",
       "131527 2015-12-31 22:15:46.650000+00:00  \n",
       "131528 2015-12-31 22:18:13.120000+00:00  \n",
       "131529 2015-12-31 23:19:21.650000+00:00  \n",
       "131530 2015-12-31 23:22:20.730000+00:00  \n",
       "131531 2015-12-31 23:53:17.350000+00:00  \n",
       "\n",
       "[131532 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_anss = pd.read_csv('../data/datasets_anss/anss_2011-15.csv')\n",
    "events_anss['datetime'] = pd.to_datetime(events_anss['time'], format='%Y-%m-%dT%H:%M:%S.%fZ', utc=True)\n",
    "events_anss= events_anss.loc[(events_anss['datetime'] > t1) & (events_anss['datetime'] < t2) ]\n",
    "events_anss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2499c46",
   "metadata": {},
   "source": [
    "## Our Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0456713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2254654/3468245980.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mycatalog['datetime'] = pd.to_datetime(mycatalog['time'], utc = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>idx</th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>picks</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>event_idx</th>\n",
       "      <th>pick_idx</th>\n",
       "      <th>residual</th>\n",
       "      <th>station</th>\n",
       "      <th>phase</th>\n",
       "      <th>time_pick</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-11-09 17:24:51.454200+00:00</td>\n",
       "      <td>-108.775094</td>\n",
       "      <td>-173.323761</td>\n",
       "      <td>6.640625</td>\n",
       "      <td>6</td>\n",
       "      <td>42.932269</td>\n",
       "      <td>-126.832522</td>\n",
       "      <td>6.640625</td>\n",
       "      <td>1</td>\n",
       "      <td>742471</td>\n",
       "      <td>0.186548</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.320860e+09</td>\n",
       "      <td>2011-11-09 17:24:51.454200+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-12-08 18:34:06.040983+00:00</td>\n",
       "      <td>-99.849958</td>\n",
       "      <td>-173.323761</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>6</td>\n",
       "      <td>42.933490</td>\n",
       "      <td>-126.723212</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>2</td>\n",
       "      <td>717826</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.323369e+09</td>\n",
       "      <td>2011-12-08 18:34:06.040983+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-12-20 00:00:16.064003+00:00</td>\n",
       "      <td>-0.557821</td>\n",
       "      <td>9.767689</td>\n",
       "      <td>25.390625</td>\n",
       "      <td>6</td>\n",
       "      <td>44.587900</td>\n",
       "      <td>-125.507025</td>\n",
       "      <td>25.390625</td>\n",
       "      <td>3</td>\n",
       "      <td>704159</td>\n",
       "      <td>1.143362</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.324339e+09</td>\n",
       "      <td>2011-12-20 00:00:16.064003+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-02-03 03:03:40.803628+00:00</td>\n",
       "      <td>-126.625365</td>\n",
       "      <td>-153.298134</td>\n",
       "      <td>12.890625</td>\n",
       "      <td>6</td>\n",
       "      <td>43.109709</td>\n",
       "      <td>-127.055663</td>\n",
       "      <td>12.890625</td>\n",
       "      <td>4</td>\n",
       "      <td>190297</td>\n",
       "      <td>-0.196536</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.328238e+09</td>\n",
       "      <td>2012-02-03 03:03:40.803628+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-02-15 03:31:16.120587+00:00</td>\n",
       "      <td>-179.060539</td>\n",
       "      <td>-143.285320</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>7</td>\n",
       "      <td>43.189203</td>\n",
       "      <td>-127.702694</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>6</td>\n",
       "      <td>208779</td>\n",
       "      <td>0.308213</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.329277e+09</td>\n",
       "      <td>2012-02-15 03:31:16.120587+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-04-18 15:20:59.528926+00:00</td>\n",
       "      <td>99.849958</td>\n",
       "      <td>14.058895</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>6</td>\n",
       "      <td>44.619587</td>\n",
       "      <td>-124.241920</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>9</td>\n",
       "      <td>238399</td>\n",
       "      <td>-0.514313</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.334762e+09</td>\n",
       "      <td>2012-04-18 15:20:59.528926+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-05-10 10:58:55.563721+00:00</td>\n",
       "      <td>-166.788477</td>\n",
       "      <td>-154.728536</td>\n",
       "      <td>44.140625</td>\n",
       "      <td>7</td>\n",
       "      <td>43.089072</td>\n",
       "      <td>-127.548388</td>\n",
       "      <td>44.140625</td>\n",
       "      <td>10</td>\n",
       "      <td>44040</td>\n",
       "      <td>-0.330297</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.336648e+09</td>\n",
       "      <td>2012-05-10 10:58:55.563721+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>2012-07-10 13:58:25.328216+00:00</td>\n",
       "      <td>-30.680155</td>\n",
       "      <td>-94.651654</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>6</td>\n",
       "      <td>43.647522</td>\n",
       "      <td>-125.880272</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>13</td>\n",
       "      <td>96284</td>\n",
       "      <td>-0.208655</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.341929e+09</td>\n",
       "      <td>2012-07-10 13:58:25.328216+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>2012-07-18 00:20:00.702900+00:00</td>\n",
       "      <td>201.373378</td>\n",
       "      <td>-210.514212</td>\n",
       "      <td>11.328125</td>\n",
       "      <td>6</td>\n",
       "      <td>42.578980</td>\n",
       "      <td>-123.047148</td>\n",
       "      <td>11.328125</td>\n",
       "      <td>14</td>\n",
       "      <td>23216</td>\n",
       "      <td>-0.073185</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.342571e+09</td>\n",
       "      <td>2012-07-18 00:20:00.702900+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>15</td>\n",
       "      <td>2012-08-29 07:54:52.443774+00:00</td>\n",
       "      <td>22.870661</td>\n",
       "      <td>14.058895</td>\n",
       "      <td>32.421875</td>\n",
       "      <td>6</td>\n",
       "      <td>44.626153</td>\n",
       "      <td>-125.211804</td>\n",
       "      <td>32.421875</td>\n",
       "      <td>15</td>\n",
       "      <td>178762</td>\n",
       "      <td>0.127071</td>\n",
       "      <td>J25B</td>\n",
       "      <td>P</td>\n",
       "      <td>1.346227e+09</td>\n",
       "      <td>2012-08-29 07:54:52.443774+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>16</td>\n",
       "      <td>2012-08-29 08:05:26.522418+00:00</td>\n",
       "      <td>96.503032</td>\n",
       "      <td>19.780503</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>6</td>\n",
       "      <td>44.671520</td>\n",
       "      <td>-124.283004</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>16</td>\n",
       "      <td>178768</td>\n",
       "      <td>-0.570727</td>\n",
       "      <td>J25B</td>\n",
       "      <td>P</td>\n",
       "      <td>1.346228e+09</td>\n",
       "      <td>2012-08-29 08:05:26.522418+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>19</td>\n",
       "      <td>2012-09-18 19:57:10.268089+00:00</td>\n",
       "      <td>-71.958908</td>\n",
       "      <td>-174.754163</td>\n",
       "      <td>3.515625</td>\n",
       "      <td>6</td>\n",
       "      <td>42.923756</td>\n",
       "      <td>-126.381396</td>\n",
       "      <td>3.515625</td>\n",
       "      <td>19</td>\n",
       "      <td>236283</td>\n",
       "      <td>-0.905047</td>\n",
       "      <td>J25B</td>\n",
       "      <td>P</td>\n",
       "      <td>1.347998e+09</td>\n",
       "      <td>2012-09-18 19:57:10.268089+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>21</td>\n",
       "      <td>2012-11-03 23:54:43.276284+00:00</td>\n",
       "      <td>111.006378</td>\n",
       "      <td>65.553366</td>\n",
       "      <td>49.609375</td>\n",
       "      <td>6</td>\n",
       "      <td>45.081189</td>\n",
       "      <td>-124.090134</td>\n",
       "      <td>49.609375</td>\n",
       "      <td>21</td>\n",
       "      <td>97669</td>\n",
       "      <td>-0.145679</td>\n",
       "      <td>J25B</td>\n",
       "      <td>P</td>\n",
       "      <td>1.351987e+09</td>\n",
       "      <td>2012-11-03 23:54:43.276284+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>25</td>\n",
       "      <td>2014-01-15 08:31:57.792461+00:00</td>\n",
       "      <td>-127.741007</td>\n",
       "      <td>-177.614967</td>\n",
       "      <td>26.953125</td>\n",
       "      <td>6</td>\n",
       "      <td>42.890716</td>\n",
       "      <td>-127.063804</td>\n",
       "      <td>26.953125</td>\n",
       "      <td>25</td>\n",
       "      <td>276927</td>\n",
       "      <td>0.137358</td>\n",
       "      <td>J25C</td>\n",
       "      <td>P</td>\n",
       "      <td>1.389775e+09</td>\n",
       "      <td>2014-01-15 08:31:57.792461+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>27</td>\n",
       "      <td>2014-02-25 23:03:08.886563+00:00</td>\n",
       "      <td>-9.482957</td>\n",
       "      <td>-87.499644</td>\n",
       "      <td>12.890625</td>\n",
       "      <td>6</td>\n",
       "      <td>43.712465</td>\n",
       "      <td>-125.617665</td>\n",
       "      <td>12.890625</td>\n",
       "      <td>27</td>\n",
       "      <td>281071</td>\n",
       "      <td>-0.054492</td>\n",
       "      <td>J25C</td>\n",
       "      <td>P</td>\n",
       "      <td>1.393369e+09</td>\n",
       "      <td>2014-02-25 23:03:08.886563+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>28</td>\n",
       "      <td>2014-05-12 16:45:45.434971+00:00</td>\n",
       "      <td>-232.611354</td>\n",
       "      <td>-103.234065</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>6</td>\n",
       "      <td>43.534678</td>\n",
       "      <td>-128.377708</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>28</td>\n",
       "      <td>398532</td>\n",
       "      <td>-0.269836</td>\n",
       "      <td>J25C</td>\n",
       "      <td>P</td>\n",
       "      <td>1.399913e+09</td>\n",
       "      <td>2014-05-12 16:45:45.434971+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>29</td>\n",
       "      <td>2014-05-12 18:50:56.744503+00:00</td>\n",
       "      <td>-228.148786</td>\n",
       "      <td>-106.094869</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>6</td>\n",
       "      <td>43.510336</td>\n",
       "      <td>-128.321367</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>29</td>\n",
       "      <td>398538</td>\n",
       "      <td>-0.057347</td>\n",
       "      <td>J25C</td>\n",
       "      <td>P</td>\n",
       "      <td>1.399921e+09</td>\n",
       "      <td>2014-05-12 18:50:56.744503+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  idx                              time           x           y  \\\n",
       "0            0    1  2011-11-09 17:24:51.454200+00:00 -108.775094 -173.323761   \n",
       "6            6    2  2011-12-08 18:34:06.040983+00:00  -99.849958 -173.323761   \n",
       "12          12    3  2011-12-20 00:00:16.064003+00:00   -0.557821    9.767689   \n",
       "18          18    4  2012-02-03 03:03:40.803628+00:00 -126.625365 -153.298134   \n",
       "24          24    6  2012-02-15 03:31:16.120587+00:00 -179.060539 -143.285320   \n",
       "31          31    9  2012-04-18 15:20:59.528926+00:00   99.849958   14.058895   \n",
       "37          37   10  2012-05-10 10:58:55.563721+00:00 -166.788477 -154.728536   \n",
       "44          44   13  2012-07-10 13:58:25.328216+00:00  -30.680155  -94.651654   \n",
       "50          50   14  2012-07-18 00:20:00.702900+00:00  201.373378 -210.514212   \n",
       "56          56   15  2012-08-29 07:54:52.443774+00:00   22.870661   14.058895   \n",
       "62          62   16  2012-08-29 08:05:26.522418+00:00   96.503032   19.780503   \n",
       "68          68   19  2012-09-18 19:57:10.268089+00:00  -71.958908 -174.754163   \n",
       "74          74   21  2012-11-03 23:54:43.276284+00:00  111.006378   65.553366   \n",
       "80          80   25  2014-01-15 08:31:57.792461+00:00 -127.741007 -177.614967   \n",
       "86          86   27  2014-02-25 23:03:08.886563+00:00   -9.482957  -87.499644   \n",
       "92          92   28  2014-05-12 16:45:45.434971+00:00 -232.611354 -103.234065   \n",
       "98          98   29  2014-05-12 18:50:56.744503+00:00 -228.148786 -106.094869   \n",
       "\n",
       "            z  picks   latitude   longitude      depth  event_idx  pick_idx  \\\n",
       "0    6.640625      6  42.932269 -126.832522   6.640625          1    742471   \n",
       "6    1.171875      6  42.933490 -126.723212   1.171875          2    717826   \n",
       "12  25.390625      6  44.587900 -125.507025  25.390625          3    704159   \n",
       "18  12.890625      6  43.109709 -127.055663  12.890625          4    190297   \n",
       "24   2.734375      7  43.189203 -127.702694   2.734375          6    208779   \n",
       "31   1.171875      6  44.619587 -124.241920   1.171875          9    238399   \n",
       "37  44.140625      7  43.089072 -127.548388  44.140625         10     44040   \n",
       "44   2.734375      6  43.647522 -125.880272   2.734375         13     96284   \n",
       "50  11.328125      6  42.578980 -123.047148  11.328125         14     23216   \n",
       "56  32.421875      6  44.626153 -125.211804  32.421875         15    178762   \n",
       "62   1.953125      6  44.671520 -124.283004   1.953125         16    178768   \n",
       "68   3.515625      6  42.923756 -126.381396   3.515625         19    236283   \n",
       "74  49.609375      6  45.081189 -124.090134  49.609375         21     97669   \n",
       "80  26.953125      6  42.890716 -127.063804  26.953125         25    276927   \n",
       "86  12.890625      6  43.712465 -125.617665  12.890625         27    281071   \n",
       "92   2.734375      6  43.534678 -128.377708   2.734375         28    398532   \n",
       "98   0.390625      6  43.510336 -128.321367   0.390625         29    398538   \n",
       "\n",
       "    residual station phase     time_pick                         datetime  \n",
       "0   0.186548    J25A     P  1.320860e+09 2011-11-09 17:24:51.454200+00:00  \n",
       "6   0.747435    J25A     P  1.323369e+09 2011-12-08 18:34:06.040983+00:00  \n",
       "12  1.143362    J25A     P  1.324339e+09 2011-12-20 00:00:16.064003+00:00  \n",
       "18 -0.196536    J25A     P  1.328238e+09 2012-02-03 03:03:40.803628+00:00  \n",
       "24  0.308213    J25A     P  1.329277e+09 2012-02-15 03:31:16.120587+00:00  \n",
       "31 -0.514313    J25A     P  1.334762e+09 2012-04-18 15:20:59.528926+00:00  \n",
       "37 -0.330297    J25A     P  1.336648e+09 2012-05-10 10:58:55.563721+00:00  \n",
       "44 -0.208655    J25A     P  1.341929e+09 2012-07-10 13:58:25.328216+00:00  \n",
       "50 -0.073185    J25A     P  1.342571e+09 2012-07-18 00:20:00.702900+00:00  \n",
       "56  0.127071    J25B     P  1.346227e+09 2012-08-29 07:54:52.443774+00:00  \n",
       "62 -0.570727    J25B     P  1.346228e+09 2012-08-29 08:05:26.522418+00:00  \n",
       "68 -0.905047    J25B     P  1.347998e+09 2012-09-18 19:57:10.268089+00:00  \n",
       "74 -0.145679    J25B     P  1.351987e+09 2012-11-03 23:54:43.276284+00:00  \n",
       "80  0.137358    J25C     P  1.389775e+09 2014-01-15 08:31:57.792461+00:00  \n",
       "86 -0.054492    J25C     P  1.393369e+09 2014-02-25 23:03:08.886563+00:00  \n",
       "92 -0.269836    J25C     P  1.399913e+09 2014-05-12 16:45:45.434971+00:00  \n",
       "98 -0.057347    J25C     P  1.399921e+09 2014-05-12 18:50:56.744503+00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all the pick assignments \n",
    "year = 'or_shore'\n",
    "mycatalog_picks = pd.read_csv(f'../data/datasets_{year}/all_pick_assignments_{year}.csv')\n",
    "mycatalog = mycatalog_picks.drop_duplicates(subset=['idx'])\n",
    "# Convert the time series in all_pick_assignments to datetime\n",
    "mycatalog['datetime'] = pd.to_datetime(mycatalog['time'], utc = True)\n",
    "mycatalog=mycatalog.loc[(mycatalog['datetime'] > t1) & (mycatalog['datetime'] < t2) ]\n",
    "mycatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d4e9ca",
   "metadata": {},
   "source": [
    "## Run this loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0e7740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched idx of Morton:  240\n",
      "matched idx of Morton:  493\n",
      "matched idx of Morton:  736\n",
      "17 11\n",
      "length of mycatalog:17\n",
      "length of events_morton:5282\n",
      "length of events_anss:131532\n",
      "matched_indices_morton:3\n",
      "matched_indices_anss:6\n",
      "unmatched_indices_morton:14\n",
      "unmatched_indices_anss:11\n",
      "unmatched_indices_morton_and_anss (new events):11\n"
     ]
    }
   ],
   "source": [
    "matched_events_mycatalog2morton = []\n",
    "matched_times_morton2mycatalog = []\n",
    "matched_events_morton2mycatalog = []\n",
    "unmatched_times_morton2mycatalog = []\n",
    "unmatched_events_morton2mycatalog = []\n",
    "unmatched_events_mycatalog2morton_and_anss = []\n",
    "matched_events_anss2mycatalog=[]\n",
    "matched_events_mycatalog2anss = []\n",
    "unmatched_times_anss2mycatalog = []\n",
    "unmatched_events_anss2mycatalog = []\n",
    "matched_times_anss2mycatalog =[]\n",
    "\n",
    "time_threshold = 5 # in seconds\n",
    "dist_threshold =25\n",
    "\n",
    "lat_morton2mycatalog = []\n",
    "lon_morton2mycatalog = []\n",
    "\n",
    "lat_anss2mycatalog =[]\n",
    "lon_anss2mycatalog = []\n",
    "\n",
    "# A set to keep track of matched indices in mycatalog\n",
    "matched_indices_morton = set()\n",
    "matched_indices_anss = set()\n",
    "count_c = 0\n",
    "count_d = 0\n",
    "# Loop over events in Morton's catalog\n",
    "for i in range(len(events_morton)):\n",
    "    t11 = events_morton.iloc[i]['datetime']\n",
    "    olat = events_morton.iloc[i]['LAT']\n",
    "    olon = events_morton.iloc[i]['LON']\n",
    "    \n",
    "                                       \n",
    "    condition = (mycatalog['datetime'] >= t11 - pd.Timedelta(seconds=time_threshold)) & \\\n",
    "                     (mycatalog['datetime'] <= t11 + pd.Timedelta(seconds=time_threshold)) & \\\n",
    "                     (degrees2kilometers(locations2degrees(olat, olon, mycatalog['latitude'], mycatalog['longitude'])) <= dist_threshold)                        \n",
    "    matched_df = mycatalog.loc[condition]\n",
    "\n",
    "    if len(matched_df) == 1:\n",
    "        print('matched idx of Morton: ',i)\n",
    "        count_c+=1\n",
    "        matched_times_morton2mycatalog.append(t11)\n",
    "        matched_events_morton2mycatalog.append(events_morton.iloc[i])\n",
    "        lat_morton2mycatalog.append(events_morton.iloc[i]['LAT'])\n",
    "        lon_morton2mycatalog.append(events_morton.iloc[i]['LON'])\n",
    "        matched_events_mycatalog2morton.append(matched_df)\n",
    "        matched_indices_morton.update(matched_df['idx'])\n",
    "    elif len(matched_df) > 1:\n",
    "        print('matched idx of Morton: ',i)\n",
    "\n",
    "        count_d+=1\n",
    "        diffs = abs(matched_df['datetime'] - t11)\n",
    "        closest_index = diffs.idxmin()\n",
    "        closest_event = matched_df.loc[[closest_index]]\n",
    "        matched_times_morton2mycatalog.append(t11)\n",
    "        matched_events_morton2mycatalog.append(events_morton.iloc[i])\n",
    "        lat_morton2mycatalog.append(events_morton.iloc[i]['LAT'])\n",
    "        lon_morton2mycatalog.append(events_morton.iloc[i]['LON'])\n",
    "        matched_events_mycatalog2morton.append(closest_event)\n",
    "        matched_indices_morton.update(closest_event['idx'])\n",
    "    else:\n",
    "        unmatched_times_morton2mycatalog.append(t11)\n",
    "        unmatched_events_morton2mycatalog.append(events_morton.iloc[i])\n",
    "\n",
    "# All events in mycatalog not matched with Morton's catalog are unmatched\n",
    "unmatched_indices_morton = set(mycatalog.idx) - matched_indices_morton\n",
    "# unmatched_events_mycatalog2morton = mycatalog.iloc[list(unmatched_indices_morton)]\n",
    "count_a =0\n",
    "count_b =0\n",
    "# Loop over events in ANSS catalog\n",
    "for i in range(len(events_anss)):\n",
    "    t11 = events_anss.iloc[i]['datetime']\n",
    "    olat = events_anss.iloc[i]['latitude']\n",
    "    olon = events_anss.iloc[i]['longitude']\n",
    "    \n",
    "                                       \n",
    "    condition = (mycatalog['datetime'] >= t11 - pd.Timedelta(seconds=time_threshold)) & \\\n",
    "                     (mycatalog['datetime'] <= t11 + pd.Timedelta(seconds=time_threshold)) & \\\n",
    "                     (degrees2kilometers(locations2degrees(olat, olon, mycatalog['latitude'], mycatalog['longitude'])) <= dist_threshold)                        \n",
    "    matched_df = mycatalog.loc[condition]\n",
    "    \n",
    "    if len(matched_df) == 1:\n",
    "        \n",
    "        count_a+=1\n",
    "        matched_times_anss2mycatalog.append(t11)\n",
    "        matched_events_anss2mycatalog.append(events_anss.iloc[i])\n",
    "        lat_anss2mycatalog.append(events_anss.iloc[i]['latitude'])\n",
    "        lon_anss2mycatalog.append(events_anss.iloc[i]['longitude'])\n",
    "        matched_events_mycatalog2anss.append(matched_df)\n",
    "        matched_indices_anss.update(matched_df['idx'])\n",
    "        \n",
    "    elif len(matched_df) > 1:\n",
    "        count_b+=1\n",
    "        diffs = abs(matched_df['datetime'] - t11)\n",
    "        closest_index = diffs.idxmin()\n",
    "        closest_event = matched_df.loc[[closest_index]]\n",
    "        matched_times_anss2mycatalog.append(t11)\n",
    "        matched_events_anss2mycatalog.append(events_anss.iloc[i])\n",
    "        lat_anss2mycatalog.append(events_anss.iloc[i]['latitude'])\n",
    "        lon_anss2mycatalog.append(events_anss.iloc[i]['longitude'])\n",
    "        matched_events_mycatalog2anss.append(closest_event)\n",
    "        matched_indices_anss.update(closest_event['idx'])\n",
    "        \n",
    "    else:\n",
    "        unmatched_times_anss2mycatalog.append(t11)\n",
    "        unmatched_events_anss2mycatalog.append(events_anss.iloc[i])\n",
    "\n",
    "# All events in mycatalog not matched with ANSS catalog are unmatched\n",
    "unmatched_indices_anss = set(mycatalog.idx) - matched_indices_anss\n",
    "\n",
    "unmatched_indices_morton_and_anss = unmatched_indices_morton.intersection(unmatched_indices_anss)\n",
    "print(len(mycatalog),len(unmatched_indices_morton_and_anss))\n",
    "\n",
    "# unmatched_events_mycatalog2morton_and_anss = mycatalog.iloc[list(unmatched_indices_morton_and_anss)]\n",
    "unmatched_events_mycatalog2morton_and_anss = mycatalog.loc[mycatalog['event_idx'].isin(list(unmatched_indices_morton_and_anss))]\n",
    "\n",
    "\n",
    "print(f\"length of mycatalog:{len(mycatalog)}\")\n",
    "print(f\"length of events_morton:{len(events_morton)}\")\n",
    "print(f\"length of events_anss:{len(events_anss)}\")\n",
    "print(f\"matched_indices_morton:{len(matched_indices_morton)}\")\n",
    "print(f\"matched_indices_anss:{len(matched_indices_anss)}\")\n",
    "print(f\"unmatched_indices_morton:{len(unmatched_indices_morton)}\")\n",
    "print(f\"unmatched_indices_anss:{len(unmatched_indices_anss)}\")\n",
    "print(f\"unmatched_indices_morton_and_anss (new events):{len(unmatched_indices_morton_and_anss)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6dd0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of mycatalog:17\n",
      "length of events_morton:5282\n",
      "length of events_anss:131532\n",
      "matched_events_mycatalog2morton:3\n",
      "matched_events_morton2mycatalog:3\n",
      "unmatched_events_anss2mycatalog:131526\n",
      "unmatched_events_morton2mycatalog:5279\n",
      "unmatched_events_mycatalog2morton_and_anss (new events):11\n",
      "matched_events_mycatalog2anss:6\n",
      "matched_events_anss2mycatalog:6\n"
     ]
    }
   ],
   "source": [
    "# new concat code\n",
    "# Concatenate and clean up dataframes\n",
    "if len(matched_events_mycatalog2morton)>0:\n",
    "    matched_events_mycatalog2morton = pd.concat(matched_events_mycatalog2morton).reset_index(drop=True)\n",
    "    matched_times_mycatalog2morton = matched_events_mycatalog2morton['datetime']\n",
    "    lat_mycatalog2morton = matched_events_mycatalog2morton['latitude']\n",
    "    lon_mycatalog2morton = matched_events_mycatalog2morton['longitude']\n",
    "\n",
    "if len(matched_events_morton2mycatalog)>0:   \n",
    "    matched_events_morton2mycatalog = pd.DataFrame(matched_events_morton2mycatalog).reset_index(drop=True)\n",
    "    \n",
    "if len(unmatched_events_anss2mycatalog)>0:\n",
    "    unmatched_events_anss2mycatalog = pd.DataFrame(unmatched_events_anss2mycatalog).reset_index(drop=True)\n",
    "    \n",
    "if len(unmatched_events_morton2mycatalog)>0:\n",
    "    unmatched_events_morton2mycatalog = pd.DataFrame(unmatched_events_morton2mycatalog).reset_index(drop=True)\n",
    "\n",
    "if len(unmatched_events_mycatalog2morton_and_anss) > 0:\n",
    "    unmatched_events_mycatalog2morton_and_anss = unmatched_events_mycatalog2morton_and_anss.reset_index(drop=True)\n",
    "\n",
    "if len(matched_events_mycatalog2anss)>0:\n",
    "    matched_events_mycatalog2anss = pd.concat(matched_events_mycatalog2anss).reset_index(drop=True)\n",
    "    matched_times_mycatalog2anss = matched_events_mycatalog2anss['datetime']\n",
    "    lat_mycatalog2anss = matched_events_mycatalog2anss['latitude']\n",
    "    lon_mycatalog2anss = matched_events_mycatalog2anss['longitude']\n",
    "\n",
    "if len(matched_events_anss2mycatalog)>0:   \n",
    "    matched_events_anss2mycatalog = pd.DataFrame(matched_events_anss2mycatalog).reset_index(drop=True)\n",
    "    matched_times_anss2mycatalog = matched_events_anss2mycatalog['datetime']\n",
    "\n",
    "print(f\"length of mycatalog:{len(mycatalog)}\")\n",
    "print(f\"length of events_morton:{len(events_morton)}\")\n",
    "print(f\"length of events_anss:{len(events_anss)}\")\n",
    "print(f\"matched_events_mycatalog2morton:{len(matched_events_mycatalog2morton)}\")\n",
    "print(f\"matched_events_morton2mycatalog:{len(matched_events_morton2mycatalog)}\")\n",
    "print(f\"unmatched_events_anss2mycatalog:{len(unmatched_events_anss2mycatalog)}\")\n",
    "print(f\"unmatched_events_morton2mycatalog:{len(unmatched_events_morton2mycatalog)}\")\n",
    "print(f\"unmatched_events_mycatalog2morton_and_anss (new events):{len(unmatched_events_mycatalog2morton_and_anss)}\")\n",
    "print(f\"matched_events_mycatalog2anss:{len(matched_events_mycatalog2anss)}\")\n",
    "print(f\"matched_events_anss2mycatalog:{len(matched_events_anss2mycatalog)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da443d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save these three catalogs to csv files\n",
    "matched_events_mycatalog2morton.to_csv(f'../data/datasets_{year}/matched_events_with_morton_mycatalog.csv')\n",
    "matched_events_anss2mycatalog.to_csv(f'../data/datasets_{year}/matched_events_with_mycatalog_anss.csv')\n",
    "matched_events_morton2mycatalog.to_csv(f'../data/datasets_{year}/matched_events_with_mycatalog_morton.csv')\n",
    "unmatched_events_mycatalog2morton_and_anss.to_csv(f'../data/datasets_{year}/new_events.csv')\n",
    "matched_events_mycatalog2anss.to_csv(f'../data/datasets_{year}/matched_events_with_anss_mycatalog.csv')\n",
    "unmatched_events_morton2mycatalog.to_csv(f'../data/datasets_{year}/missing_events_from_mycatalog_morton.csv')\n",
    "unmatched_events_anss2mycatalog.to_csv(f'../data/datasets_{year}/missing_events_from_mycatalog_anss.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b308175",
   "metadata": {},
   "source": [
    "## Plot the Origin Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b722c",
   "metadata": {},
   "source": [
    "### Compare with Morton's Catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lists for plotting the 1:1 line\n",
    "x = pd.date_range(start='2011-1-1', end='2015-12-31', periods=len(matched_times_morton2mycatalog))\n",
    "y = pd.date_range(start='2011-1-1', end='2015-12-31', periods=len(matched_times_morton2mycatalog))\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.figure()\n",
    "plt.scatter(matched_times_mycatalog2morton,matched_times_morton2mycatalog)\n",
    "plt.plot(x,y, 'k--')\n",
    "plt.xlabel('Origin Time of mycatalog')\n",
    "plt.ylabel('Origin Time of Morton')\n",
    "plt.title('Scatter Plot: Origin Times of Matched Events')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a2d257",
   "metadata": {},
   "source": [
    "### Compare with the ANSS Catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ebca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lists for plotting the 1:1 line\n",
    "matched_times_mycatalog2anss = pd.to_datetime(matched_times_mycatalog2anss)\n",
    "matched_times_anss2mycatalog = pd.to_datetime(matched_times_anss2mycatalog)\n",
    "\n",
    "x = pd.date_range(start='2014-1-1', end='2014-12-31', periods=len(matched_times_anss2mycatalog))\n",
    "y = pd.date_range(start='2014-1-1', end='2014-12-31', periods=len(matched_times_anss2mycatalog))\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.figure()\n",
    "plt.scatter(matched_times_mycatalog2anss,matched_times_anss2mycatalog)\n",
    "plt.plot(x,y, 'k--')\n",
    "plt.xlabel('Origin Time of mycatalog')\n",
    "plt.ylabel('Origin Time of Morton')\n",
    "plt.title('Scatter Plot: Origin Times of Matched Events')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43d9d5",
   "metadata": {},
   "source": [
    "## Plot the Latitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed02e61",
   "metadata": {},
   "source": [
    "### Compare with Morton's Catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77491ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter plot\n",
    "plt.figure()\n",
    "lat_min = min(lat_mycatalog2morton)\n",
    "lat_max = max(lat_mycatalog2morton)\n",
    "\n",
    "# Make lists for plotting the 1:1 line\n",
    "x_lat = np.linspace(lat_min, lat_max, 10)\n",
    "y_lat = np.linspace(lat_min, lat_max, 10)\n",
    "plt.scatter(lat_mycatalog2morton,lat_morton2mycatalog, s=15)\n",
    "plt.plot(x_lat,y_lat, 'k--')\n",
    "plt.xlabel('Latitudes of Our Catalog ($^\\circ$)')\n",
    "plt.ylabel('Latitudes of Morton et al. (2023) ($^\\circ$)')\n",
    "plt.title('Latitudes of Our Catalog vs.Latitudes of Morton et al. (2023)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9ef27",
   "metadata": {},
   "source": [
    "### Compare with the ANSS Catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter plot\n",
    "plt.figure()\n",
    "lat_min = min(lat_mycatalog2anss)\n",
    "lat_max = max(lat_mycatalog2anss)\n",
    "\n",
    "# Make lists for plotting the 1:1 line\n",
    "x_lat = np.linspace(lat_min, lat_max, 10)\n",
    "y_lat = np.linspace(lat_min, lat_max, 10)\n",
    "plt.scatter(lat_mycatalog2anss,lat_anss2mycatalog, s=15)\n",
    "plt.plot(x_lat,y_lat, 'k--')\n",
    "plt.xlabel('Latitudes of Our Catalog ($^\\circ$)')\n",
    "plt.ylabel('Latitudes of ANSS Catalog ($^\\circ$)')\n",
    "plt.title('Latitudes of Our Catalog vs. ANSS Catalog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc628b1a",
   "metadata": {},
   "source": [
    "## Plot the Longitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb31b59",
   "metadata": {},
   "source": [
    "### Compare with Morton's Catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3873dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter plot\n",
    "plt.figure()\n",
    "lon_min = min(lon_mycatalog2morton)\n",
    "lon_max = max(lon_mycatalog2morton)\n",
    "\n",
    "# Make lists for plotting the 1:1 line\n",
    "x_lon = np.linspace(lon_min, lon_max, 10)\n",
    "y_lon = np.linspace(lon_min, lon_max, 10)\n",
    "plt.scatter(lon_mycatalog2morton,lon_morton2mycatalog)\n",
    "plt.plot(x_lon,y_lon, 'k--')\n",
    "plt.xlabel('Longitudes of Our Catalog ($^\\circ$)')\n",
    "plt.ylabel('Longitudes of Morton et al. (2023) ($^\\circ$)')\n",
    "plt.title('Longitudes of Our Catalog vs.Latitudes of Morton et al. (2023)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd4045",
   "metadata": {},
   "source": [
    "### Compare with the ANSS Catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31380f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter plot\n",
    "plt.figure()\n",
    "lon_min = min(lon_mycatalog2anss)\n",
    "lon_max = max(lon_mycatalog2anss)\n",
    "\n",
    "# Make lists for plotting the 1:1 line\n",
    "x_lon = np.linspace(lon_min, lon_max, 10)\n",
    "y_lon = np.linspace(lon_min, lon_max, 10)\n",
    "plt.scatter(lon_mycatalog2anss,lon_anss2mycatalog)\n",
    "plt.plot(x_lon,y_lon, 'k--')\n",
    "plt.xlabel('Longitudes of Our Catalog ($^\\circ$)')\n",
    "plt.ylabel('Longitudes of Morton et al. (2023) ($^\\circ$)')\n",
    "plt.title('Longitudes of Our Catalog vs.Latitudes of Morton et al. (2023)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c25f0",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "Make histograms of mycatalog vs. Morton's catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814dcb8",
   "metadata": {},
   "source": [
    "### Histogram: All of our catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8dd51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv('../../data/datasets_all_years/events_pnsn_wa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the same histogram but overlay the histograms\n",
    "bins = np.linspace(5,30,25)\n",
    "\n",
    "plt.hist(unmatched_events_mycatalog2morton_and_anss['picks'], bins=bins,  \n",
    "         alpha=0.5, # the transaparency parameter \n",
    "         label='Newly detected events') \n",
    "plt.hist(matched_events_mycatalog2anss['picks'], bins=bins,\n",
    "         alpha=0.5, \n",
    "         label='Events matching the ANSS Catalog')   \n",
    "plt.hist(matched_events_mycatalog2morton['picks'], bins=bins,\n",
    "         alpha=0.5, \n",
    "         label='Events matching Morton et al., 2023') \n",
    "\n",
    "plt.xlabel('Number of Picks')\n",
    "plt.ylabel('Number of Events')  \n",
    "plt.legend(loc='upper right') \n",
    "plt.title('Picks vs. Number of Events') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0039ec69",
   "metadata": {},
   "source": [
    "### Histogram: Matched events alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db128b09",
   "metadata": {},
   "source": [
    "### Compare with Morton et al. (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e453e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the number of picks for the matched events\n",
    "plt.figure()\n",
    "bins = np.linspace(5,30,25)\n",
    "plt.hist(matched_events_mycatalog2morton['picks'],bins=bins)\n",
    "plt.xlabel('Number of Picks')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.title('Histogram of Matched Events with Morton et al. (2023): Picks vs. the Number of Events')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84052dd5",
   "metadata": {},
   "source": [
    "### Compare with ANSS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ed5380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the number of picks for the matched events\n",
    "plt.figure()\n",
    "bins = np.linspace(5,30,25)\n",
    "plt.hist(matched_events_mycatalog2anss['picks'],bins=bins)\n",
    "plt.xlabel('Number of Picks')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.title('Histogram of Matched Events with ANSS: Picks vs. the Number of Events')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b3b7f",
   "metadata": {},
   "source": [
    "## 2. Filter events \n",
    "Filter Events based on the following criteria\n",
    "1. For an event, at least two stations have to be less than 50 km from the event and no station can be 100 km apart from each other.\n",
    "2. An event has to have more than or equal to 6 picks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcc97847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>idx</th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>picks</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>event_idx</th>\n",
       "      <th>pick_idx</th>\n",
       "      <th>residual</th>\n",
       "      <th>station</th>\n",
       "      <th>phase</th>\n",
       "      <th>time_pick</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-12-08 18:34:06.040983+00:00</td>\n",
       "      <td>-99.849958</td>\n",
       "      <td>-173.323761</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>6</td>\n",
       "      <td>42.933490</td>\n",
       "      <td>-126.723212</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>2</td>\n",
       "      <td>717826</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.323369e+09</td>\n",
       "      <td>2011-12-08 18:34:06.040983+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-12-20 00:00:16.064003+00:00</td>\n",
       "      <td>-0.557821</td>\n",
       "      <td>9.767689</td>\n",
       "      <td>25.390625</td>\n",
       "      <td>6</td>\n",
       "      <td>44.587900</td>\n",
       "      <td>-125.507025</td>\n",
       "      <td>25.390625</td>\n",
       "      <td>3</td>\n",
       "      <td>704159</td>\n",
       "      <td>1.143362</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.324339e+09</td>\n",
       "      <td>2011-12-20 00:00:16.064003+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-02-03 03:03:40.803628+00:00</td>\n",
       "      <td>-126.625365</td>\n",
       "      <td>-153.298134</td>\n",
       "      <td>12.890625</td>\n",
       "      <td>6</td>\n",
       "      <td>43.109709</td>\n",
       "      <td>-127.055663</td>\n",
       "      <td>12.890625</td>\n",
       "      <td>4</td>\n",
       "      <td>190297</td>\n",
       "      <td>-0.196536</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.328238e+09</td>\n",
       "      <td>2012-02-03 03:03:40.803628+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-02-15 03:31:16.120587+00:00</td>\n",
       "      <td>-179.060539</td>\n",
       "      <td>-143.285320</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>7</td>\n",
       "      <td>43.189203</td>\n",
       "      <td>-127.702694</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>6</td>\n",
       "      <td>208779</td>\n",
       "      <td>0.308213</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.329277e+09</td>\n",
       "      <td>2012-02-15 03:31:16.120587+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-05-10 10:58:55.563721+00:00</td>\n",
       "      <td>-166.788477</td>\n",
       "      <td>-154.728536</td>\n",
       "      <td>44.140625</td>\n",
       "      <td>7</td>\n",
       "      <td>43.089072</td>\n",
       "      <td>-127.548388</td>\n",
       "      <td>44.140625</td>\n",
       "      <td>10</td>\n",
       "      <td>44040</td>\n",
       "      <td>-0.330297</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.336648e+09</td>\n",
       "      <td>2012-05-10 10:58:55.563721+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>2012-07-10 13:58:25.328216+00:00</td>\n",
       "      <td>-30.680155</td>\n",
       "      <td>-94.651654</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>6</td>\n",
       "      <td>43.647522</td>\n",
       "      <td>-125.880272</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>13</td>\n",
       "      <td>96284</td>\n",
       "      <td>-0.208655</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.341929e+09</td>\n",
       "      <td>2012-07-10 13:58:25.328216+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>2012-07-18 00:20:00.702900+00:00</td>\n",
       "      <td>201.373378</td>\n",
       "      <td>-210.514212</td>\n",
       "      <td>11.328125</td>\n",
       "      <td>6</td>\n",
       "      <td>42.578980</td>\n",
       "      <td>-123.047148</td>\n",
       "      <td>11.328125</td>\n",
       "      <td>14</td>\n",
       "      <td>23216</td>\n",
       "      <td>-0.073185</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.342571e+09</td>\n",
       "      <td>2012-07-18 00:20:00.702900+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>15</td>\n",
       "      <td>2012-08-29 07:54:52.443774+00:00</td>\n",
       "      <td>22.870661</td>\n",
       "      <td>14.058895</td>\n",
       "      <td>32.421875</td>\n",
       "      <td>6</td>\n",
       "      <td>44.626153</td>\n",
       "      <td>-125.211804</td>\n",
       "      <td>32.421875</td>\n",
       "      <td>15</td>\n",
       "      <td>178762</td>\n",
       "      <td>0.127071</td>\n",
       "      <td>J25B</td>\n",
       "      <td>P</td>\n",
       "      <td>1.346227e+09</td>\n",
       "      <td>2012-08-29 07:54:52.443774+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>25</td>\n",
       "      <td>2014-01-15 08:31:57.792461+00:00</td>\n",
       "      <td>-127.741007</td>\n",
       "      <td>-177.614967</td>\n",
       "      <td>26.953125</td>\n",
       "      <td>6</td>\n",
       "      <td>42.890716</td>\n",
       "      <td>-127.063804</td>\n",
       "      <td>26.953125</td>\n",
       "      <td>25</td>\n",
       "      <td>276927</td>\n",
       "      <td>0.137358</td>\n",
       "      <td>J25C</td>\n",
       "      <td>P</td>\n",
       "      <td>1.389775e+09</td>\n",
       "      <td>2014-01-15 08:31:57.792461+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>92</td>\n",
       "      <td>28</td>\n",
       "      <td>2014-05-12 16:45:45.434971+00:00</td>\n",
       "      <td>-232.611354</td>\n",
       "      <td>-103.234065</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>6</td>\n",
       "      <td>43.534678</td>\n",
       "      <td>-128.377708</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>28</td>\n",
       "      <td>398532</td>\n",
       "      <td>-0.269836</td>\n",
       "      <td>J25C</td>\n",
       "      <td>P</td>\n",
       "      <td>1.399913e+09</td>\n",
       "      <td>2014-05-12 16:45:45.434971+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "      <td>29</td>\n",
       "      <td>2014-05-12 18:50:56.744503+00:00</td>\n",
       "      <td>-228.148786</td>\n",
       "      <td>-106.094869</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>6</td>\n",
       "      <td>43.510336</td>\n",
       "      <td>-128.321367</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>29</td>\n",
       "      <td>398538</td>\n",
       "      <td>-0.057347</td>\n",
       "      <td>J25C</td>\n",
       "      <td>P</td>\n",
       "      <td>1.399921e+09</td>\n",
       "      <td>2014-05-12 18:50:56.744503+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.1  Unnamed: 0  idx                              time  \\\n",
       "0              0           6    2  2011-12-08 18:34:06.040983+00:00   \n",
       "1              1          12    3  2011-12-20 00:00:16.064003+00:00   \n",
       "2              2          18    4  2012-02-03 03:03:40.803628+00:00   \n",
       "3              3          24    6  2012-02-15 03:31:16.120587+00:00   \n",
       "4              4          37   10  2012-05-10 10:58:55.563721+00:00   \n",
       "5              5          44   13  2012-07-10 13:58:25.328216+00:00   \n",
       "6              6          50   14  2012-07-18 00:20:00.702900+00:00   \n",
       "7              7          56   15  2012-08-29 07:54:52.443774+00:00   \n",
       "8              8          80   25  2014-01-15 08:31:57.792461+00:00   \n",
       "9              9          92   28  2014-05-12 16:45:45.434971+00:00   \n",
       "10            10          98   29  2014-05-12 18:50:56.744503+00:00   \n",
       "\n",
       "             x           y          z  picks   latitude   longitude  \\\n",
       "0   -99.849958 -173.323761   1.171875      6  42.933490 -126.723212   \n",
       "1    -0.557821    9.767689  25.390625      6  44.587900 -125.507025   \n",
       "2  -126.625365 -153.298134  12.890625      6  43.109709 -127.055663   \n",
       "3  -179.060539 -143.285320   2.734375      7  43.189203 -127.702694   \n",
       "4  -166.788477 -154.728536  44.140625      7  43.089072 -127.548388   \n",
       "5   -30.680155  -94.651654   2.734375      6  43.647522 -125.880272   \n",
       "6   201.373378 -210.514212  11.328125      6  42.578980 -123.047148   \n",
       "7    22.870661   14.058895  32.421875      6  44.626153 -125.211804   \n",
       "8  -127.741007 -177.614967  26.953125      6  42.890716 -127.063804   \n",
       "9  -232.611354 -103.234065   2.734375      6  43.534678 -128.377708   \n",
       "10 -228.148786 -106.094869   0.390625      6  43.510336 -128.321367   \n",
       "\n",
       "        depth  event_idx  pick_idx  residual station phase     time_pick  \\\n",
       "0    1.171875          2    717826  0.747435    J25A     P  1.323369e+09   \n",
       "1   25.390625          3    704159  1.143362    J25A     P  1.324339e+09   \n",
       "2   12.890625          4    190297 -0.196536    J25A     P  1.328238e+09   \n",
       "3    2.734375          6    208779  0.308213    J25A     P  1.329277e+09   \n",
       "4   44.140625         10     44040 -0.330297    J25A     P  1.336648e+09   \n",
       "5    2.734375         13     96284 -0.208655    J25A     P  1.341929e+09   \n",
       "6   11.328125         14     23216 -0.073185    J25A     P  1.342571e+09   \n",
       "7   32.421875         15    178762  0.127071    J25B     P  1.346227e+09   \n",
       "8   26.953125         25    276927  0.137358    J25C     P  1.389775e+09   \n",
       "9    2.734375         28    398532 -0.269836    J25C     P  1.399913e+09   \n",
       "10   0.390625         29    398538 -0.057347    J25C     P  1.399921e+09   \n",
       "\n",
       "                            datetime  \n",
       "0   2011-12-08 18:34:06.040983+00:00  \n",
       "1   2011-12-20 00:00:16.064003+00:00  \n",
       "2   2012-02-03 03:03:40.803628+00:00  \n",
       "3   2012-02-15 03:31:16.120587+00:00  \n",
       "4   2012-05-10 10:58:55.563721+00:00  \n",
       "5   2012-07-10 13:58:25.328216+00:00  \n",
       "6   2012-07-18 00:20:00.702900+00:00  \n",
       "7   2012-08-29 07:54:52.443774+00:00  \n",
       "8   2014-01-15 08:31:57.792461+00:00  \n",
       "9   2014-05-12 16:45:45.434971+00:00  \n",
       "10  2014-05-12 18:50:56.744503+00:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the new events file\n",
    "events = pd.read_csv(f'../data/datasets_{year}/new_events.csv')\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b49b018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>idx</th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>picks</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>event_idx</th>\n",
       "      <th>pick_idx</th>\n",
       "      <th>residual</th>\n",
       "      <th>station</th>\n",
       "      <th>phase</th>\n",
       "      <th>time_pick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-11-09 17:24:51.454200+00:00</td>\n",
       "      <td>-108.775094</td>\n",
       "      <td>-173.323761</td>\n",
       "      <td>6.640625</td>\n",
       "      <td>6</td>\n",
       "      <td>42.932269</td>\n",
       "      <td>-126.832522</td>\n",
       "      <td>6.640625</td>\n",
       "      <td>1</td>\n",
       "      <td>742471</td>\n",
       "      <td>0.186548</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.320860e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-12-08 18:34:06.040983+00:00</td>\n",
       "      <td>-99.849958</td>\n",
       "      <td>-173.323761</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>6</td>\n",
       "      <td>42.933490</td>\n",
       "      <td>-126.723212</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>2</td>\n",
       "      <td>717826</td>\n",
       "      <td>0.747435</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.323369e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-12-20 00:00:16.064003+00:00</td>\n",
       "      <td>-0.557821</td>\n",
       "      <td>9.767689</td>\n",
       "      <td>25.390625</td>\n",
       "      <td>6</td>\n",
       "      <td>44.587900</td>\n",
       "      <td>-125.507025</td>\n",
       "      <td>25.390625</td>\n",
       "      <td>3</td>\n",
       "      <td>704159</td>\n",
       "      <td>1.143362</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.324339e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-02-03 03:03:40.803628+00:00</td>\n",
       "      <td>-126.625365</td>\n",
       "      <td>-153.298134</td>\n",
       "      <td>12.890625</td>\n",
       "      <td>6</td>\n",
       "      <td>43.109709</td>\n",
       "      <td>-127.055663</td>\n",
       "      <td>12.890625</td>\n",
       "      <td>4</td>\n",
       "      <td>190297</td>\n",
       "      <td>-0.196536</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.328238e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-02-15 03:31:16.120587+00:00</td>\n",
       "      <td>-179.060539</td>\n",
       "      <td>-143.285320</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>7</td>\n",
       "      <td>43.189203</td>\n",
       "      <td>-127.702694</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>6</td>\n",
       "      <td>208779</td>\n",
       "      <td>0.308213</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.329277e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>2012-04-18 15:20:59.528926+00:00</td>\n",
       "      <td>99.849958</td>\n",
       "      <td>14.058895</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>6</td>\n",
       "      <td>44.619587</td>\n",
       "      <td>-124.241920</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>9</td>\n",
       "      <td>238399</td>\n",
       "      <td>-0.514313</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.334762e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>2012-05-10 10:58:55.563721+00:00</td>\n",
       "      <td>-166.788477</td>\n",
       "      <td>-154.728536</td>\n",
       "      <td>44.140625</td>\n",
       "      <td>7</td>\n",
       "      <td>43.089072</td>\n",
       "      <td>-127.548388</td>\n",
       "      <td>44.140625</td>\n",
       "      <td>10</td>\n",
       "      <td>44040</td>\n",
       "      <td>-0.330297</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.336648e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>2012-07-10 13:58:25.328216+00:00</td>\n",
       "      <td>-30.680155</td>\n",
       "      <td>-94.651654</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>6</td>\n",
       "      <td>43.647522</td>\n",
       "      <td>-125.880272</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>13</td>\n",
       "      <td>96284</td>\n",
       "      <td>-0.208655</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.341929e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>2012-07-18 00:20:00.702900+00:00</td>\n",
       "      <td>201.373378</td>\n",
       "      <td>-210.514212</td>\n",
       "      <td>11.328125</td>\n",
       "      <td>6</td>\n",
       "      <td>42.578980</td>\n",
       "      <td>-123.047148</td>\n",
       "      <td>11.328125</td>\n",
       "      <td>14</td>\n",
       "      <td>23216</td>\n",
       "      <td>-0.073185</td>\n",
       "      <td>J25A</td>\n",
       "      <td>P</td>\n",
       "      <td>1.342571e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>15</td>\n",
       "      <td>2012-08-29 07:54:52.443774+00:00</td>\n",
       "      <td>22.870661</td>\n",
       "      <td>14.058895</td>\n",
       "      <td>32.421875</td>\n",
       "      <td>6</td>\n",
       "      <td>44.626153</td>\n",
       "      <td>-125.211804</td>\n",
       "      <td>32.421875</td>\n",
       "      <td>15</td>\n",
       "      <td>178762</td>\n",
       "      <td>0.127071</td>\n",
       "      <td>J25B</td>\n",
       "      <td>P</td>\n",
       "      <td>1.346227e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>16</td>\n",
       "      <td>2012-08-29 08:05:26.522418+00:00</td>\n",
       "      <td>96.503032</td>\n",
       "      <td>19.780503</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>6</td>\n",
       "      <td>44.671520</td>\n",
       "      <td>-124.283004</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>16</td>\n",
       "      <td>178768</td>\n",
       "      <td>-0.570727</td>\n",
       "      <td>J25B</td>\n",
       "      <td>P</td>\n",
       "      <td>1.346228e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>19</td>\n",
       "      <td>2012-09-18 19:57:10.268089+00:00</td>\n",
       "      <td>-71.958908</td>\n",
       "      <td>-174.754163</td>\n",
       "      <td>3.515625</td>\n",
       "      <td>6</td>\n",
       "      <td>42.923756</td>\n",
       "      <td>-126.381396</td>\n",
       "      <td>3.515625</td>\n",
       "      <td>19</td>\n",
       "      <td>236283</td>\n",
       "      <td>-0.905047</td>\n",
       "      <td>J25B</td>\n",
       "      <td>P</td>\n",
       "      <td>1.347998e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>21</td>\n",
       "      <td>2012-11-03 23:54:43.276284+00:00</td>\n",
       "      <td>111.006378</td>\n",
       "      <td>65.553366</td>\n",
       "      <td>49.609375</td>\n",
       "      <td>6</td>\n",
       "      <td>45.081189</td>\n",
       "      <td>-124.090134</td>\n",
       "      <td>49.609375</td>\n",
       "      <td>21</td>\n",
       "      <td>97669</td>\n",
       "      <td>-0.145679</td>\n",
       "      <td>J25B</td>\n",
       "      <td>P</td>\n",
       "      <td>1.351987e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>25</td>\n",
       "      <td>2014-01-15 08:31:57.792461+00:00</td>\n",
       "      <td>-127.741007</td>\n",
       "      <td>-177.614967</td>\n",
       "      <td>26.953125</td>\n",
       "      <td>6</td>\n",
       "      <td>42.890716</td>\n",
       "      <td>-127.063804</td>\n",
       "      <td>26.953125</td>\n",
       "      <td>25</td>\n",
       "      <td>276927</td>\n",
       "      <td>0.137358</td>\n",
       "      <td>J25C</td>\n",
       "      <td>P</td>\n",
       "      <td>1.389775e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>27</td>\n",
       "      <td>2014-02-25 23:03:08.886563+00:00</td>\n",
       "      <td>-9.482957</td>\n",
       "      <td>-87.499644</td>\n",
       "      <td>12.890625</td>\n",
       "      <td>6</td>\n",
       "      <td>43.712465</td>\n",
       "      <td>-125.617665</td>\n",
       "      <td>12.890625</td>\n",
       "      <td>27</td>\n",
       "      <td>281071</td>\n",
       "      <td>-0.054492</td>\n",
       "      <td>J25C</td>\n",
       "      <td>P</td>\n",
       "      <td>1.393369e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>28</td>\n",
       "      <td>2014-05-12 16:45:45.434971+00:00</td>\n",
       "      <td>-232.611354</td>\n",
       "      <td>-103.234065</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>6</td>\n",
       "      <td>43.534678</td>\n",
       "      <td>-128.377708</td>\n",
       "      <td>2.734375</td>\n",
       "      <td>28</td>\n",
       "      <td>398532</td>\n",
       "      <td>-0.269836</td>\n",
       "      <td>J25C</td>\n",
       "      <td>P</td>\n",
       "      <td>1.399913e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>29</td>\n",
       "      <td>2014-05-12 18:50:56.744503+00:00</td>\n",
       "      <td>-228.148786</td>\n",
       "      <td>-106.094869</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>6</td>\n",
       "      <td>43.510336</td>\n",
       "      <td>-128.321367</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>29</td>\n",
       "      <td>398538</td>\n",
       "      <td>-0.057347</td>\n",
       "      <td>J25C</td>\n",
       "      <td>P</td>\n",
       "      <td>1.399921e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  idx                              time           x           y  \\\n",
       "0            0    1  2011-11-09 17:24:51.454200+00:00 -108.775094 -173.323761   \n",
       "6            6    2  2011-12-08 18:34:06.040983+00:00  -99.849958 -173.323761   \n",
       "12          12    3  2011-12-20 00:00:16.064003+00:00   -0.557821    9.767689   \n",
       "18          18    4  2012-02-03 03:03:40.803628+00:00 -126.625365 -153.298134   \n",
       "24          24    6  2012-02-15 03:31:16.120587+00:00 -179.060539 -143.285320   \n",
       "31          31    9  2012-04-18 15:20:59.528926+00:00   99.849958   14.058895   \n",
       "37          37   10  2012-05-10 10:58:55.563721+00:00 -166.788477 -154.728536   \n",
       "44          44   13  2012-07-10 13:58:25.328216+00:00  -30.680155  -94.651654   \n",
       "50          50   14  2012-07-18 00:20:00.702900+00:00  201.373378 -210.514212   \n",
       "56          56   15  2012-08-29 07:54:52.443774+00:00   22.870661   14.058895   \n",
       "62          62   16  2012-08-29 08:05:26.522418+00:00   96.503032   19.780503   \n",
       "68          68   19  2012-09-18 19:57:10.268089+00:00  -71.958908 -174.754163   \n",
       "74          74   21  2012-11-03 23:54:43.276284+00:00  111.006378   65.553366   \n",
       "80          80   25  2014-01-15 08:31:57.792461+00:00 -127.741007 -177.614967   \n",
       "86          86   27  2014-02-25 23:03:08.886563+00:00   -9.482957  -87.499644   \n",
       "92          92   28  2014-05-12 16:45:45.434971+00:00 -232.611354 -103.234065   \n",
       "98          98   29  2014-05-12 18:50:56.744503+00:00 -228.148786 -106.094869   \n",
       "\n",
       "            z  picks   latitude   longitude      depth  event_idx  pick_idx  \\\n",
       "0    6.640625      6  42.932269 -126.832522   6.640625          1    742471   \n",
       "6    1.171875      6  42.933490 -126.723212   1.171875          2    717826   \n",
       "12  25.390625      6  44.587900 -125.507025  25.390625          3    704159   \n",
       "18  12.890625      6  43.109709 -127.055663  12.890625          4    190297   \n",
       "24   2.734375      7  43.189203 -127.702694   2.734375          6    208779   \n",
       "31   1.171875      6  44.619587 -124.241920   1.171875          9    238399   \n",
       "37  44.140625      7  43.089072 -127.548388  44.140625         10     44040   \n",
       "44   2.734375      6  43.647522 -125.880272   2.734375         13     96284   \n",
       "50  11.328125      6  42.578980 -123.047148  11.328125         14     23216   \n",
       "56  32.421875      6  44.626153 -125.211804  32.421875         15    178762   \n",
       "62   1.953125      6  44.671520 -124.283004   1.953125         16    178768   \n",
       "68   3.515625      6  42.923756 -126.381396   3.515625         19    236283   \n",
       "74  49.609375      6  45.081189 -124.090134  49.609375         21     97669   \n",
       "80  26.953125      6  42.890716 -127.063804  26.953125         25    276927   \n",
       "86  12.890625      6  43.712465 -125.617665  12.890625         27    281071   \n",
       "92   2.734375      6  43.534678 -128.377708   2.734375         28    398532   \n",
       "98   0.390625      6  43.510336 -128.321367   0.390625         29    398538   \n",
       "\n",
       "    residual station phase     time_pick  \n",
       "0   0.186548    J25A     P  1.320860e+09  \n",
       "6   0.747435    J25A     P  1.323369e+09  \n",
       "12  1.143362    J25A     P  1.324339e+09  \n",
       "18 -0.196536    J25A     P  1.328238e+09  \n",
       "24  0.308213    J25A     P  1.329277e+09  \n",
       "31 -0.514313    J25A     P  1.334762e+09  \n",
       "37 -0.330297    J25A     P  1.336648e+09  \n",
       "44 -0.208655    J25A     P  1.341929e+09  \n",
       "50 -0.073185    J25A     P  1.342571e+09  \n",
       "56  0.127071    J25B     P  1.346227e+09  \n",
       "62 -0.570727    J25B     P  1.346228e+09  \n",
       "68 -0.905047    J25B     P  1.347998e+09  \n",
       "74 -0.145679    J25B     P  1.351987e+09  \n",
       "80  0.137358    J25C     P  1.389775e+09  \n",
       "86 -0.054492    J25C     P  1.393369e+09  \n",
       "92 -0.269836    J25C     P  1.399913e+09  \n",
       "98 -0.057347    J25C     P  1.399921e+09  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pick_assignments = pd.read_csv(f'../data/datasets_{year}/all_pick_assignments_{year}.csv')\n",
    "mycatalog = all_pick_assignments.drop_duplicates(subset=['idx'])\n",
    "mycatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0c23e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "650f1d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2254654/2718798803.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mycatalog['datetime'] = pd.to_datetime(mycatalog['time'], utc = True)\n",
      "  9%|▉         | 1/11 [00:01<00:10,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, '7D', 'J25A', 240.4863040612118], [None, '7D', 'J33A', 296.6393961150126], [None, '7D', 'J41A', 364.14862419020477]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 2/11 [00:02<00:09,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, '7D', 'J25A', 71.34147087129752], [None, '7D', 'J33A', 93.67004878976472], [None, 'UW', 'TAKO', 147.36783447986178], [None, '7D', 'J41A', 155.8752668498324]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 3/11 [00:03<00:08,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, '7D', 'J25A', 247.26326809396446], [None, 'UW', 'TAKO', 250.13485149466624], [None, '7D', 'J33A', 297.7341082672938], [None, '7D', 'J41A', 360.83168311921736]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 4/11 [00:04<00:06,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, '7D', 'J25A', 285.37766050412034], [None, 'UW', 'TAKO', 298.4877322412891], [None, '7D', 'J33A', 328.43437892653156], [None, '7D', 'J41A', 384.740108862721]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 5/11 [00:04<00:05,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, '7D', 'J25A', 280.8403376786241], [None, 'UW', 'TAKO', 289.1396834650697], [None, '7D', 'J33A', 326.8585275481028], [None, '7D', 'J41A', 385.67932491555877]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 6/11 [00:05<00:04,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, '7D', 'J25A', 136.1532120859405], [None, 'UW', 'TAKO', 144.8524617789304], [None, '7D', 'J33A', 192.74638264281137]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 7/11 [00:06<00:03,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, '7D', 'J25B', 245.73274853909322], [None, '7D', 'J25A', 245.88029047546718], [None, '7D', 'J33B', 306.450906585552], [None, '7D', 'J33A', 306.4572655832467]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 8/11 [00:07<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, '7D', 'J25B', 49.831560265756245], [None, '7D', 'J33B', 73.53628019057321], [None, 'UW', 'TAKO', 133.1773846058599]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 9/11 [00:07<00:01,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, '7D', 'J25C', 263.6459040939181], [None, '7D', 'J33C', 316.9616653619745], [None, '7D', 'J41C', 381.8418928888588]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 10/11 [00:07<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, '7D', 'J25C', 317.9787830752227], [None, '7D', 'J33C', 349.62814194555716], [None, '7D', 'J41C', 395.28063530248096]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:08<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, '7D', 'J25C', 314.69378094025006], [None, '7D', 'J33C', 347.1838590671208], [None, '7D', 'J41C', 393.6724327265124]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>idx</th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>picks</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>event_idx</th>\n",
       "      <th>pick_idx</th>\n",
       "      <th>residual</th>\n",
       "      <th>station</th>\n",
       "      <th>phase</th>\n",
       "      <th>time_pick</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0.1, Unnamed: 0, idx, time, x, y, z, picks, latitude, longitude, depth, event_idx, pick_idx, residual, station, phase, time_pick, datetime]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Inputs:\n",
    "1. Either of the following files can be the input:\n",
    "    1. matched_events_with_morton_mycatalog.csv from the 4_quality_control file\n",
    "    2. matched_events_with_anss_mycatalog.csv from the 4_quality_control file\n",
    "    3. new_events.csv from the 4_quality_control file\n",
    "2. The all_pick_assignments CSV file from the 3_associate file: e.g., all_pick_assignments = pd.read_csv('../data/datasets_2012/all_pick_assignments_2012.csv')\n",
    "\n",
    "\n",
    "Outputs:\n",
    "1. A new dataframe that only has events that fall into the following categories:\n",
    "    1. For an event, at least two stations have to be less than 50 km from the event and no station can be 100 km apart from each other.\n",
    "2. An event has to have more than or equal to 6 picks\n",
    "\"\"\"\n",
    "\n",
    "# Parameters\n",
    "client2 = Client(\"IRIS\")\n",
    "\n",
    "mycatalog = all_pick_assignments.drop_duplicates(subset=['idx'])\n",
    "mycatalog['datetime'] = pd.to_datetime(mycatalog['time'], utc = True)\n",
    "\n",
    "for i, idx in tqdm(enumerate(events['idx']),total=len(events['idx'])):\n",
    "    event = mycatalog\n",
    "    picks = all_pick_assignments\n",
    "    picks_idx = picks.loc[picks['idx']==idx]\n",
    "    pick_sta = np.unique(picks_idx['station'])\n",
    "    otime = UTCDateTime(str(event[event['idx'] == idx][\"datetime\"].values[0]))\n",
    "    distances = []\n",
    "    max_dist = 10\n",
    "    min_dist = 0\n",
    "    for station in pick_sta:\n",
    "\n",
    "\n",
    "        sta_inv = client2.get_stations(network='*',\n",
    "                                       station=station, channel=\"?H?\", \n",
    "                                       starttime=otime - 1e8, endtime=otime + 1e8,level=\"response\")\n",
    "        if len(sta_inv) == 0:\n",
    "            print(f\"Failed to fetch for {networks} {station} {otime}\")\n",
    "            continue\n",
    "\n",
    "        _network = sta_inv[0].code\n",
    "        slat = sta_inv[0][0].latitude\n",
    "        slon = sta_inv[0][0].longitude\n",
    "        olat = event.loc[event['idx']==idx, 'latitude'].values[0]\n",
    "        olon = event.loc[event['idx']==idx, 'longitude'].values[0]\n",
    "\n",
    "        dis1 = locations2degrees(olat, olon, slat, slon)\n",
    "        dist = degrees2kilometers(dis1)\n",
    "\n",
    "        distances.append([None, _network, station, dist])\n",
    "\n",
    "    # Sort distances\n",
    "    distances = sorted(distances, key=lambda item: item[-1])\n",
    "\n",
    "    # This is for the first criterion in the markdown above\n",
    "    # Determine if any two of the numbers in the distances list are less than or equal to 50\n",
    "    found = False\n",
    "    for i in range(len(distances)):\n",
    "        for j in range(i + 1, len(distances)):\n",
    "            if distances[i][3] <= 50 and distances[j][3] <= 50:\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            break\n",
    "\n",
    "    # Make a list that includes the differences between the consecutive numbers in the distances list.\n",
    "    differences = [distances[i+1][3] - distances[i][3] for i in range(len(distances) - 1)]\n",
    "\n",
    "    if found == False: # If there were not at least two distances between the station and the event less than or equal to 50 km\n",
    "        print(distances)\n",
    "        index = events[events['idx'] == idx].index\n",
    "        events = events.drop(index=index)\n",
    "\n",
    "    elif any(differences > 100 for differences in differences): # If any of the distances between two stations were greater than 100 km\n",
    "        print(distances)\n",
    "        index = events[events['idx'] == idx].index\n",
    "        events = events.drop(index=index)\n",
    "\n",
    "    else: \n",
    "        continue\n",
    "\n",
    "\n",
    "events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3444633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_events_filtered = filter_sta(new_events, mycatalog_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da81e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events_filtered.to_csv(f'../data/datasets_{year}/new_events_filtered_{year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f4637d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.to_csv(f'../data/datasets_{year}/new_events_filtered_{year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "575d60f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>idx</th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>picks</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>event_idx</th>\n",
       "      <th>pick_idx</th>\n",
       "      <th>residual</th>\n",
       "      <th>station</th>\n",
       "      <th>phase</th>\n",
       "      <th>time_pick</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0.1, Unnamed: 0, idx, time, x, y, z, picks, latitude, longitude, depth, event_idx, pick_idx, residual, station, phase, time_pick, datetime]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d11af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, idx in enumerate(range(0,10,1)):\n",
    "    print(i,idx,count)\n",
    "    count+=1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d60411",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aaac94",
   "metadata": {},
   "source": [
    "## Plot using the plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84953e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_picks = pd.read_csv('../data/datasets_2014/all_picks_2014_for_assoc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444b3861",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e15bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_picks_networks = all_picks['station_network_code'].drop_duplicates()\n",
    "list_networks = list(all_picks_networks)\n",
    "all_picks_networks = ','.join(all_picks_networks)\n",
    "all_picks_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a4493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the memory\n",
    "del all_picks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3946e",
   "metadata": {},
   "source": [
    "## Plot the offshore events north of 44&deg; N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events = pd.read_csv('../data/datasets_2014/new_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7496a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events_44N_and_above= new_events.loc[(new_events['latitude']>44)&(new_events['longitude']<-124)]\n",
    "new_events_44N_and_above = new_events_44N_and_above[0:50] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for subplots_cluster_scale\n",
    "mycatalog= mycatalog\n",
    "mycatalog_picks=mycatalog_picks\n",
    "networks= all_picks_networks\n",
    "channel= \"?H?\"\n",
    "idx_sta= 50\n",
    "title= \"Events matched\"\n",
    "fig_title= \"new_events_filtered_44N_and_above_plots.pdf\"\n",
    "\n",
    "subplots_cluster_scale(new_events_44N_and_above,mycatalog_picks,networks,channel,idx_sta,title,fig_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a80d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634dd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78356615",
   "metadata": {},
   "source": [
    "## Plot one of the cluster events at around 46.5&deg; N, 125&deg; W using the plotting functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplots_cluster_scale_p(idx, mycatalog, mycatalog_picks, networks, channel, idx_sta, title, fig_title):\n",
    "    \"\"\"\n",
    "    idx: event_idx\n",
    "    mycatalog: dataframe that contains only the unique picks (i.e., mycatalog_picks.drop_duplicates(subset=['idx']).copy())\n",
    "    mycatalog_picks: all pick assignments csv file (e.g., pd.read_csv('../data/datasets_OR/all_pick_assignments_OR.csv'))\n",
    "    networks: string of networks (e.g., \"NV,OO,7A\")\n",
    "    channel: specify the direction of the channel (i.e., \"?HZ\", \"?HE\" or \"?HN\")\n",
    "    idx_sta: choose the station to which you want to show the waveforms\n",
    "    title: title in a string\n",
    "    fig_title: figure title in as string\n",
    "    \"\"\"\n",
    "        \n",
    "    # Define the clients \n",
    "    client_waveform = WaveformClient()\n",
    "    client2 = Client(\"IRIS\")\n",
    "    client_ncedc = Client('NCEDC')\n",
    "\n",
    "\n",
    "    # Plot the earthquake moveout for one of the unmatched events for all stations \n",
    "    event = mycatalog\n",
    "    picks = mycatalog_picks\n",
    "    picks_idx = picks.loc[picks['idx']==idx]\n",
    "    pick_sta = np.unique(picks_idx['station'])\n",
    "    \n",
    "    otime = UTCDateTime(str(event[event['idx'] == idx][\"datetime\"].values[0]))\n",
    "    distances = []\n",
    "    max_dist = 10\n",
    "    min_dist = 0\n",
    "    \n",
    "    print(event[event['idx'] == idx]['picks'].values[0])\n",
    "    for station in pick_sta:\n",
    "        \n",
    "        \n",
    "        sta_inv = client2.get_stations(network=networks,\n",
    "                                       station=station, channel=\"?H?\", \n",
    "                                       starttime=otime - 1e8, endtime=otime + 1e8,level=\"response\")\n",
    "        if len(sta_inv) == 0:\n",
    "#             print(f\"Failed to fetch for {networks} {station} {otime}\")\n",
    "            continue\n",
    "            \n",
    "        _network = sta_inv[0].code\n",
    "        slat = sta_inv[0][0].latitude\n",
    "        slon = sta_inv[0][0].longitude\n",
    "        olat = event.loc[event['idx']==idx, 'latitude'].values[0]\n",
    "        olon = event.loc[event['idx']==idx, 'longitude'].values[0]\n",
    "        \n",
    "        dis1 = locations2degrees(olat, olon, slat, slon)\n",
    "        dist = degrees2kilometers(dis1)\n",
    "#         if max_dist < dist:\n",
    "#             max_dist = dist\n",
    "            \n",
    "#         if min_dist > dist:\n",
    "#             min_dist = dist\n",
    "            \n",
    "        distances.append([None, _network, station, dist])\n",
    "\n",
    "    # Sort distances\n",
    "    distances = sorted(distances, key=lambda item: item[-1])\n",
    "    distances = distances[:idx_sta+1]\n",
    "    \n",
    "    # Set up to define the xlim and ylim\n",
    "    max_y = 0\n",
    "    min_y = 0\n",
    "    # This count is for the if statements. Only used to ensure that min_y_count \n",
    "    #is changed from 0 to either the first positive value of the distance of one of the stations from the event\n",
    "    min_y_count = 0 \n",
    "    \n",
    "    max_x = 0\n",
    "    min_x = 0\n",
    "    \n",
    "    # This count is for the if statements. Only used to ensure that min_x_count \n",
    "    #is changed from 0 to either the first positive value of P pick time or the first positive value of S pick time\n",
    "    min_x_count= 0\n",
    "    # Create a figure\n",
    "    fig,axs = plt.subplots(1,4,figsize=(18,6))\n",
    "    gs = fig.add_gridspec(3, hspace=0, figure=fig)\n",
    "#     axs = gs.subplots(sharex=True, sharey=True)\n",
    "    starttime = otime -30\n",
    "    endtime = otime + 120\n",
    "    \n",
    "    # Define texts\n",
    "    texts = []\n",
    "    \n",
    "    for i, ii in enumerate(distances):\n",
    "            \n",
    "        if ii[1] in ['NC', 'BK']:\n",
    "            # Query waveforms\n",
    "            st = client_ncedc.get_waveforms(network=ii[1], station=ii[2], location=\"*\", channel=channel,starttime=starttime, endtime=endtime)\n",
    "\n",
    "        elif ii[1] in networks: \n",
    "            st = client_waveform.get_waveforms(network=ii[1], station=ii[2], channel=channel,starttime=starttime, endtime=endtime)\n",
    "  \n",
    "        else: \n",
    "            st =  Stream()\n",
    "            print(f\"WARNING: No data for {ii[1]}.{ii[2]}.{channel} on {otime}.\")    \n",
    "            continue\n",
    "            \n",
    "#         print(f\"len(st):{len(st)}\")\n",
    "#         print(st)\n",
    "    \n",
    "        # Skip empty traces\n",
    "        if len(st) == 0:\n",
    "                continue\n",
    "                \n",
    "        sta_picks = picks_idx[picks_idx['station'] == ii[2]]\n",
    "        p_picks = sta_picks.loc[sta_picks['phase'] == 'P']\n",
    "        s_picks = sta_picks.loc[sta_picks['phase'] == 'S']\n",
    "#         print(len(p_picks),len(s_picks))\n",
    "        \n",
    "        # Define the xlim values\n",
    "        # Define the maximum x value\n",
    "        if len(s_picks) > 0:\n",
    "            if max_x < UTCDateTime(s_picks.iloc[0]['time_pick']) - starttime:\n",
    "                max_x = UTCDateTime(s_picks.iloc[0]['time_pick']+5) - starttime\n",
    "        elif len(p_picks) > 0:\n",
    "            if max_x < UTCDateTime(p_picks.iloc[0]['time_pick']) - starttime: \n",
    "                max_x = UTCDateTime(p_picks.iloc[0]['time_pick']+5) - starttime\n",
    "        else:\n",
    "            print('No picks for this station. Skipping.')\n",
    "            continue \n",
    "            \n",
    "        # Define the minimum x value\n",
    "        if len(p_picks) > 0:\n",
    "            if min_x_count == 0:\n",
    "                if min_x < UTCDateTime(p_picks.iloc[0]['time_pick']) - starttime:\n",
    "                    min_x = UTCDateTime(p_picks.iloc[0]['time_pick']-5) - starttime\n",
    "                    min_x_count += 1           \n",
    "            else:\n",
    "                if min_x >= UTCDateTime(p_picks.iloc[0]['time_pick']) - starttime:\n",
    "                    min_x = UTCDateTime(p_picks.iloc[0]['time_pick']-5) - starttime            \n",
    "        elif len(s_picks) > 0:\n",
    "            if min_x_count == 0:\n",
    "                if min_x < UTCDateTime(s_picks.iloc[0]['time_pick'])- starttime:\n",
    "                    min_x = UTCDateTime(s_picks.iloc[0]['time_pick']-5)- starttime\n",
    "                    min_x_count += 1                \n",
    "            else:\n",
    "                if min_x >= UTCDateTime(s_picks.iloc[0]['time_pick'])- starttime:\n",
    "                    min_x = UTCDateTime(s_picks.iloc[0]['time_pick']-5) - starttime\n",
    "        else:\n",
    "            print('No picks for this station. Skipping.')\n",
    "            continue    \n",
    "            \n",
    "        if len(p_picks) == 0:\n",
    "            continue\n",
    "            \n",
    "#         print('This is after the p_pick continue statement')\n",
    "    \n",
    "        # Define ylim values\n",
    "        if min_y_count == 0:\n",
    "            if min_y < ii[3]:\n",
    "                min_y = ii[3] - 5\n",
    "                min_y_count += 1           \n",
    "        else:\n",
    "            if min_y >= ii[3]:\n",
    "                min_y = ii[3] - 5 \n",
    "                \n",
    "        max_y = ii[3] + 5\n",
    "        \n",
    "    scaling_factor = (1/2)*(max_y-min_y)   \n",
    "        \n",
    "    for i, ii in enumerate(distances):\n",
    "            \n",
    "        if ii[1] in ['NC', 'BK']:\n",
    "            # Query waveforms\n",
    "            st = client_ncedc.get_waveforms(network=ii[1], station=ii[2], location=\"*\", channel=channel,starttime=starttime, endtime=endtime)\n",
    "\n",
    "        elif ii[1] in networks: \n",
    "            st = client_waveform.get_waveforms(network=ii[1], station=ii[2], channel=channel,starttime=starttime, endtime=endtime)\n",
    "  \n",
    "        else: \n",
    "            st =  Stream()\n",
    "            print(f\"WARNING: No data for {ii[1]}.{ii[2]}.{channel} on {otime}.\")    \n",
    "            continue\n",
    "            \n",
    "#         print(f\"len(st):{len(st)}\")\n",
    "#         print(st)\n",
    "    \n",
    "        # Skip empty traces\n",
    "        if len(st) == 0:\n",
    "                continue\n",
    "        _st = Stream()\n",
    "        # Check for HH and BH channels presence\n",
    "        has_HH = bool(st.select(channel=\"HH?\"))\n",
    "        has_BH = bool(st.select(channel=\"BH?\"))\n",
    "\n",
    "        # Apply selection logic based on channel presence\n",
    "        if has_HH and has_BH:\n",
    "            # If both HH and BH channels are present, select only HH\n",
    "            _st += st.select(channel=\"HH?\")\n",
    "        elif has_HH:\n",
    "            # If only HH channels are present\n",
    "            _st += st.select(channel=\"HH?\")\n",
    "        elif has_BH:\n",
    "            # If only BH channels are present\n",
    "            _st += st.select(channel=\"BH?\")\n",
    "\n",
    "        st = _st\n",
    "\n",
    "        print(f'Second st print:{_st}')\n",
    "              \n",
    "        st = Stream(filter(lambda st: st.stats.sampling_rate > 10, st))\n",
    "        st.taper(max_percentage=0.05)\n",
    "        st.filter(type='bandpass', freqmin=2, freqmax=25)\n",
    "        st.merge(fill_value='interpolate') # fill gaps if there are any.\n",
    "\n",
    "#         print(st)\n",
    "        # Select only one trace per channel\n",
    "        unique_channels = set(tr.stats.channel for tr in st)\n",
    "        selected_traces = []\n",
    "        \n",
    "        for ch in unique_channels:\n",
    "            selected_traces.append(next(tr for tr in st if tr.stats.channel == ch))\n",
    "        st = Stream(selected_traces)\n",
    "                   \n",
    "        trim_st = st.copy()\n",
    "        sta_picks = picks_idx[picks_idx['station'] == ii[2]]\n",
    "        p_picks = sta_picks.loc[sta_picks['phase'] == 'P']\n",
    "        s_picks = sta_picks.loc[sta_picks['phase'] == 'S']\n",
    "#         print(len(p_picks),len(s_picks))\n",
    "        \n",
    "        \n",
    "                \n",
    "            \n",
    "        if len(p_picks) == 0:\n",
    "            continue \n",
    "#         print('This is after the p_pick continue statement')\n",
    "        print(trim_st)\n",
    "        \n",
    "        for iax in range(len(trim_st)):\n",
    "            print(iax)\n",
    "            sampling_rate = trim_st[iax].stats.sampling_rate\n",
    "            trim_st = trim_st.normalize()\n",
    "            \n",
    "            tp = UTCDateTime(p_picks.iloc[0]['time_pick']) - otime + 30\n",
    "            i1 = int((tp-5)*sampling_rate)\n",
    "            i2 = int((tp+15)*sampling_rate)\n",
    "\n",
    "            offsets1 = ii[3]\n",
    "            try: \n",
    "                wave = trim_st[iax].data\n",
    "                wave = wave / (np.nanmax(wave[i1:i2], axis=-1)*10)\n",
    "            except:\n",
    "                continue \n",
    "            \n",
    "#             print(trim_st[iax].stats.sampling_rate)\n",
    "            axs[iax].plot(trim_st[iax].times(), wave * scaling_factor + offsets1, \n",
    "                          color='black', label=f\"{trim_st[iax].stats.channel}\", alpha=0.7, lw=0.5)\n",
    "#             axs[iax].plot(trim_st[iax].times(), wave * 30 + offsets1, color='black', label=f\"{trim_st[iax].stats.channel}\", alpha=0.7, lw=0.5)\n",
    "\n",
    "#             axs[iax].text(xlim[-1] + 2,   offsets1, \n",
    "#                               [ii[2]], fontsize=8, verticalalignment='bottom')\n",
    "\n",
    "            if len(p_picks) > 0:\n",
    "                axs[iax].vlines(UTCDateTime(p_picks.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/35) * scaling_factor, \n",
    "                                offsets1 + (1/35) * scaling_factor, color='r')\n",
    "            if len(s_picks) > 0:\n",
    "                axs[iax].vlines(UTCDateTime(s_picks.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/35) * scaling_factor, \n",
    "                                offsets1 + (1/35) * scaling_factor, color='b')\n",
    "        texts.append([ii[2],ii[3]])\n",
    "\n",
    "    \n",
    "#     print(max_y,min_y)\n",
    "    chs = ['2','1','Z']\n",
    "    for iax in range(3):\n",
    "        for i, ii in enumerate(texts):\n",
    "            offsets1 = ii[1]\n",
    "            axs[iax].text(max_x + 0.5, offsets1, \n",
    "                                  [ii[0]], fontsize=8, verticalalignment='bottom')\n",
    "        axs[iax].legend(chs[iax],loc='upper right', handlelength=0)\n",
    "        axs[iax].set_ylim([min_y,max_y])\n",
    "        axs[iax].set_xlim([min_x,max_x])\n",
    "        axs[iax].grid(alpha=0.5)\n",
    "    fig.supxlabel('Time [sec]', y=0.07)\n",
    "    fig.supylabel('Distance [km]')\n",
    "    fig.suptitle(f\"{title}: Origin Time={otime}, \\n Latitude={round(event[event['idx']==idx]['latitude'].values[0], 2)}, Longtitude={round(event[event['idx']==idx]['longitude'].values[0], 2)}, Depth={round(event[event['idx']==idx]['depth'].values[0], 2)}\", y=1)\n",
    "    \n",
    "    m = Basemap(projection='merc', llcrnrlat=40, urcrnrlat=50, llcrnrlon=-130, urcrnrlon=-120, resolution='i', ax=axs[3])\n",
    "    m.drawcoastlines()\n",
    "    m.drawcountries()\n",
    "    m.drawstates()\n",
    "    m.drawmapboundary()\n",
    "    m.drawparallels(np.arange(40, 51, 1), labels=[1,0,0,0])\n",
    "    m.drawmeridians(np.arange(-130, -119, 1), labels=[0,0,0,1])\n",
    "    x, y = m(event[event['idx']==idx]['longitude'].values[0], event[event['idx']==idx]['latitude'].values[0])\n",
    "    m.plot(x, y, 'ro', markersize=9)\n",
    "    axs[3].set_title('Event Location')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba14668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplots_cluster_scale(idx, mycatalog, mycatalog_picks, networks, channel, idx_sta, title, fig_title):\n",
    "    \"\"\"\n",
    "    idx: event_idx\n",
    "    mycatalog: dataframe that contains only the unique picks (i.e., mycatalog_picks.drop_duplicates(subset=['idx']).copy())\n",
    "    mycatalog_picks: all pick assignments csv file (e.g., pd.read_csv('../data/datasets_OR/all_pick_assignments_OR.csv'))\n",
    "    networks: string of networks (e.g., \"NV,OO,7A\")\n",
    "    channel: specify the direction of the channel (i.e., \"?HZ\", \"?HE\" or \"?HN\")\n",
    "    idx_sta: choose the station to which you want to show the waveforms\n",
    "    title: title in a string\n",
    "    fig_title: figure title in as string\n",
    "    \"\"\"\n",
    "        \n",
    "    # Define the clients \n",
    "    client_waveform = WaveformClient()\n",
    "    client2 = Client(\"IRIS\")\n",
    "    client_ncedc = Client('NCEDC')\n",
    "\n",
    "\n",
    "    # Plot the earthquake moveout for one of the unmatched events for all stations \n",
    "    event = mycatalog\n",
    "    picks = mycatalog_picks\n",
    "    \n",
    "    p = PdfPages(fig_title) \n",
    "    \n",
    "    for idx in event['idx']:\n",
    "        \n",
    "        picks_idx = picks.loc[picks['idx']==idx]\n",
    "        pick_sta = np.unique(picks_idx['station'])\n",
    "\n",
    "        otime = UTCDateTime(str(event[event['idx'] == idx][\"datetime\"].values[0]))\n",
    "        distances = []\n",
    "        max_dist = 10\n",
    "        min_dist = 0\n",
    "\n",
    "        print(event[event['idx'] == idx]['picks'].values[0])\n",
    "        for station in pick_sta:\n",
    "\n",
    "\n",
    "            sta_inv = client2.get_stations(network=networks,\n",
    "                                           station=station, channel=\"?H?\", \n",
    "                                           starttime=otime - 1e8, endtime=otime + 1e8,level=\"response\")\n",
    "            if len(sta_inv) == 0:\n",
    "    #             print(f\"Failed to fetch for {networks} {station} {otime}\")\n",
    "                continue\n",
    "\n",
    "            _network = sta_inv[0].code\n",
    "            slat = sta_inv[0][0].latitude\n",
    "            slon = sta_inv[0][0].longitude\n",
    "            olat = event.loc[event['idx']==idx, 'latitude'].values[0]\n",
    "            olon = event.loc[event['idx']==idx, 'longitude'].values[0]\n",
    "\n",
    "            dis1 = locations2degrees(olat, olon, slat, slon)\n",
    "            dist = degrees2kilometers(dis1)\n",
    "    #         if max_dist < dist:\n",
    "    #             max_dist = dist\n",
    "\n",
    "    #         if min_dist > dist:\n",
    "    #             min_dist = dist\n",
    "\n",
    "            distances.append([None, _network, station, dist])\n",
    "\n",
    "        # Sort distances\n",
    "        distances = sorted(distances, key=lambda item: item[-1])\n",
    "        distances = distances[:idx_sta+1]\n",
    "\n",
    "        # Set up to define the xlim and ylim\n",
    "        max_y = 0\n",
    "        min_y = 0\n",
    "        # This count is for the if statements. Only used to ensure that min_y_count \n",
    "        #is changed from 0 to either the first positive value of the distance of one of the stations from the event\n",
    "        min_y_count = 0 \n",
    "\n",
    "        max_x = 0\n",
    "        min_x = 0\n",
    "\n",
    "        # This count is for the if statements. Only used to ensure that min_x_count \n",
    "        #is changed from 0 to either the first positive value of P pick time or the first positive value of S pick time\n",
    "        min_x_count= 0\n",
    "        # Create a figure\n",
    "        fig,axs = plt.subplots(1,4,figsize=(18,6))\n",
    "        gs = fig.add_gridspec(3, hspace=0, figure=fig)\n",
    "    #     axs = gs.subplots(sharex=True, sharey=True)\n",
    "        starttime = otime -30\n",
    "        endtime = otime + 120\n",
    "\n",
    "        # Define texts\n",
    "        texts = []\n",
    "\n",
    "        for i, ii in enumerate(distances):\n",
    "\n",
    "            if ii[1] in ['NC', 'BK']:\n",
    "                # Query waveforms\n",
    "                st = client_ncedc.get_waveforms(network=ii[1], station=ii[2], location=\"*\", channel=channel,starttime=starttime, endtime=endtime)\n",
    "\n",
    "            elif ii[1] in networks: \n",
    "                st = client_waveform.get_waveforms(network=ii[1], station=ii[2], channel=channel,starttime=starttime, endtime=endtime)\n",
    "\n",
    "            else: \n",
    "                st =  Stream()\n",
    "                print(f\"WARNING: No data for {ii[1]}.{ii[2]}.{channel} on {otime}.\")    \n",
    "                continue\n",
    "\n",
    "    #         print(f\"len(st):{len(st)}\")\n",
    "    #         print(st)\n",
    "\n",
    "            # Skip empty traces\n",
    "            if len(st) == 0:\n",
    "                    continue\n",
    "\n",
    "            sta_picks = picks_idx[picks_idx['station'] == ii[2]]\n",
    "            p_picks = sta_picks.loc[sta_picks['phase'] == 'P']\n",
    "            s_picks = sta_picks.loc[sta_picks['phase'] == 'S']\n",
    "    #         print(len(p_picks),len(s_picks))\n",
    "\n",
    "            # Define the xlim values\n",
    "            # Define the maximum x value\n",
    "            if len(s_picks) > 0:\n",
    "                if max_x < UTCDateTime(s_picks.iloc[0]['time_pick']) - starttime:\n",
    "                    max_x = UTCDateTime(s_picks.iloc[0]['time_pick']+5) - starttime\n",
    "            elif len(p_picks) > 0:\n",
    "                if max_x < UTCDateTime(p_picks.iloc[0]['time_pick']) - starttime: \n",
    "                    max_x = UTCDateTime(p_picks.iloc[0]['time_pick']+5) - starttime\n",
    "            else:\n",
    "                print('No picks for this station. Skipping.')\n",
    "                continue \n",
    "\n",
    "            # Define the minimum x value\n",
    "            if len(p_picks) > 0:\n",
    "                if min_x_count == 0:\n",
    "                    if min_x < UTCDateTime(p_picks.iloc[0]['time_pick']) - starttime:\n",
    "                        min_x = UTCDateTime(p_picks.iloc[0]['time_pick']-5) - starttime\n",
    "                        min_x_count += 1           \n",
    "                else:\n",
    "                    if min_x >= UTCDateTime(p_picks.iloc[0]['time_pick']) - starttime:\n",
    "                        min_x = UTCDateTime(p_picks.iloc[0]['time_pick']-5) - starttime            \n",
    "            elif len(s_picks) > 0:\n",
    "                if min_x_count == 0:\n",
    "                    if min_x < UTCDateTime(s_picks.iloc[0]['time_pick'])- starttime:\n",
    "                        min_x = UTCDateTime(s_picks.iloc[0]['time_pick']-5)- starttime\n",
    "                        min_x_count += 1                \n",
    "                else:\n",
    "                    if min_x >= UTCDateTime(s_picks.iloc[0]['time_pick'])- starttime:\n",
    "                        min_x = UTCDateTime(s_picks.iloc[0]['time_pick']-5) - starttime\n",
    "            else:\n",
    "                print('No picks for this station. Skipping.')\n",
    "                continue    \n",
    "\n",
    "    #         if len(p_picks) == 0:\n",
    "    #             continue\n",
    "\n",
    "    #         print('This is after the p_pick continue statement')\n",
    "\n",
    "            # Define ylim values\n",
    "            if min_y_count == 0:\n",
    "                if min_y < ii[3]:\n",
    "                    min_y = ii[3] - 5\n",
    "                    min_y_count += 1           \n",
    "            else:\n",
    "                if min_y >= ii[3]:\n",
    "                    min_y = ii[3] - 5 \n",
    "\n",
    "            max_y = ii[3] + 5\n",
    "\n",
    "        scaling_factor = (1/2)*(max_y-min_y)   \n",
    "\n",
    "        for i, ii in enumerate(distances):\n",
    "\n",
    "            if ii[1] in ['NC', 'BK']:\n",
    "                # Query waveforms\n",
    "                st = client_ncedc.get_waveforms(network=ii[1], station=ii[2], location=\"*\", channel=channel,starttime=starttime, endtime=endtime)\n",
    "\n",
    "            elif ii[1] in networks: \n",
    "                st = client_waveform.get_waveforms(network=ii[1], station=ii[2], channel=channel,starttime=starttime, endtime=endtime)\n",
    "\n",
    "            else: \n",
    "                st =  Stream()\n",
    "                print(f\"WARNING: No data for {ii[1]}.{ii[2]}.{channel} on {otime}.\")    \n",
    "                continue\n",
    "\n",
    "    #         print(f\"len(st):{len(st)}\")\n",
    "    #         print(st)\n",
    "\n",
    "            # Skip empty traces\n",
    "            if len(st) == 0:\n",
    "                    continue\n",
    "            _st = Stream()\n",
    "            # Check for HH and BH channels presence\n",
    "            has_HH = bool(st.select(channel=\"HH?\"))\n",
    "            has_BH = bool(st.select(channel=\"BH?\"))\n",
    "\n",
    "            # Apply selection logic based on channel presence\n",
    "            if has_HH and has_BH:\n",
    "                # If both HH and BH channels are present, select only HH\n",
    "                _st += st.select(channel=\"HH?\")\n",
    "            elif has_HH:\n",
    "                # If only HH channels are present\n",
    "                _st += st.select(channel=\"HH?\")\n",
    "            elif has_BH:\n",
    "                # If only BH channels are present\n",
    "                _st += st.select(channel=\"BH?\")\n",
    "\n",
    "            st = _st\n",
    "\n",
    "            print(f'Second st print:{_st}')\n",
    "\n",
    "            st = Stream(filter(lambda st: st.stats.sampling_rate > 10, st))\n",
    "            st.taper(max_percentage=0.05)\n",
    "            st.filter(type='bandpass', freqmin=2, freqmax=25)\n",
    "            st.merge(fill_value='interpolate') # fill gaps if there are any.\n",
    "\n",
    "    #         print(st)\n",
    "            # Select only one trace per channel\n",
    "            unique_channels = set(tr.stats.channel for tr in st)\n",
    "            selected_traces = []\n",
    "\n",
    "            for ch in unique_channels:\n",
    "                selected_traces.append(next(tr for tr in st if tr.stats.channel == ch))\n",
    "            st = Stream(selected_traces)\n",
    "\n",
    "            trim_st = st.copy()\n",
    "            sta_picks = picks_idx[picks_idx['station'] == ii[2]]\n",
    "            p_picks = sta_picks.loc[sta_picks['phase'] == 'P']\n",
    "            s_picks = sta_picks.loc[sta_picks['phase'] == 'S']\n",
    "    #         print(len(p_picks),len(s_picks))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #         if len(p_picks) == 0:\n",
    "    #             continue \n",
    "    #         print('This is after the p_pick continue statement')\n",
    "            print(trim_st)\n",
    "\n",
    "            for iax in range(len(trim_st)):\n",
    "                print(iax)\n",
    "                sampling_rate = trim_st[iax].stats.sampling_rate\n",
    "                trim_st = trim_st.normalize()\n",
    "\n",
    "                if len(p_picks)>0:\n",
    "                    tp = UTCDateTime(p_picks.iloc[0]['time_pick']) - otime + 30\n",
    "                    i1 = int((tp-5)*sampling_rate)\n",
    "                    i2 = int((tp+15)*sampling_rate)\n",
    "                elif len(s_picks)>0:\n",
    "                    ts = UTCDateTime(s_picks.iloc[0]['time_pick']) - otime + 30\n",
    "                    i1 = int((ts-10)*sampling_rate)\n",
    "                    i2 = int((ts+10)*sampling_rate)\n",
    "                else:\n",
    "                    print(f\"WARNING: No pick time for {ii[1]}.{ii[2]}.{channel} on {otime}.\")\n",
    "\n",
    "                offsets1 = ii[3]\n",
    "                try: \n",
    "                    wave = trim_st[iax].data\n",
    "                    wave = wave / (np.nanmax(wave[i1:i2], axis=-1)*10)\n",
    "                except:\n",
    "                    continue \n",
    "\n",
    "    #             print(trim_st[iax].stats.sampling_rate)\n",
    "                axs[iax].plot(trim_st[iax].times(), wave * scaling_factor + offsets1, \n",
    "                              color='black', label=f\"{trim_st[iax].stats.channel}\", alpha=0.7, lw=0.5)\n",
    "    #             axs[iax].plot(trim_st[iax].times(), wave * 30 + offsets1, color='black', label=f\"{trim_st[iax].stats.channel}\", alpha=0.7, lw=0.5)\n",
    "\n",
    "    #             axs[iax].text(xlim[-1] + 2,   offsets1, \n",
    "    #                               [ii[2]], fontsize=8, verticalalignment='bottom')\n",
    "\n",
    "                if len(p_picks) > 0:\n",
    "                    axs[iax].vlines(UTCDateTime(p_picks.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/35) * scaling_factor, \n",
    "                                    offsets1 + (1/35) * scaling_factor, color='r')\n",
    "                if len(s_picks) > 0:\n",
    "                    axs[iax].vlines(UTCDateTime(s_picks.iloc[0]['time_pick']) - otime + 30, offsets1 - (1/35) * scaling_factor, \n",
    "                                    offsets1 + (1/35) * scaling_factor, color='b')\n",
    "            texts.append([ii[2],ii[3]])\n",
    "\n",
    "\n",
    "    #     print(max_y,min_y)\n",
    "        chs = ['2','1','Z']\n",
    "        for iax in range(3):\n",
    "            for i, ii in enumerate(texts):\n",
    "                offsets1 = ii[1]\n",
    "                axs[iax].text(max_x + 0.5, offsets1, \n",
    "                                      [ii[0]], fontsize=8, verticalalignment='bottom')\n",
    "            axs[iax].legend(chs[iax],loc='upper right', handlelength=0)\n",
    "            axs[iax].set_ylim([min_y,max_y])\n",
    "            axs[iax].set_xlim([min_x,max_x])\n",
    "            axs[iax].grid(alpha=0.5)\n",
    "        fig.supxlabel('Time [sec]', y=0.07)\n",
    "        fig.supylabel('Distance [km]')\n",
    "        fig.suptitle(f\"{title}: Origin Time={otime}, \\n Latitude={round(event[event['idx']==idx]['latitude'].values[0], 2)}, Longtitude={round(event[event['idx']==idx]['longitude'].values[0], 2)}, Depth={round(event[event['idx']==idx]['depth'].values[0], 2)}\", y=1)\n",
    "\n",
    "        m = Basemap(projection='merc', llcrnrlat=40, urcrnrlat=50, llcrnrlon=-130, urcrnrlon=-120, resolution='i', ax=axs[3])\n",
    "        m.drawcoastlines()\n",
    "        m.drawcountries()\n",
    "        m.drawstates()\n",
    "        m.drawmapboundary()\n",
    "        m.drawparallels(np.arange(40, 51, 1), labels=[1,0,0,0])\n",
    "        m.drawmeridians(np.arange(-130, -119, 1), labels=[0,0,0,1])\n",
    "        x, y = m(event[event['idx']==idx]['longitude'].values[0], event[event['idx']==idx]['latitude'].values[0])\n",
    "        m.plot(x, y, 'ro', markersize=9)\n",
    "        axs[3].set_title('Event Location')\n",
    "        \n",
    "        fig.savefig(p, format='pdf')  \n",
    "\n",
    "    p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef03321",
   "metadata": {},
   "source": [
    "### Specify the latitudes and longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f79e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events = pd.read_csv('../data/datasets_2014/new_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d048ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = new_events[new_events['station']=='J25B']['idx'].values\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d4c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events = new_events[new_events[\"idx\"].isin(idx)]\n",
    "new_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac241e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events_specific_lat_lon = new_events.loc[(new_events['latitude']>46)&(new_events['latitude']<47.5)&(new_events['longitude']<-124)&(new_events['longitude']>-126)]\n",
    "new_events_specific_lat_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c610d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_events = new_events_specific_lat_lon.loc[(new_events_specific_lat_lon['depth']>1)&(new_events_specific_lat_lon['depth']<40)]\n",
    "new_events = new_events_specific_lat_lon.loc[new_events_specific_lat_lon['picks']>=6][0:30]\n",
    "new_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eda7e0",
   "metadata": {},
   "source": [
    "### Histogram: Depths of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92381c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the number of picks for the matched events\n",
    "plt.figure()\n",
    "bins = np.linspace(0,50,25)\n",
    "plt.hist(new_events['depth'],bins=bins)\n",
    "plt.xlabel('Depth (km)')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.title('Histogram of the depths of the events in the cluster at ~46.5$^\\circ$ N')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436cab64",
   "metadata": {},
   "source": [
    "### Plot HH?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f35b6a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "mycatalog= mycatalog\n",
    "mycatalog_picks=mycatalog_picks\n",
    "networks= all_picks_networks\n",
    "channel= \"HH?\"\n",
    "idx_sta= 50\n",
    "title= \"Events matched\"\n",
    "fig_title= \"events_matched.png\"\n",
    "ylim= [0,300]\n",
    "xlim= [30,45]\n",
    "\n",
    "for idx in new_events['idx']:\n",
    "    subplots_cluster_scale_p(idx,mycatalog,mycatalog_picks,networks,channel,idx_sta,title,fig_title,ylim,xlim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72ab1e",
   "metadata": {},
   "source": [
    "### Plot BH?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c369c148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "mycatalog= mycatalog\n",
    "mycatalog_picks=mycatalog_picks\n",
    "networks= all_picks_networks\n",
    "channel= \"BH?\"\n",
    "idx_sta= 50\n",
    "title= \"Events matched\"\n",
    "fig_title= \"events_matched.png\"\n",
    "ylim= [0,300]\n",
    "xlim= [30,45]\n",
    "\n",
    "for idx in new_events['idx']:\n",
    "    subplots_cluster_scale_p(idx,mycatalog,mycatalog_picks,networks,channel,idx_sta,title,fig_title,ylim,xlim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6211d",
   "metadata": {},
   "source": [
    "### Plot both HH? and BH?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events['datetime'] = pd.to_datetime(new_events['datetime'], utc = True)\n",
    "new_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f15bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameters for subplots_cluster_scale_p\n",
    "mycatalog= mycatalog\n",
    "mycatalog_picks=mycatalog_picks\n",
    "networks= all_picks_networks\n",
    "channel= \"?H?\"\n",
    "idx_sta= 50\n",
    "title= \"Events matched\"\n",
    "fig_title= \"events_matched.png\"\n",
    "\n",
    "for idx in new_events['idx']:\n",
    "    subplots_cluster_scale_p(idx,new_events,mycatalog_picks,networks,channel,idx_sta,title,fig_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae32807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameters for subplots_cluster_scale\n",
    "mycatalog= mycatalog\n",
    "mycatalog_picks=mycatalog_picks\n",
    "networks= all_picks_networks\n",
    "channel= \"?H?\"\n",
    "idx_sta= 50\n",
    "title= \"Events matched\"\n",
    "fig_title= \"new_events_plots.pdf\"\n",
    "\n",
    "subplots_cluster_scale(new_events,mycatalog_picks,networks,channel,idx_sta,title,fig_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e815a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the number of picks for the matched events\n",
    "new_events['time'] = pd.to_datetime(new_events['time'])\n",
    "year1 = 2012\n",
    "time1 = datetime(year=year1, month=1, day=1)\n",
    "time2 = datetime(year=year1 + 1, month=1, day=1)\n",
    "time_bins = pd.date_range(start=time1, end=time2, freq='5D')\n",
    "plt.figure()\n",
    "plt.hist(new_events['time'], bins=time_bins)\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.title('Histogram for the frequency of the events in the cluster at ~46.5$^\\circ$ N')\n",
    "plt.xticks(rotation=45)  # Optional: Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02952d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.backends.backend_pdf import PdfPages \n",
    "\n",
    "# customizing runtime configuration stored \n",
    "# in matplotlib.rcParams \n",
    "plt.rcParams[\"figure.figsize\"] = [7.00, 3.50] \n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "fig1 = plt.figure() \n",
    "plt.plot([17, 45, 7, 8, 7], color='orange') \n",
    "\n",
    "fig2 = plt.figure() \n",
    "plt.plot([13, 25, 1, 6, 3], color='blue') \n",
    "\n",
    "Fig3 = plt.figure() \n",
    "plt.plot([22, 11, 2, 1, 23], color='green') \n",
    "\n",
    "\n",
    "def save_image(filename): \n",
    "\t\n",
    "\t# PdfPages is a wrapper around pdf \n",
    "\t# file so there is no clash and create \n",
    "\t# files with no error. \n",
    "\tp = PdfPages(filename) \n",
    "\t\n",
    "\t# get_fignums Return list of existing \n",
    "\t# figure numbers \n",
    "\tfig_nums = plt.get_fignums() \n",
    "\tfigs = [plt.figure(n) for n in fig_nums] \n",
    "\t\n",
    "\t# iterating over the numbers in list \n",
    "\tfor fig in figs: \n",
    "\t\t\n",
    "\t\t# and saving the files \n",
    "\t\tfig.savefig(p, format='pdf') \n",
    "\t\n",
    "\t# close the object \n",
    "\tp.close() \n",
    "\n",
    "# name your Pdf file \n",
    "filename = \"multi_plot_image.pdf\"\n",
    "\n",
    "# call the function \n",
    "save_image(filename) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84d3bd",
   "metadata": {},
   "source": [
    "## Plot the cluster events at around 43.25&deg; N, 124.25&deg; W using the plotting functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de7f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events_specific_lat_lon = unmatched_events_mycatalog2morton_and_anss.loc[(unmatched_events_mycatalog2morton_and_anss['latitude']>43.0)&(unmatched_events_mycatalog2morton_and_anss['latitude']<43.3)&(unmatched_events_mycatalog2morton_and_anss['longitude']<-124.25)&(unmatched_events_mycatalog2morton_and_anss['longitude']>-124.75)]\n",
    "new_events_specific_lat_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6556db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events = new_events_specific_lat_lon.loc[new_events_specific_lat_lon['picks']>5]\n",
    "new_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa50fe",
   "metadata": {},
   "source": [
    "### Plot HH?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "mycatalog= mycatalog\n",
    "mycatalog_picks=mycatalog_picks\n",
    "networks= all_picks_networks\n",
    "channel= \"HH?\"\n",
    "idx_sta= 50\n",
    "title= \"Events matched\"\n",
    "fig_title= \"events_matched.png\"\n",
    "ylim= [0,300]\n",
    "xlim= [20,150]\n",
    "\n",
    "for idx in new_events['idx']:\n",
    "    subplots_cluster_scale_p(idx,mycatalog,mycatalog_picks,networks,channel,idx_sta,title,fig_title,ylim,xlim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0acaf0",
   "metadata": {},
   "source": [
    "### Plot BH?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "mycatalog= mycatalog\n",
    "mycatalog_picks=mycatalog_picks\n",
    "networks= all_picks_networks\n",
    "channel= \"BH?\"\n",
    "idx_sta= 50\n",
    "title= \"Events matched\"\n",
    "fig_title= \"events_matched.png\"\n",
    "ylim= [0,300]\n",
    "xlim= [20,150]\n",
    "\n",
    "for idx in new_events['idx']:\n",
    "    subplots_cluster_scale_p(idx,mycatalog,mycatalog_picks,networks,channel,idx_sta,title,fig_title,ylim,xlim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863afcd8",
   "metadata": {},
   "source": [
    "## Calculate SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8944e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_picks = pd.read_csv('../data/datasets_2014/all_picks_2014.csv')\n",
    "all_pick_assignments = pd.read_csv('../data/datasets_2014/all_pick_assignments_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_snr(all_picks,all_pick_assignments):\n",
    "    \"\"\" \n",
    "    This function calculates the SNRs for each station in each event.\n",
    "    \n",
    "    Inputs:\n",
    "    1. The all_pick.csv file from the 2_format_pick2associate file.\n",
    "    2. The all_pick_assignments.csv file from the 3_association file.\n",
    "    \n",
    "    Oututs:\n",
    "    The new all_pick_assignments_snr file with the additional SNR column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the list of networks\n",
    "    all_picks_networks = all_picks['station_network_code'].drop_duplicates()\n",
    "    list_networks = list(all_picks_networks)\n",
    "    networks = ','.join(all_picks_networks)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define the clients \n",
    "    client_waveform = WaveformClient()\n",
    "    client2 = Client(\"IRIS\")\n",
    "    client_ncedc = Client('NCEDC')\n",
    "    \n",
    "    all_pick_assignments['datetime'] = pd.to_datetime(all_pick_assignments['time'], utc = True)\n",
    "\n",
    "    \n",
    "    # Define parameters\n",
    "    percentile=98\n",
    "    \n",
    "    # Create empty lists\n",
    "    snr_list = []\n",
    "        \n",
    "    # Make sure if a station for an event has more than 1 P or S pick\n",
    "    for idx in all_pick_assignments['idx'].drop_duplicates():\n",
    "        # Define parameters\n",
    "        otime = UTCDateTime(str(all_pick_assignments[all_pick_assignments['idx'] == idx][\"datetime\"].values[0]))\n",
    "\n",
    "\n",
    "        # Create empty lists\n",
    "        networks_stas = []\n",
    "\n",
    "        # Plot the earthquake moveout for one of the unmatched events for all stations \n",
    "    #     event = mycatalog\n",
    "        pick_idx = all_pick_assignments.loc[all_pick_assignments['idx']==idx]\n",
    "        pick_sta = np.unique(pick_idx['station'])\n",
    "        \n",
    "    #     distances = []\n",
    "    #     max_dist = 10\n",
    "    #     min_dist = 0\n",
    "        for station in pick_sta:\n",
    "\n",
    "            sta_inv = client2.get_stations(network=networks,\n",
    "                                           station=station, channel=\"?H?\", \n",
    "                                           starttime=otime - 1e8, endtime=otime + 1e8,level=\"response\")\n",
    "            if len(sta_inv) == 0:\n",
    "                print(f'No inventory for station {station}. Skipping.')\n",
    "                continue\n",
    "\n",
    "            network = sta_inv[0].code\n",
    "    #         slat = sta_inv[0][0].latitude\n",
    "    #         slon = sta_inv[0][0].longitude\n",
    "    #         olat = event.loc[event['idx']==idx, 'latitude'].values[0]\n",
    "    #         olon = event.loc[event['idx']==idx, 'longitude'].values[0]\n",
    "\n",
    "    #         dis1 = locations2degrees(olat, olon, slat, slon)\n",
    "    #         dist = degrees2kilometers(dis1)\n",
    "    # #         if max_dist < dist:\n",
    "    # #             max_dist = dist\n",
    "\n",
    "    # #         if min_dist > dist:\n",
    "    # #             min_dist = dist\n",
    "\n",
    "            networks_stas.append([network,station])\n",
    "        \n",
    "   \n",
    "        events = all_pick_assignments[all_pick_assignments['idx']==idx]\n",
    "        for i in networks_stas:\n",
    "            events1 = events[events['station']==i[1]]\n",
    "            p_picks = events1[events1['phase']=='P']\n",
    "            s_picks = events1[events1['phase']=='S']\n",
    "            \n",
    "\n",
    "            if len(p_picks)>0 and len(s_picks)>0:\n",
    "                print(p_picks['datetime'].values,s_picks['datetime'].values)\n",
    "                p_pick_time = UTCDateTime(str(p_picks['datetime'].values[0]))\n",
    "                s_pick_time = UTCDateTime(str(s_picks['datetime'].values[0]))\n",
    "                \n",
    "                starttime_st = UTCDateTime(p_pick_time)-timedelta(seconds=120)\n",
    "                endtime_st = UTCDateTime(p_pick_time)+timedelta(seconds=120)\n",
    "                \n",
    "                starttime_noise = UTCDateTime(p_pick_time)-timedelta(seconds=8)\n",
    "                endtime_noise = UTCDateTime(p_pick_time)\n",
    "                \n",
    "                starttime_signal = UTCDateTime(s_pick_time)-timedelta(seconds=1)\n",
    "                endtime_signal = UTCDateTime(s_pick_time)+timedelta(seconds=2)\n",
    "                \n",
    "                print(starttime_noise,endtime_noise)\n",
    "            \n",
    "                if i[0] in ['NC', 'BK']:\n",
    "                # Query waveforms\n",
    "                    st = client_ncedc.get_waveforms(network=i[0], station=i[1],\n",
    "                                                    location=\"*\", channel=\"?HZ\",starttime=starttime_st,\n",
    "                                                    endtime=endtime_st)\n",
    "\n",
    "                elif i[0] in networks: \n",
    "                    st = client_waveform.get_waveforms(network=i[0], station=i[1],\n",
    "                                                       channel='?HZ',starttime=starttime_st, endtime=endtime_st)\n",
    "\n",
    "                else: \n",
    "                    st =  Stream()\n",
    "                    print(f\"WARNING: No data for {ii[1]}.{ii[2]}.{channel} on {otime}.\")    \n",
    "                    continue\n",
    "\n",
    "        #         print(f\"len(st):{len(st)}\")\n",
    "        #         print(st)\n",
    "\n",
    "                # Skip empty traces\n",
    "                if len(st) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                print(f'First st print:{st}')\n",
    "                # Create a new stream\n",
    "                _st = Stream()\n",
    "                # Check for HH and BH channels presence\n",
    "                has_HH = bool(st.select(channel=\"HH?\"))\n",
    "                has_BH = bool(st.select(channel=\"BH?\"))\n",
    "\n",
    "                # Apply selection logic based on channel presence\n",
    "                if has_HH and has_BH:\n",
    "                    # If both HH and BH channels are present, select only HH\n",
    "                    _st += st.select(channel=\"HH?\")\n",
    "                elif has_HH:\n",
    "                    # If only HH channels are present\n",
    "                    _st += st.select(channel=\"HH?\")\n",
    "                elif has_BH:\n",
    "                    # If only BH channels are present\n",
    "                    _st += st.select(channel=\"BH?\")\n",
    "\n",
    "                _st.merge(fill_value='interpolate') # fill gaps if there are any.\n",
    "\n",
    "                print(f'Second st print:{_st}')\n",
    "            \n",
    "                noise = _st.copy().trim(starttime=starttime_noise,endtime=endtime_noise)    \n",
    "                signal = _st.copy().trim(starttime=starttime_signal,endtime=endtime_signal) \n",
    "                \n",
    "                print(f\"P and S pick times:{p_pick_time} and {s_pick_time}\")\n",
    "                print(f\"Stream start and end times:{starttime_st} and {endtime_st}\")\n",
    "                print(f\"Noise start and end times:{starttime_noise} and {endtime_noise}\")\n",
    "                print(f\"Signal start and end times:{starttime_signal} and {endtime_signal}\")\n",
    "                \n",
    "                print(f'Noise:{noise}')\n",
    "                print(f'Signal:{signal}')\n",
    "\n",
    "                noise_abs = np.percentile(abs(noise[0].data),percentile)\n",
    "                signal_abs = np.percentile(abs(signal[0].data),percentile)\n",
    "\n",
    "                snr = 20 * np.log10((signal_abs/noise_abs))\n",
    "\n",
    "                snr_list.append(snr)\n",
    "                \n",
    "            if len(p_picks)>0 and len(s_picks)==0:\n",
    "                \n",
    "                print(p_picks['datetime'].values,s_picks['datetime'].values)\n",
    "                p_pick_time = UTCDateTime(str(p_picks['datetime'].values[0]))\n",
    "#                 s_pick_time = UTCDateTime(str(s_picks['datetime'].values[0]))\n",
    "\n",
    "                starttime_st = UTCDateTime(p_pick_time)-timedelta(seconds=120)\n",
    "                endtime_st = UTCDateTime(p_pick_time)+timedelta(seconds=120)\n",
    "                \n",
    "                starttime_noise = UTCDateTime(p_pick_time)-timedelta(seconds=8)\n",
    "                endtime_noise = UTCDateTime(p_pick_time)\n",
    "                \n",
    "                starttime_signal = UTCDateTime(p_pick_time)+timedelta(seconds=1)\n",
    "                endtime_signal = UTCDateTime(p_pick_time)+timedelta(seconds=4)\n",
    "                \n",
    "            \n",
    "                if i[0] in ['NC', 'BK']:\n",
    "                # Query waveforms\n",
    "                    st = client_ncedc.get_waveforms(network=i[0], station=i[1],\n",
    "                                                    location=\"*\", channel=\"?HZ\",starttime=starttime_st, \n",
    "                                                    endtime=endtime_st)\n",
    "\n",
    "                elif i[0] in networks: \n",
    "                    st = client_waveform.get_waveforms(network=i[0], station=i[1],\n",
    "                                                       channel='?HZ',starttime=starttime_st, endtime=endtime_st)\n",
    "\n",
    "                else: \n",
    "                    st =  Stream()\n",
    "                    print(f\"WARNING: No data for {ii[1]}.{ii[2]}.{channel} on {otime}.\")    \n",
    "                    continue\n",
    "\n",
    "        #         print(f\"len(st):{len(st)}\")\n",
    "        #         print(st)\n",
    "\n",
    "                # Skip empty traces\n",
    "                if len(st) == 0:\n",
    "                    continue\n",
    "                print(f'First st print:{st}')\n",
    "                # Create a new stream\n",
    "                _st = Stream()\n",
    "                # Check for HH and BH channels presence\n",
    "                has_HH = bool(st.select(channel=\"HH?\"))\n",
    "                has_BH = bool(st.select(channel=\"BH?\"))\n",
    "\n",
    "                # Apply selection logic based on channel presence\n",
    "                if has_HH and has_BH:\n",
    "                    # If both HH and BH channels are present, select only HH\n",
    "                    _st += st.select(channel=\"HH?\")\n",
    "                elif has_HH:\n",
    "                    # If only HH channels are present\n",
    "                    _st += st.select(channel=\"HH?\")\n",
    "                elif has_BH:\n",
    "                    # If only BH channels are present\n",
    "                    _st += st.select(channel=\"BH?\")\n",
    "\n",
    "                _st.merge(fill_value='interpolate') # fill gaps if there are any.\n",
    "\n",
    "                print(f'Second st print:{_st}')\n",
    "                \n",
    "                \n",
    "                    \n",
    "\n",
    "                noise = _st.copy().trim(starttime=starttime_noise,endtime=endtime_noise)    \n",
    "                signal = _st.copy().trim(starttime=starttime_signal,endtime=endtime_signal) \n",
    "                \n",
    "                print(f\"P pick time:{p_pick_time}\")\n",
    "                print(f\"Stream start and end times:{starttime_st} and {endtime_st}\")\n",
    "                print(f\"Noise start and end times:{starttime_noise} and {endtime_noise}\")\n",
    "                print(f\"Signal start and end times:{starttime_signal} and {endtime_signal}\")\n",
    "\n",
    "                print(f'Noise:{noise}')\n",
    "                print(f'Signal:{signal}')\n",
    "\n",
    "                noise_abs = np.percentile(abs(noise[0].data),percentile)\n",
    "                signal_abs = np.percentile(abs(signal[0].data),percentile)\n",
    "\n",
    "                snr = 20 * np.log10((signal_abs/noise_abs))\n",
    "\n",
    "                snr_list.append(snr)\n",
    "                    \n",
    "            if len(p_picks)==0 and len(s_picks)>0:\n",
    "                print(p_picks['datetime'].values,s_picks['datetime'].values)\n",
    "#                 p_pick_time = UTCDateTime(str(p_picks['datetime'].values))\n",
    "                s_pick_time = UTCDateTime(str(s_picks['datetime'].values[0]))\n",
    "    \n",
    "                starttime_st = UTCDateTime(s_pick_time)-timedelta(seconds=120)\n",
    "                endtime_st = UTCDateTime(s_pick_time)+timedelta(seconds=120)\n",
    "                \n",
    "                starttime_noise = UTCDateTime(s_pick_time)-timedelta(seconds=8)\n",
    "                endtime_noise = UTCDateTime(s_pick_time)\n",
    "                \n",
    "                starttime_signal = UTCDateTime(s_pick_time)\n",
    "                endtime_signal = UTCDateTime(s_pick_time)+timedelta(seconds=3)\n",
    "                \n",
    "                print(starttime_noise,endtime_noise)\n",
    "            \n",
    "                if i[0] in ['NC', 'BK']:\n",
    "                # Query waveforms\n",
    "                    st = client_ncedc.get_waveforms(network=i[0], station=i[1],\n",
    "                                                    location=\"*\", channel=\"?HZ\",starttime=starttime_st, \n",
    "                                                    endtime=endtime_st)\n",
    "\n",
    "                elif i[0] in networks: \n",
    "                    st = client_waveform.get_waveforms(network=i[0], station=i[1],\n",
    "                                                       channel='?HZ',starttime=starttime_st, endtime=endtime_st)\n",
    "\n",
    "                else: \n",
    "                    st =  Stream()\n",
    "                    print(f\"WARNING: No data for {ii[1]}.{ii[2]}.{channel} on {otime}.\")    \n",
    "                    continue\n",
    "\n",
    "        #         print(f\"len(st):{len(st)}\")\n",
    "        #         print(st)\n",
    "\n",
    "                # Skip empty traces\n",
    "                if len(st) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                print(f'First st print:{st}')\n",
    "                # Create a new stream\n",
    "                _st = Stream()\n",
    "                # Check for HH and BH channels presence\n",
    "                has_HH = bool(st.select(channel=\"HH?\"))\n",
    "                has_BH = bool(st.select(channel=\"BH?\"))\n",
    "\n",
    "                # Apply selection logic based on channel presence\n",
    "                if has_HH and has_BH:\n",
    "                    # If both HH and BH channels are present, select only HH\n",
    "                    _st += st.select(channel=\"HH?\")\n",
    "                elif has_HH:\n",
    "                    # If only HH channels are present\n",
    "                    _st += st.select(channel=\"HH?\")\n",
    "                elif has_BH:\n",
    "                    # If only BH channels are present\n",
    "                    _st += st.select(channel=\"BH?\")\n",
    "\n",
    "                _st.merge(fill_value='interpolate') # fill gaps if there are any.\n",
    "\n",
    "                print(f'Second st print:{_st}')\n",
    "\n",
    "            \n",
    "                noise = _st.copy().trim(starttime=starttime_noise,endtime=endtime_noise)    \n",
    "                signal = _st.copy().trim(starttime=starttime_signal,endtime=endtime_signal) \n",
    "                \n",
    "                print(f\"S pick time:{s_pick_time}\")\n",
    "                print(f\"Stream start and end times:{starttime_st} and {endtime_st}\")\n",
    "                print(f\"Noise start and end times:{starttime_noise} and {endtime_noise}\")\n",
    "                print(f\"Signal start and end times:{starttime_signal} and {endtime_signal}\")\n",
    "                \n",
    "                print(f'Noise:{noise}')\n",
    "                print(f'Signal:{signal}')\n",
    "\n",
    "                noise_abs = np.percentile(abs(noise[0].data),percentile)\n",
    "                signal_abs = np.percentile(abs(signal[0].data),percentile)\n",
    "\n",
    "                snr = 20 * np.log10((signal_abs/noise_abs))\n",
    "\n",
    "                snr_list.append(snr)\n",
    "            \n",
    "    all_assignments_picks['snr']=snr_list\n",
    "     \n",
    "    return snr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52736088",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_list = calc_snr(all_picks,all_pick_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_waveform = WaveformClient()\n",
    "\n",
    "p_pick_time = '2014-01-02T07:40:02.642533Z'\n",
    "\n",
    "starttime_st = UTCDateTime(p_pick_time)-timedelta(seconds=120)\n",
    "endtime_st = UTCDateTime(p_pick_time)+timedelta(seconds=120)\n",
    "\n",
    "# starttime_st = UTCDateTime('2011-01-03T00:00:0.000000Z')\n",
    "# endtime_st = UTCDateTime('2011-01-03T12:59:59.000000Z')\n",
    "\n",
    "print(f'Requested start and end times:{starttime_st} and {endtime_st}')\n",
    "\n",
    "\n",
    "st = client_waveform.get_waveforms(network='CN', station='BTB',\n",
    "                                       channel='HHZ',starttime=starttime_st, endtime=endtime_st)\n",
    "print(f'Actual start and end times: {st[0].stats.starttime} and {st[0].stats.endtime}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a901a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
